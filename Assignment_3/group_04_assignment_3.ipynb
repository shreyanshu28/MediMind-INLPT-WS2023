{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9f7653",
   "metadata": {
    "id": "be9f7653"
   },
   "source": [
    "**Heidelberg University**\n",
    "\n",
    "**Data Science  Group**\n",
    "    \n",
    "Prof. Dr. Michael Gertz  \n",
    "\n",
    "Ashish Chouhan, Satya Almasian, John Ziegler, Jayson Salazar, Nicolas Reuter\n",
    "    \n",
    "December 4, 2023\n",
    "    \n",
    "Natural Language Processing with Transformers\n",
    "\n",
    "Winter Semster 2023/2024     \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e9648",
   "metadata": {
    "id": "258e9648"
   },
   "source": [
    "# **Assignment 3: “Transformers”**\n",
    "**Due**: Monday, January 8, 2024, 2pm, via [Moodle](https://moodle.uni-heidelberg.de/course/view.php?id=19251)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc27ad9e",
   "metadata": {
    "id": "fc27ad9e"
   },
   "source": [
    "### **Submission Guidelines**\n",
    "\n",
    "- Solutions need to be uploaded as a **single** Jupyter notebook. You will find several pre-filled code segments in the notebook, your task is to fill in the missing cells.\n",
    "- For the written solution, use LaTeX in markdown inside the same notebook. Do **not** hand in a separate file for it.\n",
    "- Download the .zip file containing the dataset but do **not** upload it with your solution.\n",
    "- It is sufficient if one person per group uploads the solution to Moodle, but make sure that the full names of all team members are given in the notebook.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HETm7VsBkmLq",
   "metadata": {
    "id": "HETm7VsBkmLq"
   },
   "source": [
    "## **Task 1: Diving into Attention** (3 + 4 + 4 + 1 = 12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ODkKBIRkrfe",
   "metadata": {
    "id": "0ODkKBIRkrfe"
   },
   "source": [
    "In this task, you work with self-attention equations and find out why multi-head attention is preferable to single-head attention.\n",
    "\n",
    "Recall the equation of attention on slide 5-9 to compute self-attention on a series of input tokens. We simplify the formula by focusing on a single query vector $q \\in R^d$, value vectors ($\\{ v_1,v_2,...,v_i \\},v_i \\in R^d$), and key vectors ($\\{ k_1,k_2,...,k_i \\},k_i \\in R^d$). We then have\n",
    "\n",
    "$$\n",
    "a_i=\\frac{exp(q^Tk_i)}{\\Sigma^n_{j=1}exp(q^Tk_j)}\n",
    "$$\n",
    "\n",
    "$$\n",
    " o= \\Sigma^n_{i=1} a_i v_i\n",
    "$$\n",
    "\n",
    "with $a_i$ being the attention weight for query $q$ with respect to key $k_i$. Then the output $o$ is the new representation for the query token as a weighted average of value vectors with weights $a=\\{ a_1,a_2,...,a_i \\},a_i \\in R^d$.\n",
    "Answer the following questions with the help of the equations and the intuition behind attention that you learned in the class:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MRwxqsMVodDt",
   "metadata": {
    "id": "MRwxqsMVodDt"
   },
   "source": [
    "### Subtask 1: Copying  \n",
    "\n",
    "1.   Explain why $a$ can be interpreted as a categorical distribution.\n",
    "2.   This distribution is typically diffuse, where the mass is spread out between different values of $a_i$. Describe a scenario in which the categorical distribution puts all the weight on a single element, e.g., $a_j \\gg \\Sigma_{j\\neq i}a_i$. What are the conditions on key and/or query for this to happen?\n",
    "3. In this case of a single large $a$, what would the output $c$ look like and what it means intuitively?\n",
    "\n",
    "In attention, it is easy to **copy** a value vector $v_i$ to the output $o$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Km0X1VPoqgrt",
   "metadata": {
    "id": "Km0X1VPoqgrt"
   },
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZcLTljmmqhIM",
   "metadata": {
    "id": "ZcLTljmmqhIM"
   },
   "source": [
    "\n",
    "1. Because the calculation of $a$ is essentially the application of softmax to the matrix of $q^Tk_i$. Since softmax yields a propabilitiy distribution for the probability of the query regarding all the keys (value between 0 and 1 with a sum over all keys of 1), this can be seen as categorical distribution\n",
    "\n",
    "2. The scenario where one element $a_j$ dominates the distribution ($a_j \\gg \\sum_{j\\neq i} a_i$) occurs when the query vector $q$ strongly aligns with a specific key vector $k_j$. In other words, the dot product $q^Tk_j$ is significantly larger than the dot products of $q$ with other key vectors. This condition indicates that the query has a strong association with a particular key, leading to a focused attention on that specific element.\n",
    "\n",
    "3. When a single $a_j$ is much larger than the others, the output $o$ becomes a weighted sum where the dominant weight is associated with the value vector $v_j$. Intuitively, this means that the output representation is heavily influenced by the information in the value vector corresponding to the key that strongly matches the query. The output essentially becomes a \"copy\" of the information from the value vector $v_j$, demonstrating the mechanism's capability to selectively focus on relevant information during the attention process.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NK-2Scv8qqYV",
   "metadata": {
    "id": "NK-2Scv8qqYV"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 1.1}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "Total points = 3/3\n",
    "\n",
    "1. The answer is correct and explanation similar to what is explained in sample solution. \n",
    "2. The answer is correct and explanation similar to what is explained in sample solution.\n",
    "3. The answer is correct and explanation similar to what is explained in sample solution.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YmWxycPF15kM",
   "metadata": {
    "id": "YmWxycPF15kM"
   },
   "source": [
    "### Subtask 2: Averaging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WFKra56Q15mq",
   "metadata": {
    "id": "WFKra56Q15mq"
   },
   "source": [
    "Instead of focusing on just one value vector $v_j$, the Transformer model can incorporate information from multiple inputs. Consider the situation where we want to incorporate information from two value vectors $v_b$ and $v_c$ with keys $k_b$ and $k_c$. In machine learning one of the ways to combine this information is through averaging of vectors $o= \\frac{1}{2}(v_b+v_c)$.  It might seem hard to extract information about the original vectors $v_b$ and $v_c$ from the resulting average. But under certain conditions, one can do so. In this subtask, we look at the following cases:\n",
    "\n",
    "1. Suppose we know the following:\n",
    "\n",
    "\n",
    "* $v_b$ lies in a subspace $B$ formed by the $m$ basis vectors $\\{b_1, b_2, .. , b_m\\}$, while $v_c$ lies in a subspace $C$ formed by the $p$ basis vectors $\\{c_1, c_2, . . . , c_p\\}$ (This means that any $v_b$ and $v_c$ can be expressed as a linear combination of their basis vectors).\n",
    "*   All basis vectors have the norm 1 and are orthogonal to each other.\n",
    "*   The two subspaces $B$ and $C$ are orthogonal, meaning $b_j^Tc_k=0$ for all $j$ and $k$.\n",
    "* Given that $\\{b_1, b_2, .. , b_m\\}$ are both orthogonal and form a basis for $v_b$, we know that there exists some $d_1, ..., d_m$ such that $v_b=d_1 b_1+d_2 b_2+...+d_m b_m$. Use these $d\\text{s}$ to solve this task.\n",
    "\n",
    "Using the basis vectors $\\{b_1, b_2, .. , b_m\\}$, construct a matrix $M$ such that for arbitrary vectors $v_b$ and $v_c$ with the given conditions, we can use $M$ to extract $v_b$ from the sum of the vector $s = v_b + v_c$. In other words, construct an $M$ such that  $ Ms = v_b$ holds.\n",
    "\n",
    "\n",
    "2. If we assume that\n",
    "* all key vectors are orthogonal, i.e., $k_i^Tk_j=0$ for all $i \\neq j$, and\n",
    "* all key vectors have the norm 1.\n",
    "\n",
    "Find an expression for the query vector $q$ such that $o \\approx \\frac{1}{2}(v_b+v_c)$. Justify your answer.\n",
    "\n",
    "**Hint:** Use your finding in subtask 1 to solve part 2.\n",
    "\n",
    "**Hint:** If the norm of a vector $x$ is 1, then $x^Tx=1$\n",
    "\n",
    "**Hint:** Start with writing $v_b$ and $v_c$ as the linear combination of the bases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UdPaWhCzTxKT",
   "metadata": {
    "id": "UdPaWhCzTxKT"
   },
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uDB4aKn0Us4H",
   "metadata": {
    "id": "uDB4aKn0Us4H"
   },
   "source": [
    "1.\n",
    "We know that $v_b = d_1 b_1 + d_2 b_2 + ... + d_m b_m$, and $v_c$ can be expressed similarly with other coefficents, we call them $d'_1, .., d'_p$. Let's define the matrix $M$ as follows:\n",
    "\n",
    "$$\n",
    "M = \\begin{bmatrix}\n",
    "    b_1^2 & 0 & \\cdots & 0 \\\\\n",
    "    0 & b_2^2 &\\cdots & 0 \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & 0 & \\cdots & b_m^2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "It is a diagonal matrix containing b_x / b_x. This allows the following:\n",
    "Since s = $v_b + v_c$ both must be of equal length. Also we know that $b_j^T c_k = 0$\n",
    "Hence, for each part of the sum of s it holds:\n",
    "$ b_j^2 (b_j d_j + c_j d'_j) = b_j b_j b_j d_j + c_j b_j b_j d'_j = 1 b_j d_j + 0 b_j d'_j = v_b[j] $\n",
    "\n",
    "Now, for any vectors $v_b$ and $v_c$ satisfying the given conditions, the matrix multiplication $Ms$ will yield $v_b$.\n",
    "\n",
    "\n",
    "\n",
    "2. To achieve $o \\approx \\frac{1}{2}(v_b+v_c)$, we want the attention weights $a_i$ to be such that they give equal importance to $v_b$ and $v_c$. Let $a_b$ and $a_c$ be the attention weights for $v_b$ and $v_c$ respectively.\n",
    "\n",
    "$ o \\approx a_b \\cdot v_b + a_c \\cdot v_c $\n",
    "\n",
    "Now, let's find $q$ such that $o \\approx \\frac{1}{2}(v_b + v_c)$. To achieve this, we need $a_b \\approx a_c$ and $a_b + a_c = 1$.\n",
    "\n",
    "Given the softmax attention weight calculation:\n",
    "\n",
    "$a_i = \\frac{\\exp(q^Tk_i)}{\\sum^n_{j=1}\\exp(q^Tk_j)} $\n",
    "\n",
    "To simplify the expression and achieve $o \\approx \\frac{1}{2}(v_b + v_c)$, we can aim for $q^Tk_b \\approx q^Tk_c$ and $q^Tk_b + q^Tk_c = 0$ (to satisfy the orthogonality condition).\n",
    "\n",
    "Let $q$ be:\n",
    "\n",
    "$ q = \\frac{1}{\\sqrt{2}}(k_b - k_c) $\n",
    "\n",
    "With this choice of $q$, let's analyze the terms:\n",
    "\n",
    "$ q^Tk_b = \\frac{1}{\\sqrt{2}}(k_b - k_c)^Tk_b = \\frac{1}{\\sqrt{2}}\\|k_b\\|^2 - \\frac{1}{\\sqrt{2}}(k_b^Tk_c) $\n",
    "\n",
    "$ q^Tk_c = \\frac{1}{\\sqrt{2}}(k_b - k_c)^Tk_c = -\\frac{1}{\\sqrt{2}}(k_b^Tk_c) + \\frac{1}{\\sqrt{2}}\\|k_c\\|^2 $\n",
    "\n",
    "Therefore, $ q^Tk_b + q^Tk_c = 0 $, and $ q^Tk_b \\approx q^Tk_c $. This implies that the attention weights $a_b$ and $a_c$ will be approximately equal.\n",
    "\n",
    "As a result, the output \\(o\\) becomes:\n",
    "\n",
    "$ o \\approx a_b \\cdot v_b + a_c \\cdot v_c \\approx \\frac{1}{2}(v_b + v_c) $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5poTWvSxUoc3",
   "metadata": {
    "id": "5poTWvSxUoc3"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 1.2}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "```\n",
    "\n",
    "Total points = 3/4\n",
    "1. The answer is incorrect as M is transpose of B and not a diagonal matrix. However, the logic is correct to prove the next part of the equation \n",
    "$\n",
    "B^TBd+ B^TCf= Id+0f = d\n",
    "$. (1/2)\n",
    "2. The answer is correct and explanation similar to what is explained in sample solution. (2/2)\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imqOTai0bxuA",
   "metadata": {
    "id": "imqOTai0bxuA"
   },
   "source": [
    "### Subtask 3: Drawbacks of Single-head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0lObCVx7bx3q",
   "metadata": {
    "id": "0lObCVx7bx3q"
   },
   "source": [
    "You might have wondered why we need multi-heads for attention. In this subtask, we look at some of the drawbacks of having a single head attention. As shown in the previous subtask, it is possible for single head attention to focus equally on two values. The same can apply to any subset of values, which therefor can become problematic.\n",
    "\n",
    "Consider a set of key vectors $\\{ k_1,k_2,...,k_n \\}$, randomly sampled from a normal distribution with a known mean value of $\\mu_i \\in R^d$ and unknown covariance $Σ_i, i \\in \\{1, \\ldots, n\\}$, where\n",
    "\n",
    "\n",
    "*   $\\mu_i\\text{s}$ are all orthogonal $\\mu_i^T\\mu_j=0$ if $i \\neq j$.\n",
    "*   $\\mu_i\\text{s}$ all have unit norm $||\\mu_i||=1$.\n",
    "\n",
    "1. For a vanishingly small $\\alpha$ (not to be confused with attention weights), the covariance matrices are  $Σ_i=\\alpha I, \\forall i  \\in \\{1,2,..,n\\}$, design a query $q$ in terms of the $\\mu_i$ such that as before, $o= \\frac{1}{2}(v_b+v_c)$ and describe why it works.\n",
    "\n",
    "2.  Large perturbations in key value might cause problems for single head attention.  Specifically, in some cases, one key vector $k_b$ may be larger or smaller in norm than the others, while still pointing in the same direction as $\\mu_b$. As an example of such a case,\n",
    "consider a covariance matrix for item $b$ for vanishingly small $\\alpha$ as $Σ_b=\\alpha I + \\frac{1}{2}(\\mu_b^T\\mu_b)$. This causes $k_a$ to point to roughly the same direction as $\\mu_b$ but with large differences in magnitude, while for other items. Further, let $Σ_i=\\alpha I\\  \\forall_i i \\neq b$. When you sample multiple keys from the distribution $\\{ k_1,k_2,...,k_n \\}$ and use the $q$ vector from the pervious part, what do you expect vector $o$ to look like? Explain why this shows the drawback of single-head attention.\n",
    "\n",
    "**Hint:**\n",
    "Think about how it differs from pervious part and how $o$'s variance would be affected by the change in $Σ_b$.\n",
    "\n",
    "**Hint:** Considering that $\\mu_b^T\\mu_b=1$, think of what are the ranges $Σ_b$ can take and how does that effect a sampled $k_b$ value.\n",
    "\n",
    "**Hint:** $\\frac{exp(b)}{exp(b)+exp(c)}=\\frac{exp(b)}{exp(b)+exp(c)}\\frac{exp(-b)}{exp(-b)}= \\frac{1}{1+exp(c-b)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PFkzZv9NcCpZ",
   "metadata": {
    "id": "PFkzZv9NcCpZ"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1yhrRv0rTww2",
   "metadata": {
    "id": "1yhrRv0rTww2"
   },
   "source": [
    "\n",
    "1. Given that the covariance matrices are $Σ_i = \\alpha I$, for vanishingly small $\\alpha$, we can design the query vector $q$ as follows:\n",
    "\n",
    "$ q = \\frac{1}{\\sqrt{2\\alpha}}(\\mu_b - \\mu_c) $\n",
    "\n",
    "Now, let's analyze why this choice of $q$ works:\n",
    "\n",
    "- In the softmax attention weight calculation, $a_i = \\frac{\\exp(q^Tk_i)}{\\sum^n_{j=1}\\exp(q^Tk_j)}$.\n",
    "- With $q = \\frac{1}{\\sqrt{2\\alpha}}(\\mu_b - \\mu_c)$, the inner product $q^Tk_i$ simplifies to $\\frac{1}{\\sqrt{2\\alpha}}(\\mu_b^Tk_i - \\mu_c^Tk_i)$.\n",
    "- Since $\\mu_i^T\\mu_j = 0$ for $i \\neq j$ (orthogonality), the terms $\\mu_b^Tk_i$ and $\\mu_c^Tk_i$ effectively isolate $k_b$ and $k_c$ respectively in the inner product.\n",
    "- The denominators $\\sum^n_{j=1}\\exp(q^Tk_j)$ involve terms similar to $q^Tk_i$, and the softmax function ensures that $a_b \\approx a_c$.\n",
    "\n",
    "Therefore, with this choice of $q$, the attention weights $a_b$ and $a_c$ should be approximately equal, and the output $o$ becomes a weighted average of $v_b$ and $v_c$ with equal weights, achieving the desired result.\n",
    "\n",
    "---\n",
    "\n",
    "2.\n",
    "In this scenario, where $Σ_b = \\alpha I + \\frac{1}{2}(\\mu_b^T\\mu_b)$ and $Σ_i = \\alpha I$ for all $i \\neq b$, the covariance matrix for item $b$ introduces a perturbation term proportional to $\\mu_b^T\\mu_b$. This perturbation term causes $k_b$ to have large differences in magnitude compared to the other key vectors.\n",
    "\n",
    "Considering the query vector $q = \\frac{1}{\\sqrt{2\\alpha}}(\\mu_b - \\mu_c)$ from the previous part, the inner product $q^Tk_b$ simplifies to $\\frac{1}{\\sqrt{2\\alpha}}(\\mu_b^Tk_b - \\mu_c^Tk_b)$. Due to the large perturbation in $k_b$, the term $\\mu_b^Tk_b$ dominates, causing $q^Tk_b$ to be significantly larger than other $q^Tk_i$ terms.\n",
    "\n",
    "As a result, in the softmax attention weight calculation, $a_b$ becomes much larger than the other attention weights $a_i$. This leads to a situation where the attention mechanism predominantly focuses on $v_b$ while largely neglecting the other values.\n",
    "\n",
    "Therefore, in this case, the vector $o$ is expected to be heavily skewed towards $v_b$, indicating a drawback of single-head attention in handling large perturbations in key values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j0r37mi5cC1B",
   "metadata": {
    "id": "j0r37mi5cC1B"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 1.3}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "total points 3/4\n",
    "1. Answer is correct. 1/1\n",
    "2. Answer is partially correct and method described here is not comprehensive (w.r.t to sample solution). The answer needs an explanation in detail  2/3\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_qxdcrolx48r",
   "metadata": {
    "id": "_qxdcrolx48r"
   },
   "source": [
    "### Subtask 4: Model Size  \n",
    "1. Imagine you have an input sequence of  $l$ tokens, how much memory is required and what time complexity do we have for a single self-attention layer? (give your answer in terms of $l$)\n",
    "2. If you have $N$ layers of self-attention, how  would the memory requirements and the time complexity change? (give your answer in terms of $l$ and $N$)\n",
    "3. If you have $l=10,000$ and $10$ layers, with the ability to perform $10M$ operations per second, how long would it take to compute the attention output?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s35qnPU4yoYD",
   "metadata": {
    "id": "s35qnPU4yoYD"
   },
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LzlVLskKzBXq",
   "metadata": {
    "id": "LzlVLskKzBXq"
   },
   "source": [
    "1. The memory requirement for a single self-attention layer involves storing the key, query, and value vectors for each token. Assuming each vector has a dimension of $d$, the memory complexity is $O(l \\cdot d)$. The time complexity for self-attention is approximately $O(l^2 \\cdot d)$.\n",
    "\n",
    "2. For $N$ layers of self-attention, the memory requirements would scale linearly with the number of layers, and the time complexity would scale quadratically. The memory complexity becomes $O(N \\cdot l \\cdot d)$, and the time complexity becomes $O(N \\cdot l^2 \\cdot d)$.\n",
    "\n",
    "3. Substitute $l=10,000$, $N=10$, and $d$ with the specific dimensionality of your vectors into the time complexity formula:\n",
    "$ \\text{Time} = O(N \\cdot l^2 \\cdot d) = 10 \\cdot (10,000)^2 \\cdot d \\text{ operations} $\n",
    "\n",
    "Given the ability to perform $10M$ (million) operations per second:\n",
    "\n",
    "$ \\text{Time taken} = \\frac{1.000.000.000 \\cdot d}{10.000.000} = 100 \\cdot d \\text{   seconds} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n2UFNSuozvNd",
   "metadata": {
    "id": "n2UFNSuozvNd"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 1.4}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "total points 1/1\n",
    "All three answers are correct and explanation similar to what is explained in sample solution. (with added factor of d in time complexity) \n",
    "\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Av_GjYokHmGo",
   "metadata": {
    "id": "Av_GjYokHmGo"
   },
   "source": [
    "## **Task 2: Multiple Choice Question Answering** (4 + 3 + 5 + 2 = 14 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hypnmNp2yeNz",
   "metadata": {
    "id": "hypnmNp2yeNz"
   },
   "source": [
    "In this task, you will fine-tune a transformer model on a multiple-choice task, which is the task of selecting the most plausible inputs in a given selection. The dataset used here is [SWAG](https://www.aclweb.org/anthology/D18-1009/), which is available via the Hugging Face [hub](https://huggingface.co/datasets/swag). Check the link for an overview of the dataset. SWAG is a dataset about commonsense reasoning, where each example describes a situation and then proposes four options that could apply for it.\n",
    "Let's start by installing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "RYb57u4CHnZ7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYb57u4CHnZ7",
    "outputId": "06c7d47d-dbad-46f4-81ee-7bef66fbba6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
      "Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: responses, evaluate\n",
      "Successfully installed evaluate-0.4.1 responses-0.18.0\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.25.0\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install datasets\n",
    "%pip install evaluate\n",
    "%pip install accelerate -U\n",
    "%pip install sentencepiece\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "CjuRVAYciVLh",
   "metadata": {
    "id": "CjuRVAYciVLh"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oLwC5naF8KzV",
   "metadata": {
    "id": "oLwC5naF8KzV"
   },
   "source": [
    "In this task, you will use a BERT model with a `MultipleChoice` head from the Hugging Face library and then create your custom model.   Recall from the class that the BERT model has an auxiliary next sentence prediction task, in which two sentences are given to BERT separated by a `[SEP]` token and a classifier head decides if the second sentence logically follows the first one. Hugging Face has\n",
    " a `*ForMultipleChoice` architecture that uses the representation of the `[CLS]` token and a linear layer to classify if one sentence follows the other. We first start with this default architecture and then build a more complicated one in a later subtask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FJ7H6SSk1DqI",
   "metadata": {
    "id": "FJ7H6SSk1DqI"
   },
   "source": [
    "### Subtask 1: Loading and Processing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KvvYhCtW1kI3",
   "metadata": {
    "id": "KvvYhCtW1kI3"
   },
   "source": [
    "We use the `dataset` library to download the SWAG dataset, which already contains train, validation, and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "-cLxQBhq0Rmo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754,
     "referenced_widgets": [
      "5a57877bd1584d38b77fb7f1408aabbd",
      "f97256cc0f9a43b79688eb076147e980",
      "1fa8b739e3f045a0bb3d31147d4900f7",
      "f0f4796fd6f64f8f84027dca0b403f99",
      "265fb4db2fc3495ea1c787f0cfc3184c",
      "5755cd49cc8c43219e369a608401b97c",
      "d388b6f112bc403e9397f6e80978b80c",
      "3ba966155c584b06b177e52ce1c7495f",
      "fedd66d83af04fe08e432b6899321d7b",
      "c5c2eaa5b339436f9ae750e9d2c7fbd2",
      "909ca5bee1a34086812609f2a8524625",
      "0d84c640fba846acbcd3abb92e0b24e4",
      "a5049fbdc5db4ef4ab908f16901573dd",
      "2d8ad4c70b194050b447e1525312a636",
      "d7f3dfab8d7d480f808d0a89bc5bbbb6",
      "1e8b6cb082d0464c89f31d0dc981d1ae",
      "0ce25511b0c54f9a8ad546a00c7d041a",
      "97f473ef07f040b498fedf3e7decbe56",
      "94d41362847e431ab013a75ac431125d",
      "88cae77cf84847efb964bc0cc21ec55e",
      "dbbae709ee7d41d7a55553bcf3185f7c",
      "4c6ae1461ac34a96a71820cb3ee35da0",
      "3ee154deae6d431e824dbf7b2d72070f",
      "a5a7b3bf299241a886b958d9204a5ba3",
      "cfabc4420a7c4bdca39c01e5e62faf42",
      "98edcdbed47946ca8ef1b2c60f02a15e",
      "0ff40e429a5747f48de3f356bf415709",
      "359f41dc0a8a4ed0a548e596a466a93f",
      "67ea5dc5d0e44ca0b3e044d2c05162ab",
      "578304a456b84469bddf7b106dcda33f",
      "3dbe0771dc614016b0108aa4f21a6365",
      "afcbba2ab9e1478a897692d48e16065e",
      "f8abdeef1a874b21a6a26e85630e917f",
      "fe6e8015267f4c3db98845148095bafe",
      "5a34873d2c384e738ea0c98f00e37cd3",
      "ca09f1eb68bc472ea9370c62026bf09b",
      "88be60663f574a36b05415099c7d9ebe",
      "33dd465640c6456d8f8a5e5657dcb52c",
      "e9e2c788e43448e296dc982d55e4a154",
      "5d598908cc7a4ae98a77fdfb5c5e1413",
      "66edd391e81c4a0f8bb63b1eca20f58e",
      "5e902246d66f471e82a87a2da202dbfc",
      "68e4b94d07b84955806f37b808d59675",
      "fb69487f907c45a38b44826503c5849c",
      "cafacfc001b84794843fd369e4b77698",
      "29c5a6ef24ee43ccadd891d774b93bb8",
      "a4f95680036e4b1c8e7df70b19b14bbf",
      "49b0eaefe2a640c184dffe89cab27794",
      "74db6de2bc4746058c2469d702a8b8ec",
      "c8aac1cce4ab4c079674b85c71b6a416",
      "21f37e12489d4c5db71851539f163c6c",
      "e6bec7d0b3594f69b4ac6c809457e1d9",
      "265d180ad9e648c194472d8258f195d4",
      "fa1829f7a57643aa9a9a42be635e5eca",
      "6a4288d797d04edeb1861c23dc371cc4",
      "021b8f0ed860481da9b692a64c76eced",
      "f071a994d59c4786a8de930823a798bb",
      "979a2d2165aa439eb9f53243b48f4235",
      "2dd52546dd8d43e787b39319eb621c48",
      "22d26990dccf44399d6b7316ebd6109e",
      "a86346c2f4354dc4876ea9da7dadfa70",
      "7f89ba5ea2f44f1cb850d90f5ff43ca3",
      "8002acdb281f4cf4a8dfd2d5f5804f83",
      "9c38cf7f1fa048c68a907aa408f759df",
      "1fd0ea7e9ae640e6a0333240e22f96f0",
      "d15544fead5f4a4d95db8be9ae6120ac",
      "49a27242d0fe44ae8e0af200280aba14",
      "4f3c3f4854b44d3abeb66405d7c36228",
      "642d57c00b6a4809b6330e65046c2f8f",
      "c23b288d5ed1442cad80012a64b46e64",
      "9a377a3780e24232b8c12ac29eed97c9",
      "0eebbf045d5d44938f87c8b8e34934d6",
      "b3b53e6af28f4bd4b04471b651cb86b2",
      "2c2a64eb71224cfda8cfb60f6869bbd9",
      "faa89a0704e149528f4ff84946a68dbd",
      "0b2efc34361f47d8b7a491ab140221eb",
      "a6186dc1ec544b69b98290fea5b2553a",
      "349611bde2e5489c9b63436ff8e2bda7",
      "67099f9a3a734be791c4d133715da363",
      "c74ef17522654428a6ad6e65948dc5e2",
      "3d4d483d936e494584ab216f96b9a972",
      "8418aa5b385043669c8d2edbb8a301b3",
      "648899cb119f42ff949cd0b1b432ee12",
      "d9200911023d47918495cd1307814c5c",
      "5fd84178dc1d4101869d693d61d300c6",
      "d8e98c4d49a5420dbe27eb6a710ba93f",
      "0f2a1a430f8140ec9c6d909fcbdebd90",
      "6ed11b69997044a2a7571f3872aebbcd",
      "a3a5fe30ad17420295e5ff5996dc13f8",
      "5f9fbdf5c7954348b12fe236d8d2149c",
      "bd584a34ff534146917c6336c6136d11",
      "ec929cb2fcad45eaad53f558f2f90d40",
      "216ba850075a46208c4ce5316e23f4e5",
      "35bbff4bdfb2446089e5378cb105cf9e",
      "24517fb789b64889852c5c59764d8c34",
      "23ce666d4dd4452aa33796e2f785ac8d",
      "54f4073a15e8443488fa8e224c1b3ca8",
      "7ba1d762b16b4db789fc9a45d67b43bf",
      "2b81a4e73e4149a5b1d682dade9c75c5"
     ]
    },
    "id": "-cLxQBhq0Rmo",
    "outputId": "c1c19ea8-8d8a-46af-e0d7-b7c9100be423"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1429: FutureWarning: The repository for swag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/swag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a57877bd1584d38b77fb7f1408aabbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d84c640fba846acbcd3abb92e0b24e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/7.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee154deae6d431e824dbf7b2d72070f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6e8015267f4c3db98845148095bafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafacfc001b84794843fd369e4b77698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021b8f0ed860481da9b692a64c76eced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a27242d0fe44ae8e0af200280aba14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/73546 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349611bde2e5489c9b63436ff8e2bda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/20006 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a5fe30ad17420295e5ff5996dc13f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/20005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
       "        num_rows: 73546\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
       "        num_rows: 20006\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
       "        num_rows: 20005\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from datasets import load_dataset, load_metric\n",
    "datasets = load_dataset(\"swag\", \"regular\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DHkkMD3v4bs3",
   "metadata": {
    "id": "DHkkMD3v4bs3"
   },
   "source": [
    "Lets look at the first item to see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vN6p1Mt84ZW_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vN6p1Mt84ZW_",
    "outputId": "1756a54d-2110-4ff8-8f9f-fc3e697223ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video-id': 'anetv_jkn6uvmqwh4',\n",
       " 'fold-ind': '3416',\n",
       " 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n",
       " 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n",
       " 'sent2': 'A drum line',\n",
       " 'gold-source': 'gold',\n",
       " 'ending0': 'passes by walking down the street playing their instruments.',\n",
       " 'ending1': 'has heard approaching them.',\n",
       " 'ending2': \"arrives and they're outside dancing and asleep.\",\n",
       " 'ending3': 'turns the lead singer watches the performance.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xOxxXEdbTF8l",
   "metadata": {
    "id": "xOxxXEdbTF8l"
   },
   "source": [
    "**Question:**\n",
    "Look at the dataset card on the Hugging Face hub and define what each of these fields means, with respect to the task:\n",
    "\n",
    "*   `sent1`:\n",
    "*   `sent2`:\n",
    "*    `ending0`, `ending1`, `ending2` and `ending3`:\n",
    "*   `label`:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2FfOTODlURAY",
   "metadata": {
    "id": "2FfOTODlURAY"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "`\n",
    "- sent1: the first sentence\n",
    "- sent2: the start of the second sentence (to be filled)\n",
    "- ending0: first proposition\n",
    "- ending1: second proposition\n",
    "- ending2: third proposition\n",
    "- ending3: fourth proposition\n",
    "- label: the correct proposition\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D9TcSWfiU2m-",
   "metadata": {
    "id": "D9TcSWfiU2m-"
   },
   "source": [
    "Write a function that displays the context and each of the four choices, following the format\n",
    "\n",
    "\n",
    "```\n",
    "Context:...\n",
    "A-\n",
    "B-\n",
    "C-\n",
    "D-\n",
    "Ground truth: option ...\n",
    "```\n",
    "\n",
    "How you display the results is not important. You should be able to extract different parts of the data correctly and know what each field represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "jVOf4b2r4gDq",
   "metadata": {
    "id": "jVOf4b2r4gDq"
   },
   "outputs": [],
   "source": [
    "def explain_example(example):\n",
    "    # Extract relevant fields from the example\n",
    "    context = example['startphrase']\n",
    "    choices = [example[f'ending{i}'] for i in range(4)]\n",
    "    # Convert label to corresponding option letter\n",
    "    ground_truth = chr(ord('A') + example['label'])\n",
    "\n",
    "    # Display the information\n",
    "    print(f\"Context: {context}\\n\")\n",
    "\n",
    "    # Display choices\n",
    "    for i, choice in enumerate(choices):\n",
    "        print(f\"{chr(ord('A') + i)}: {choice}\")\n",
    "\n",
    "    # Display ground truth\n",
    "    print(f\"\\nGround truth: Option {ground_truth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "BlTFSjmR5QrP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BlTFSjmR5QrP",
    "outputId": "fc65d566-3fd2-485d-ee09-9f9e790cae2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Members of the procession walk down the street holding small horn brass instruments. A drum line\n",
      "\n",
      "A: passes by walking down the street playing their instruments.\n",
      "B: has heard approaching them.\n",
      "C: arrives and they're outside dancing and asleep.\n",
      "D: turns the lead singer watches the performance.\n",
      "\n",
      "Ground truth: Option A\n"
     ]
    }
   ],
   "source": [
    "explain_example(datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lXnX0E915qbb",
   "metadata": {
    "id": "lXnX0E915qbb"
   },
   "source": [
    "Before feeding the data into the model, we need to preprocess the text using `Tokenizer` to tokenize the inputs into tokens and put it in a format that the model expects. The tokenizer specific to the model we want to use for this task is `distilbert-base-uncased`. Complete the code below to load a fast tokenizer for this model. DistilBERT is similar to the BERT model, and we only use this particular architecture for faster training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4BkVDc5RdO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272,
     "referenced_widgets": [
      "556cb992cb69488ca88c51bca7884c23",
      "6efea153049a467d945507b922767dc9",
      "4692e3964b7440d794d4625b08692507",
      "f129b011542e47a7b3deb195d6bd54ca",
      "d11034b705ee43e89a6444af654e6095",
      "5ab45343bbb843c59214c7ae88aed759",
      "91923ab4188c4ab0b96da0d1a6ca5df9",
      "26475a21ebff4973a517851e2bcb7b27",
      "67e531e278504247aaddf6de4d17e2a0",
      "5bb59cc2b87e47549cfb02c49a43f300",
      "8d35a7a964c14f798b96c18cad73f169",
      "7ef279340fd2417da8bfb759e1ec4a44",
      "a4ddc6c88c59428da1dcf2d68680ec12",
      "de30af7c954d457c88116d2dbdfb50b6",
      "8545cc6a77c24d16887fe821caa9188c",
      "234692e7eb264701abcaca0b3c5e96db",
      "b3fa688048aa49859105b385711c394d",
      "a8c58072428c46fea597473d72d0e529",
      "ea253b6459cf40bb9c347adf7bc15b9b",
      "f069586be5bf4c80b8728120b1dc8c23",
      "2f05a4d4092c4a43a0d4b10be5c77ea0",
      "007900d3b4d940ed8e75ffcb1a449282",
      "7918418ae85d49afb4448db6a0b285ec",
      "0361bad8a55147a28dd49b87f6a5a0c6",
      "147ffcd6b3384a05ae7658cd0982f32d",
      "2734418a212c4044899a4509265765c8",
      "c14aa0003a084a4c8f33c70550d94868",
      "30959f57119346cd96f30a3e4d573f45",
      "849cfa8331304d6fbb0d54b6de39d1b2",
      "6ee7ecb284b8482882186a6300001f61",
      "d30bc69199fe44ad9ebcc190a90948da",
      "4906bb9727364d179a22d7895d537705",
      "90ce257bf1164264806fa72327da4179",
      "7e1a93a9ccc04f8a88cf09133e3858dd",
      "594827e957f24aa4af9cf3f54895be96",
      "5cacb793be0d4a0182e0c6e6db95a503",
      "df015b6c7d5543a9b595b911e9cf81c3",
      "7236f0d574ef4554b7da54104457fd49",
      "83ab832dfbc54bbca93682b740cd50d5",
      "3d1615a0e9ae438a98e8347bdadf2f37",
      "46f1b5739fa84c4e9e3f4029c18e568a",
      "b449490449cf4f7599dfe79f92ad16c1",
      "47f5b713728545d39aeedf65558258c0",
      "115e3b3e5b8242dd83bd6992071e7823"
     ]
    },
    "id": "fd4BkVDc5RdO",
    "outputId": "dd528be4-eff7-45a5-f70b-7448fdc674cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556cb992cb69488ca88c51bca7884c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef279340fd2417da8bfb759e1ec4a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7918418ae85d49afb4448db6a0b285ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1a93a9ccc04f8a88cf09133e3858dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download vocabulary from huggingface.co and cache.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "BbtOfQ4T7AQV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbtOfQ4T7AQV",
    "outputId": "694cbe29-6a04-484c-84a2-4f435c9b14c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 103, 2023, 102, 2003, 1996, 2034, 6251, 999, 102, 1998, 2023, 2003, 1996, 2117, 2028, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"[MASK] This [SEP] is the first sentence!\", \"And this is the second one.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4LMdG45b7Yop",
   "metadata": {
    "id": "4LMdG45b7Yop"
   },
   "source": [
    "Write a function that preprocesses the samples.\n",
    "The tricky part is to put all the possible pairs of sentences in two big lists before passing them to the tokenizer.\n",
    "Each **first** sentence has to be repeated 4 times to go with different ending options.\n",
    "There should be a separator token between the first and second sentence, to follow the BERT input logic.\n",
    "The final output is a list of 4 elements, one for each choice, where the input is transformed by the tokenizer.\n",
    "For example, with a list of 2 training examples, the output includes 2 lists, where each contains 4 elements. Each of those elements is the converted input ID of the first sentence followed by the second sentence with different endings.\n",
    "When calling the `tokenizer`, we use the argument `truncation=True`. This will ensure that an input longer than what the model selected can handle will be truncated to the maximum length accepted by the model.\n",
    "\n",
    "**Hint:** Flatten the lists (all choices are flattened into a single list) before feeding them into the tokenizer and unflatten them once again for the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2302d2c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2302d2c3",
    "outputId": "b2e59ab3-0224-4a20-e534-ed87069fadd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video-id': ['anetv_jkn6uvmqwh4', 'anetv_jkn6uvmqwh4'],\n",
       " 'fold-ind': ['3416', '3417'],\n",
       " 'startphrase': ['Members of the procession walk down the street holding small horn brass instruments. A drum line',\n",
       "  'A drum line passes by walking down the street playing their instruments. Members of the procession'],\n",
       " 'sent1': ['Members of the procession walk down the street holding small horn brass instruments.',\n",
       "  'A drum line passes by walking down the street playing their instruments.'],\n",
       " 'sent2': ['A drum line', 'Members of the procession'],\n",
       " 'gold-source': ['gold', 'gen'],\n",
       " 'ending0': ['passes by walking down the street playing their instruments.',\n",
       "  'are playing ping pong and celebrating one left each in quick.'],\n",
       " 'ending1': ['has heard approaching them.', 'wait slowly towards the cadets.'],\n",
       " 'ending2': [\"arrives and they're outside dancing and asleep.\",\n",
       "  'continues to play as well along the crowd along with the band being interviewed.'],\n",
       " 'ending3': ['turns the lead singer watches the performance.',\n",
       "  'continue to play marching, interspersed.'],\n",
       " 'label': [0, 3]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "uEBvuUSm7FD_",
   "metadata": {
    "id": "uEBvuUSm7FD_"
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# Unoptimized\n",
    "#############\n",
    "\n",
    "# import torch\n",
    "\n",
    "# ending_names = ['ending0', 'ending1', 'ending2', 'ending3']\n",
    "\n",
    "# def preprocess_function(examples):\n",
    "\n",
    "#     # repeat each first sentence four times\n",
    "#     # Results is a list with n=number of options=4 items\n",
    "#     # Each list inside contains  n=number of examples sentences\n",
    "#     first_sentences = [examples['sent1'] for _ in range(4)]\n",
    "\n",
    "#     # second sentences possible are combination of header and ending\n",
    "#     question_headers = []\n",
    "#     for first_sentence in first_sentences:\n",
    "#         first_option_temp = []\n",
    "#         for first_option in first_sentence:\n",
    "#             first_option_temp.append(f\"{first_option} [SEP]\")\n",
    "#         question_headers.append(first_option_temp)\n",
    "\n",
    "#     assert len(first_sentences) == len(question_headers), \"Dimensions don't match\"\n",
    "#     assert len(first_sentences[0]) == len(question_headers[0]), \"Dimensions don't match\"\n",
    "\n",
    "#     # Get second sentence and merge each ending with it\n",
    "#     # Results is a list with n=number of options=4 items\n",
    "#     # Each list inside contains  n=number of examples sentences\n",
    "#     second_sentences = []\n",
    "#     for ending_name in ending_names:\n",
    "#         second_sentences_temp = []\n",
    "#         for ending, start in zip(examples[ending_name], examples[\"sent2\"]):\n",
    "#             second_sentences_temp.append(start + \" \" + ending)\n",
    "#         second_sentences.append(second_sentences_temp)\n",
    "\n",
    "#     # flatten everything\n",
    "#     flat_first_sentences = [item for sublist in first_sentences for item in sublist]\n",
    "#     flat_second_sentences = [item for sublist in second_sentences for item in sublist]\n",
    "\n",
    "#     assert len(flat_second_sentences) == len(examples['sent1']) * 4, \"Dimensions don't match\"\n",
    "#     assert len(first_sentences) == len(second_sentences), \"Dimensions don't match\"\n",
    "\n",
    "#     # tokenize\n",
    "#     inputs = []\n",
    "#     for flat_first, flat_second in zip(flat_first_sentences, flat_second_sentences):\n",
    "#         inputs_temp = tokenizer(flat_first, flat_second, return_tensors='pt', truncation=True)\n",
    "#         inputs.append(inputs_temp)\n",
    "\n",
    "#     # un-flatten\n",
    "#     input_ids = []\n",
    "#     attention_masks = []\n",
    "\n",
    "#     num_lists = len(examples[\"sent1\"])\n",
    "#     for i in range(num_lists):\n",
    "#         input_id = [input[\"input_ids\"][0] for input in inputs][i::num_lists]\n",
    "#         attention_mask = [input[\"attention_mask\"][0] for input in inputs][i::num_lists]\n",
    "\n",
    "#         input_ids.append(input_id)\n",
    "#         attention_masks.append(attention_mask)\n",
    "\n",
    "#     inputs = {\n",
    "#         'input_ids': input_ids,\n",
    "#         'attention_mask': attention_masks,\n",
    "#         'labels': torch.tensor([label for label in examples[\"label\"]], dtype=torch.long)\n",
    "#     }\n",
    "\n",
    "#     return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b464ca6b",
   "metadata": {
    "id": "b464ca6b"
   },
   "outputs": [],
   "source": [
    "ending_names = ['ending0', 'ending1', 'ending2', 'ending3']\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times\n",
    "    first_sentences = [examples['sent1'] for _ in range(4)]\n",
    "\n",
    "    # Generate question headers\n",
    "    question_headers = [\n",
    "        [f\"{first_option} [SEP]\" for first_option in first_sentence]\n",
    "        for first_sentence in first_sentences\n",
    "    ]\n",
    "\n",
    "    # Generate second sentences by combining each ending with it\n",
    "    second_sentences = [\n",
    "        [start + \" \" + ending for ending, start in zip(examples[ending_name], examples[\"sent2\"])]\n",
    "        for ending_name in ending_names\n",
    "    ]\n",
    "\n",
    "    # Flatten the lists\n",
    "    flat_first_sentences = [item for sublist in first_sentences for item in sublist]\n",
    "    flat_second_sentences = [item for sublist in second_sentences for item in sublist]\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = [\n",
    "        tokenizer(flat_first, flat_second, return_tensors='pt', truncation=True)\n",
    "        for flat_first, flat_second in zip(flat_first_sentences, flat_second_sentences)\n",
    "    ]\n",
    "\n",
    "    # Extract input_ids and attention_masks\n",
    "    input_ids = [input[\"input_ids\"][0] for input in inputs]\n",
    "    attention_masks = [input[\"attention_mask\"][0] for input in inputs]\n",
    "\n",
    "    # Un-flatten the lists\n",
    "    num_lists = len(examples[\"sent1\"])\n",
    "    input_ids = [input_ids[i::num_lists] for i in range(num_lists)]\n",
    "    attention_masks = [attention_masks[i::num_lists] for i in range(num_lists)]\n",
    "\n",
    "    # Return the processed inputs\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_masks,\n",
    "        'label': torch.tensor([label for label in examples[\"label\"]], dtype=torch.long)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9Q25z-jQ-rMu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Q25z-jQ-rMu",
    "outputId": "669b4d81-5a10-416b-de54-aa7c25cb0ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4 [30, 25, 30, 28]\n"
     ]
    }
   ],
   "source": [
    "examples = datasets[\"train\"][:2]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])# output should be 2 4 [30, 25, 30, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "923093f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "923093f4",
    "outputId": "1987d1e0-faa4-4571-ec6e-558249be0b88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([  101,  2372,  1997,  1996, 14385,  3328,  2091,  1996,  2395,  3173,\n",
       "           2235,  7109,  8782,  5693,  1012,   102,  1037,  6943,  2240,  5235,\n",
       "           2011,  3788,  2091,  1996,  2395,  2652,  2037,  5693,  1012,   102]),\n",
       "  tensor([  101,  2372,  1997,  1996, 14385,  3328,  2091,  1996,  2395,  3173,\n",
       "           2235,  7109,  8782,  5693,  1012,   102,  1037,  6943,  2240,  2038,\n",
       "           2657,  8455,  2068,  1012,   102]),\n",
       "  tensor([  101,  2372,  1997,  1996, 14385,  3328,  2091,  1996,  2395,  3173,\n",
       "           2235,  7109,  8782,  5693,  1012,   102,  1037,  6943,  2240,  8480,\n",
       "           1998,  2027,  1005,  2128,  2648,  5613,  1998,  6680,  1012,   102]),\n",
       "  tensor([  101,  2372,  1997,  1996, 14385,  3328,  2091,  1996,  2395,  3173,\n",
       "           2235,  7109,  8782,  5693,  1012,   102,  1037,  6943,  2240,  4332,\n",
       "           1996,  2599,  3220, 12197,  1996,  2836,  1012,   102])],\n",
       " [tensor([  101,  1037,  6943,  2240,  5235,  2011,  3788,  2091,  1996,  2395,\n",
       "           2652,  2037,  5693,  1012,   102,  2372,  1997,  1996, 14385,  2024,\n",
       "           2652, 17852, 13433,  3070,  1998, 12964,  2028,  2187,  2169,  1999,\n",
       "           4248,  1012,   102]),\n",
       "  tensor([  101,  1037,  6943,  2240,  5235,  2011,  3788,  2091,  1996,  2395,\n",
       "           2652,  2037,  5693,  1012,   102,  2372,  1997,  1996, 14385,  3524,\n",
       "           3254,  2875,  1996, 15724,  1012,   102]),\n",
       "  tensor([  101,  1037,  6943,  2240,  5235,  2011,  3788,  2091,  1996,  2395,\n",
       "           2652,  2037,  5693,  1012,   102,  2372,  1997,  1996, 14385,  4247,\n",
       "           2000,  2377,  2004,  2092,  2247,  1996,  4306,  2247,  2007,  1996,\n",
       "           2316,  2108, 10263,  1012,   102]),\n",
       "  tensor([  101,  1037,  6943,  2240,  5235,  2011,  3788,  2091,  1996,  2395,\n",
       "           2652,  2037,  5693,  1012,   102,  2372,  1997,  1996, 14385,  3613,\n",
       "           2000,  2377, 10998,  1010, 25338,  1012,   102])]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hKizHUiGXgj-",
   "metadata": {
    "id": "hKizHUiGXgj-"
   },
   "source": [
    "We can now apply our function to all the examples in the dataset. We use the `map` method to apply the function on all the elements of all the splits in the dataset (training, validation, and testing).\n",
    "Note that we passed `batched=True` to leverage the fast tokenizer and use multi-threading to process the texts in batches concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9Wau4GZsXcvE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "174d000d421e4299ab33e7b3e41d70f3",
      "c27e8811bbb143ca858e8aa11b36c865",
      "feb8371c04ac40afa3c011415ed07bd2",
      "36b46aec1888489e8e82915739d7e941",
      "f2a5311797d84b30a515ec772031cb96",
      "b37a253d25d745dcb2859b6781a969d3",
      "706e66897bfe40c996206711386acccf",
      "0b5abc95fcb041ab8402a13d925292a0",
      "a6f4f537543b407c9c22539fac062caf",
      "19614ee0b7a140969c83b3ff0b5cad6c",
      "156559c29199483d82f93035348cf40a",
      "3bfdbd6d26a9447eaa612d04cd0e46cc",
      "048757572a7a4255b90a3013e49fd169",
      "957e27222bec433ca19262825b276359",
      "a0226be9cf934af999b986c51e01cd3c",
      "190d3cbed2384ca89c211f290fe2c668",
      "74b182da3443406c9dcf1c91310ac2b7",
      "bb0eb5bcab934a05a0a774b8940f4b0f",
      "1c921f44296f4fbbba790ca690618120",
      "cd14944f9a054c3d95d195f68df593f0",
      "8cf76e72149b492db2a131fcfe28b562",
      "d951bec8d7c049c69b37412b26806912",
      "c8a40c3a9ae64ddcbfd1d11378cfc8c9",
      "090ee45b51354baeb27a1818a3889c34",
      "c2dbaa670dc042528573f912ae400329",
      "3097c731c8eb411db10609a4fc9eb2cd",
      "a49a2787e46a4a29b85d760b1c15d645",
      "35b61a49f19e4caa98e527159194341f",
      "cbba9215e5494575be6159e003995891",
      "af8f18e7d2754934bf82e22260df1fb2",
      "45eb191b9ac14eff80b12e837a87fbf7",
      "9fda181650fd4908999a30892431b3be",
      "6fd644afa33a4536956f50a6b1d17e48"
     ]
    },
    "id": "9Wau4GZsXcvE",
    "outputId": "1cee28ce-18e5-4a02-e807-887bf0904720"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174d000d421e4299ab33e7b3e41d70f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73546 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfdbd6d26a9447eaa612d04cd0e46cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20006 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a40c3a9ae64ddcbfd1d11378cfc8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_datasets = datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G69L2vtPR8uV",
   "metadata": {
    "id": "G69L2vtPR8uV"
   },
   "source": [
    "Our dataset is still not converted to tensors and not padded. This is the job of the `data collator`. A data collator takes a list of examples and converts them to a batch.\n",
    "There is no data collator in the Hugging Face default library that works on our specific problem. We thus need to write our own one. In this collator:\n",
    "\n",
    "*  All the inputs/attention masks are flattened.\n",
    "* A flattened list is passed to the `tokenizer.pad ` method to apply dynamic padding to pad inputs to the maximum length in the batch. Output will be the size of `(batch_size * 4) x seq_length`.\n",
    "* Everything needs to be unflattened for the output of the data collator.\n",
    "* `input_ids` and `labels` should be returned as tensors.\n",
    "* The output is a dictionary called `batch` that contains features needed for training (`input_ids`, `attention_mask`, `label`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "r_3SvkBOSgZx",
   "metadata": {
    "id": "r_3SvkBOSgZx"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class MultipleChoiceDataCollator:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "        if len(features[0])>len(accepted_keys):\n",
    "          features=[{k: v for k, v in i.items() if k in accepted_keys} for i in features]\n",
    "\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "\n",
    "        # Flatten Features\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Unflatten and add labels as tensors\n",
    "\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "-oKeJUr_UBUV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oKeJUr_UBUV",
    "outputId": "7904f8d8-c6cb-4ac1-adbd-49bbcc4f5dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 35])\n",
      "torch.Size([2, 4, 35])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(2)]\n",
    "\n",
    "batch = MultipleChoiceDataCollator(tokenizer)(features)\n",
    "print(batch[\"input_ids\"].shape)\n",
    "print(batch[\"attention_mask\"].shape)\n",
    "print(batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "glDO1KfaVXoX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glDO1KfaVXoX",
    "outputId": "86194ccd-d41e-49e4-8a68-230cb775b70f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  2372,  1997,  1996, 14385,  3328,  2091,  1996,  2395,  3173,\n",
      "         2235,  7109,  8782,  5693,  1012,   102,  1037,  6943,  2240,  5235,\n",
      "         2011,  3788,  2091,  1996,  2395,  2652,  2037,  5693,  1012,   102,\n",
      "            0,     0,     0,     0,     0])\n",
      "[CLS] members of the procession walk down the street holding small horn brass instruments. [SEP] a drum line passes by walking down the street playing their instruments. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([  101,  2372,  1997,  1996, 14385,  3328,  2091,  1996,  2395,  3173,\n",
      "         2235,  7109,  8782,  5693,  1012,   102,  1037,  6943,  2240,  2038,\n",
      "         2657,  8455,  2068,  1012,   102,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "[CLS] members of the procession walk down the street holding small horn brass instruments. [SEP] a drum line has heard approaching them. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([  101,  2372,  1997,  1996, 14385,  3328,  2091,  1996,  2395,  3173,\n",
      "         2235,  7109,  8782,  5693,  1012,   102,  1037,  6943,  2240,  8480,\n",
      "         1998,  2027,  1005,  2128,  2648,  5613,  1998,  6680,  1012,   102,\n",
      "            0,     0,     0,     0,     0])\n",
      "[CLS] members of the procession walk down the street holding small horn brass instruments. [SEP] a drum line arrives and they're outside dancing and asleep. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([  101,  2372,  1997,  1996, 14385,  3328,  2091,  1996,  2395,  3173,\n",
      "         2235,  7109,  8782,  5693,  1012,   102,  1037,  6943,  2240,  4332,\n",
      "         1996,  2599,  3220, 12197,  1996,  2836,  1012,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "[CLS] members of the procession walk down the street holding small horn brass instruments. [SEP] a drum line turns the lead singer watches the performance. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "  print(batch[\"input_ids\"][0][i])\n",
    "  print(tokenizer.decode(batch[\"input_ids\"][0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WD4IjgtLYCLa",
   "metadata": {
    "id": "WD4IjgtLYCLa"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 2.1}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b209ff",
   "metadata": {
    "id": "b3b209ff"
   },
   "source": [
    "### Subtask 2: Fine-tuning a Hugging Face Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2290d8",
   "metadata": {
    "id": "3b2290d8"
   },
   "source": [
    "To fine-tune our model, we first need to download the correct architecture from Hugging Face. Import the correct class for this task and download the pre-trained checkpoint for the base class from `distilbert-base-uncased`. Note that the weights in the classification head are initialized at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a130f71d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212,
     "referenced_widgets": [
      "e8e820701f234441bced37d987e8add4",
      "5739a7692748402c913c6e28a8354903",
      "26e98c12c57f4731948ec3d0c59cd3a8",
      "3815a63aab344a768b7ef1565989b952",
      "59106f669b284e96acc2e8e37cadca25",
      "62de7ece5ec34e44aa30c57077da9e8d",
      "f4612458689a4184a02334faa218165e",
      "dbe26119eed94ab0a7e775e3070eefcc",
      "405cfa82a5b14a35aba8dde062df62fa",
      "bcf9ac8f07ab427ab78cfe09dafcd152",
      "6f4e3198f914455c96d85f1134ae8ad0"
     ]
    },
    "id": "a130f71d",
    "outputId": "5c9f6b2c-d857-4284-e21c-5cbd2ace39f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e820701f234441bced37d987e8add4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model_hf =  AutoModelForMultipleChoice.from_pretrained(\"distilbert-base-uncased\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680e8a4",
   "metadata": {
    "id": "7680e8a4"
   },
   "source": [
    "Next, we need to define our `Trainer` and pass in the correct `TrainingArguments` (a class that contains all the attributes to customize the training). Define a `TrainingArguments` that\n",
    "\n",
    "\n",
    "* creates an output directory `distilbert-base-uncased-swag` to save the checkpoints and logs.\n",
    "*   evaluates the model on the validation set after the `300` steps.\n",
    "* a checkpoint should be saved after each `600` step and no more than 2 checkpoints should be saved in total.\n",
    "* the random seed for training is `77`.\n",
    "* batch size for training and evaluation: `48` (if you are running out of memory, feel free to change this setting but indicate it as a comment in your notebook, on a T4 GPU from google colab this takes about `13.2GB` of `15.0GB`).\n",
    "* train for `1800` steps with a learning rate of `5e-5`, and add weight decay of `0.01` to the optimizer.\n",
    "* the trainer should remove the columns from the data that are not used by the model.\n",
    "* The final checkpoint should be the checkpoint that had the best overall validation metric not necessarily the last checkpoint.\n",
    "\n",
    "**Note:** Please use GPU for to train your model. If on colab, you can use T4 GPU for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "224f27ef",
   "metadata": {
    "id": "224f27ef"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "output_directory = \"distilbert-base-uncased-swag\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_directory,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=300,\n",
    "    save_total_limit=2,\n",
    "    save_steps=600,\n",
    "    seed=77,\n",
    "    per_device_train_batch_size=48,\n",
    "    per_device_eval_batch_size=48,\n",
    "    max_steps=1800,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    remove_unused_columns=True,\n",
    "    logging_dir=output_directory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29330eed",
   "metadata": {
    "id": "29330eed"
   },
   "source": [
    "Before we initialize the `Trainer`, we create a function that tells the trainer how to compute the metrics from the predictions. Fill the `compute_metrics` function to compute the accuracy based on the `predictions`. This object contains the prediction of the model, as well as the ground truth labels.\n",
    "\n",
    "**Hint 1:** Keep in mind that the output of this function should be a dictionary containing the metric name and value.\n",
    "\n",
    "**Hint 2:** Consider the shape of the example input. This is similar to the logits produced by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "514aafd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "069903334f5a473196d989203e08a270",
      "c87c6653e0b840f08fa6f5d32ee73cbe",
      "1c1c02687c7b46dc932649ad6b76c09f",
      "d21f7ffc85234dc580c3e426c1bd8885",
      "f6c484ad77f74a00b68a8108085fcc0f",
      "f75547ba1b484fa096b2a601c6e05cb7",
      "84903426242f4928b95fb5bc768dcc25",
      "037ac3bd40fd4a8493a54b0ad274ff34",
      "886d55f8441d40b0b1ba1b85eff3a7d1",
      "fef9fd747cb84e3783dd41cc90fb7d4d",
      "bc68c23d359a4f4ba577c5aa55265d46"
     ]
    },
    "id": "514aafd2",
    "outputId": "98d3b4f0-ce4f-4d78-e8c5-4d5023030603"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069903334f5a473196d989203e08a270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "#def compute_metrics(predictions):\n",
    "#    logits, labels = predictions[0], predictions[1]\n",
    "#\n",
    "#    preds = np.argmax(logits, axis=-1)\n",
    "#    accuracy = (preds == labels).mean()\n",
    "\n",
    "#    return {\"accuracy\": accuracy}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "569cbea5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "569cbea5",
    "outputId": "3494768c-f718-4b2b-b1cc-cd40674d313b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=np.array([[0.9,0.2,0,0],\n",
    "                [0.2,0.2,0.9,0.1],\n",
    "                [0.2,0.9,0,0],\n",
    "                [0.2,0.1,0.8,0],\n",
    "                [0.9,0.1,0.8,0],\n",
    "                [0.2,1,0.4,0],\n",
    "                [0.2,1,0.4,0.9],\n",
    "                [1,0.1,0.4,0.3],\n",
    "                [0.1,0.1,0.9,0.3],\n",
    "                [0.1,0.1,0.2,1]])\n",
    "label_ids=np.array([0,3,1,2,0,1,3,0,2,3])\n",
    "compute_metrics((preds,label_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b585b5",
   "metadata": {
    "id": "51b585b5"
   },
   "source": [
    "Now it's time to pass everything to a `Trainer` object to start the training process. Initialize a `Trainer` object and pass all the necessary information, keep in mind that we also have the optional metric computation and that we tend to run an evaluation on the validation set during training. The training should take around 30 min on Google Colab T4 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ac85ce8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ac85ce8",
    "outputId": "c8791147-5512-4d20-8f31-ebc8c34cf090"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9de28371",
   "metadata": {
    "id": "9de28371"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_hf.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_datasets[\"train\"],  # must be replaced with processed data from 2.1\n",
    "    eval_dataset=encoded_datasets[\"validation\"],    # must be replace with processed data from 2.1\n",
    "    data_collator=MultipleChoiceDataCollator(tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53a7fc29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "53a7fc29",
    "outputId": "135789b3-491d-4670-b5b0-25a22566cd94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 10:34, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=0.1932568359375, metrics={'train_runtime': 634.8097, 'train_samples_per_second': 136.104, 'train_steps_per_second': 2.835, 'total_flos': 5678117920017504.0, 'train_loss': 0.1932568359375, 'epoch': 1.17})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() # should take around 30 min on Google Colab T4 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625340cc",
   "metadata": {
    "id": "625340cc"
   },
   "source": [
    "Save the model in `distilbert-base-uncased-swag/final_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1abf674f",
   "metadata": {
    "id": "1abf674f"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"distilbert-base-uncased-swag/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "oTOZ4wtJSNLx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTOZ4wtJSNLx",
    "outputId": "1c34662f-497d-482c-97b5-3b5e206eb718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/distilbert-base-uncased-swag/ (stored 0%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1800/ (stored 0%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1800/optimizer.pt (deflated 100%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1800/config.json (deflated 44%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1800/trainer_state.json (deflated 76%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1800/rng_state.pth (deflated 25%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1800/scheduler.pt (deflated 56%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1800/training_args.bin (deflated 51%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1800/model.safetensors (deflated 100%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1200/ (stored 0%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1200/optimizer.pt (deflated 100%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1200/config.json (deflated 44%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1200/trainer_state.json (deflated 71%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1200/rng_state.pth (deflated 25%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1200/scheduler.pt (deflated 55%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1200/training_args.bin (deflated 51%)\n",
      "  adding: content/distilbert-base-uncased-swag/checkpoint-1200/model.safetensors (deflated 100%)\n",
      "  adding: content/distilbert-base-uncased-swag/final_model/ (stored 0%)\n",
      "  adding: content/distilbert-base-uncased-swag/final_model/config.json (deflated 44%)\n",
      "  adding: content/distilbert-base-uncased-swag/final_model/training_args.bin (deflated 51%)\n",
      "  adding: content/distilbert-base-uncased-swag/final_model/model.safetensors (deflated 100%)\n",
      "  adding: content/distilbert-base-uncased-swag/events.out.tfevents.1704444416.b6a295c15285.1066.1 (deflated 60%)\n",
      "  adding: content/distilbert-base-uncased-swag/events.out.tfevents.1704443385.b6a295c15285.1066.0 (deflated 57%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/assignment3.zip /content/distilbert-base-uncased-swag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "i0U20YWv0stl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i0U20YWv0stl",
    "outputId": "7ea976cf-389a-4d24-e6d0-53ee5b96bb26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForMultipleChoice\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.35.2\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hf.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6df3043",
   "metadata": {
    "id": "c6df3043"
   },
   "source": [
    "Look at the saved files and answer the following questions (it is possible to answer these questions by writing some code, but we want you to explore the saved files):\n",
    "\n",
    "**Question:**\n",
    "\n",
    "\n",
    "1.   What is the vocabulary id for the `[CLS]` and `[MASK]` tokens?\n",
    "2.   What is the dropout probability for the attention layer?\n",
    "\n",
    "**Dropout:** With dropout, certain nodes are set to the value zero in a training run, i.e. removed from the network. Thus, they have no influence on the prediction and also in the backpropagation. Thus, a new, slightly modified network architecture is built in each run and the network learns to produce good predictions without certain inputs. Read more [here](https://databasecamp.de/en/ml/dropout-layer-en).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9412e7",
   "metadata": {
    "id": "8c9412e7"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "`\n",
    "1. [CLS] = 101 and [MASK] = 103\n",
    "2. attention dropout prob. = 0.1\n",
    "\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017d569",
   "metadata": {
    "id": "b017d569"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 2.2}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vAcJQfpHAvbR",
   "metadata": {
    "id": "vAcJQfpHAvbR"
   },
   "source": [
    "### Subtask 3: Fine-tune a Custom Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QT3cbQO-wnio",
   "metadata": {
    "id": "QT3cbQO-wnio"
   },
   "source": [
    "In this case, we were lucky that Hugging Face had a pre-implemented architecture available for us to use. However, that is not always the case. Moreover, we might want to experiment beyond the default architectures to find a suitable one for a task. Therefore, it is important to learn to extend the Hugging Face models and train a custom model. The good news is that except for the model architecture the rest of the code can remain as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G2RtNQewxG2O",
   "metadata": {
    "id": "G2RtNQewxG2O"
   },
   "source": [
    "Design a model for multiple choice model as follows:\n",
    "\n",
    "\n",
    "1.   the config file for a feature extractor (must be a distilbert type) is  passed during initialization. The config file determines which model is used for feature extraction.\n",
    "2.   From the `last_hidden_state` of the feature extractor, choose the `[CLS]` embedding (first one). This embedding is used as the compressed representation of first and second sentences. During pre-training it is used  for classifying whether these two sentences follow one another, making it a good candidate for our task.\n",
    "3. `[CLS]` embedding is passed through a linear layer **that does not change the size of the embedding** and is passed through a tanh nonlinearity.\n",
    "4. The output of tanh is passed through a dropout layer, where the dropout probability is the same as the dropout probability used for the `distilbert` model used as feature extractor.\n",
    "5. The output of the previous stage is fed into another linear layer that shrinks the size of the embedding dimension to a quarter of the original size, e.g., if the embedding size is 12, the new embedding dimension is 3.\n",
    "6. The output is followed by another dropout layer (you can use the one from stage 4).\n",
    "7. Finally, a binary classifier is applied to determine the probability of sentence 1 being followed by sentence 2.\n",
    "8. the cross-entropy loss is used to compute the loss.\n",
    "\n",
    "**Hint:** Keep in mind that for a 4 choice system, you classify each of the four solutions independently. However, the final output should group the four logits together. For example, if input ids have the shape `[2, 4, 35]` (batch size=2, num choices=4, seq len=35), then the logits have the `[2, 4]` and labels have the dimension `[2, 1]`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "tedXQykJ7gEq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tedXQykJ7gEq",
    "outputId": "0b34acac-f988-4242-f287-5c45a908c53f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./distilbert-base-uncased-swag.zip\n",
      "  inflating: __MACOSX/._distilbert-base-uncased-swag  \n",
      "  inflating: distilbert-base-uncased-swag/events.out.tfevents.1704444416.b6a295c15285.1066.1  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/._events.out.tfevents.1704444416.b6a295c15285.1066.1  \n",
      "  inflating: distilbert-base-uncased-swag/events.out.tfevents.1704443385.b6a295c15285.1066.0  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/._events.out.tfevents.1704443385.b6a295c15285.1066.0  \n",
      "   creating: distilbert-base-uncased-swag/checkpoint-1200/\n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/._checkpoint-1200  \n",
      "   creating: distilbert-base-uncased-swag/checkpoint-1800/\n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/._checkpoint-1800  \n",
      "   creating: distilbert-base-uncased-swag/final_model/\n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/._final_model  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1200/model.safetensors  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1200/._model.safetensors  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1200/rng_state.pth  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1200/._rng_state.pth  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1200/optimizer.pt  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1200/._optimizer.pt  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1200/config.json  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1200/._config.json  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1200/scheduler.pt  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1200/._scheduler.pt  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1200/training_args.bin  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1200/._training_args.bin  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1200/trainer_state.json  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1200/._trainer_state.json  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1800/model.safetensors  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1800/._model.safetensors  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1800/rng_state.pth  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1800/._rng_state.pth  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1800/optimizer.pt  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1800/._optimizer.pt  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1800/config.json  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1800/._config.json  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1800/scheduler.pt  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1800/._scheduler.pt  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1800/training_args.bin  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1800/._training_args.bin  \n",
      "  inflating: distilbert-base-uncased-swag/checkpoint-1800/trainer_state.json  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/checkpoint-1800/._trainer_state.json  \n",
      "  inflating: distilbert-base-uncased-swag/final_model/model.safetensors  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/final_model/._model.safetensors  \n",
      "  inflating: distilbert-base-uncased-swag/final_model/config.json  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/final_model/._config.json  \n",
      "  inflating: distilbert-base-uncased-swag/final_model/training_args.bin  \n",
      "  inflating: __MACOSX/distilbert-base-uncased-swag/final_model/._training_args.bin  \n"
     ]
    }
   ],
   "source": [
    "!unzip ./distilbert-base-uncased-swag.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "KUZOp8o1Pb9X",
   "metadata": {
    "id": "KUZOp8o1Pb9X"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel,BertConfig,DistilBertConfig,PretrainedConfig,PreTrainedModel,DistilBertPreTrainedModel\n",
    "from torch import nn, Tensor\n",
    "from typing import Optional\n",
    "\n",
    "class CustomMultipleChoice(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.dense = nn.Linear(config.dim, config.dim)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.dense2 = nn.Linear(config.dim, config.dim // 4)\n",
    "        self.dropout2 = nn.Dropout(config.dropout)\n",
    "        self.classifier = nn.Linear(config.dim // 4, 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[Tensor] = None,\n",
    "        attention_mask: Optional[Tensor] = None,\n",
    "        labels: Optional[Tensor] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_ids: input sentences converted to ids\n",
    "        attention_mask: the attention mask\n",
    "        labels:  Labels for computing the multiple choice classification loss.\n",
    "        Indices should be in `[0, ...,num_choices-1]` where `num_choices` is the\n",
    "        size of the second dimension of the input tensors.\n",
    "        \"\"\"\n",
    "\n",
    "        num_choices = input_ids.shape[1]\n",
    "\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        # Choose the [CLS] embedding\n",
    "        cls_embedding = last_hidden_states[:, 0, :]\n",
    "\n",
    "        # Apply the linear layer, tanh, and dropout\n",
    "        x = self.dense(cls_embedding)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Apply the second linear layer, dropout, and the final classifier\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x)\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        reshaped_logits = logits.view(-1, num_choices)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(reshaped_logits, labels.view(-1))\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": reshaped_logits}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IXFcGJQPgjil",
   "metadata": {
    "id": "IXFcGJQPgjil"
   },
   "source": [
    "Initialize the feature extractor with `distilbert-base-uncased` and create your custome model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "GHCT0HdYKk5p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GHCT0HdYKk5p",
    "outputId": "f82b44db-9b8c-4899-ec65-2e5f308b0978"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "###your code ###\n",
    "config = AutoConfig.from_pretrained(\"distilbert-base-uncased\")\n",
    "model_custom = CustomMultipleChoice(config)\n",
    "###your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "_genDEZbgsJd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_genDEZbgsJd",
    "outputId": "35c31174-31f0-4bb7-8935-c1b0098fc16a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense.weight torch.Size([768, 768])\n",
      "dense.bias torch.Size([768])\n",
      "dense2.weight torch.Size([192, 768])\n",
      "dense2.bias torch.Size([192])\n",
      "classifier.weight torch.Size([1, 192])\n",
      "classifier.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_custom.named_parameters():\n",
    "    if param.requires_grad and not name.startswith(\"distilbert.\"):\n",
    "        print(name, param.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yyD-ivMzh5P7",
   "metadata": {
    "id": "yyD-ivMzh5P7"
   },
   "source": [
    "We keep the same training arguments but change the directory in which we save the model logs, the directory in which we save the model output and the name of the run, to `custom_model`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aX5Jw-Eubo56",
   "metadata": {
    "id": "aX5Jw-Eubo56"
   },
   "outputs": [],
   "source": [
    "###your code ###\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "output_directory = \"custom-swag\"\n",
    "\n",
    "training_args_custom = TrainingArguments(\n",
    "    output_dir=output_directory,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=300,\n",
    "    save_total_limit=2,\n",
    "    save_steps=600,\n",
    "    seed=77,\n",
    "    per_device_train_batch_size=48,\n",
    "    per_device_eval_batch_size=48,\n",
    "    max_steps=1800,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    remove_unused_columns=True,\n",
    "    logging_dir=output_directory,\n",
    ")\n",
    "\n",
    "###your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0sCoDrINiO0j",
   "metadata": {
    "id": "0sCoDrINiO0j"
   },
   "source": [
    "Initialize the trainer for training the custom model.The training should take around 30 min on Google Colab T4 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "s1_2hwKabo8p",
   "metadata": {
    "id": "s1_2hwKabo8p"
   },
   "outputs": [],
   "source": [
    "trainer_custom = Trainer(\n",
    "    model=model_custom.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_datasets[\"train\"],  # must be replaced with processed data from 2.1\n",
    "    eval_dataset=encoded_datasets[\"validation\"],    # must be replace with processed data from 2.1\n",
    "    data_collator=MultipleChoiceDataCollator(tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "###your code ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "btobBRSZbo_O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "btobBRSZbo_O",
    "outputId": "270deca0-f330-4e38-a8c3-d47c55180bfb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 09:49, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.686900</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.686900</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.246576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=0.190810546875, metrics={'train_runtime': 591.4685, 'train_samples_per_second': 146.077, 'train_steps_per_second': 3.043, 'total_flos': 5678117920017504.0, 'train_loss': 0.190810546875, 'epoch': 1.17})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()# should take around 30 min on Colab T4 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B9Fi0ZZYjIdJ",
   "metadata": {
    "id": "B9Fi0ZZYjIdJ"
   },
   "source": [
    "Save the model in `custom_model/final_model`. Note that with the custom model, you need to save it without the help of the trainer. The trainer would save the configuration but since this model is not a registered Hugging Face model only the base model would be saved. Loading the model weights is also effected by this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "rvb3xo-ibpB9",
   "metadata": {
    "id": "rvb3xo-ibpB9"
   },
   "outputs": [],
   "source": [
    "###your code ###\n",
    "trainer.save_model(\"custom_model/final_model\")\n",
    "###your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "yJ2a8xUf6hdN",
   "metadata": {
    "id": "yJ2a8xUf6hdN"
   },
   "outputs": [],
   "source": [
    "#!zip -r /content/assignment3_all.zip /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UxU3fivlihOX",
   "metadata": {
    "id": "UxU3fivlihOX"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 2.3}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A_M4MSb0kcBP",
   "metadata": {
    "id": "A_M4MSb0kcBP"
   },
   "source": [
    "### Subtask 4: Evaluation and Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4oO0XKbbmzzW",
   "metadata": {
    "id": "4oO0XKbbmzzW"
   },
   "source": [
    "Many times you do not perform the final evaluation right after training, but load the checkpoints and evaluate them on the fly. To this end, load the two models from  disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ptE1gxKwa843",
   "metadata": {
    "id": "ptE1gxKwa843"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMultipleChoice,AutoConfig\n",
    "### your code ###\n",
    "model_hf = AutoModelForMultipleChoice.from_pretrained(\"/content/distilbert-base-uncased-swag/final_model\")\n",
    "model_custom = AutoModelForMultipleChoice.from_pretrained(\"/content/custom_model/final_model\", config=config)\n",
    "### your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Am9mUOXHbwC9",
   "metadata": {
    "id": "Am9mUOXHbwC9"
   },
   "source": [
    "To evaluate the data we load the validation split using a data loader and our previously defined data collator. Note that although we had a test split we cannot use it, since there are no labels available for this split (you can check the data to confirm this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "jhBq38xadGvA",
   "metadata": {
    "id": "jhBq38xadGvA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "\n",
    "eval_dataloader = DataLoader(encoded_datasets[\"validation\"], batch_size=64, collate_fn=MultipleChoiceDataCollator(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ctcpVXXrl8Wd",
   "metadata": {
    "id": "ctcpVXXrl8Wd"
   },
   "source": [
    "To make things easier, let's use the `evaluate` library from Hugging Face to compute the accuracy metric. Here we load `accuracy` from the `evaluate` library two times, one for the custom model and one for the Hugging Face model. Further, we put the models on eval mode. Complete the code for evaluation using the capabilities of the `evaluate` library to simultaneously compute the metric for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "Q5ZskVcHBvls",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q5ZskVcHBvls",
    "outputId": "8b2e1103-6222-481e-ee5f-eb5676d208a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Evaluation module inputs don't match the expected format.\nExpected format: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)},\nInput predictions: tensor([[nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan]], device='cuda:0'),\nInput references: tensor([2, 2, 2, 2, 2, 0, 0, 2, 1, 0, 2, 0, 2, 0, 3, 0, 3, 3, 1, 0, 0, 2, 2, 2,\n        2, 3, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 3, 1, 3, 3, 2, 3, 1, 2, 0, 2, 2, 0,\n        1, 0, 3, 2, 3, 2, 3, 1, 1, 0, 3, 3, 3, 1, 1, 3], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-bb617e2b29bb>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Update the accuracy metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0macc_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0macc_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreshaped_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Get the final accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, prediction, reference, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m             )\n\u001b[1;32m    583\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror_msg_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_infer_feature_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Evaluation module inputs don't match the expected format.\nExpected format: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)},\nInput predictions: tensor([[nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan]], device='cuda:0'),\nInput references: tensor([2, 2, 2, 2, 2, 0, 0, 2, 1, 0, 2, 0, 2, 0, 3, 0, 3, 3, 1, 0, 0, 2, 2, 2,\n        2, 3, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 3, 1, 3, 3, 2, 3, 1, 2, 0, 2, 2, 0,\n        1, 0, 3, 2, 3, 2, 3, 1, 1, 0, 3, 3, 3, 1, 1, 3], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "metric_dict = {\"custom\": evaluate.load(\"accuracy\"), \"hf\": evaluate.load(\"accuracy\")}\n",
    "models_dict = {\"custom\": model_custom, \"hf\": model_hf}\n",
    "num_choices = 4\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "for batch in tqdm(eval_dataloader, total=len(eval_dataloader)):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "\n",
    "    for name, model in models_dict.items():\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        logits = outputs['logits']\n",
    "        # Reshape logits\n",
    "        reshaped_logits = logits.view(-1, num_choices)\n",
    "        # Update the accuracy metric\n",
    "        acc_metric = metric_dict[name]\n",
    "        acc_metric.add(predictions=reshaped_logits, references=labels.view(-1))\n",
    "\n",
    "# Get the final accuracy\n",
    "acc_hf = metric_dict[\"hf\"].compute()\n",
    "acc_custom = metric_dict[\"custom\"].compute()\n",
    "\n",
    "print(\"Hugging Face Model Accuracy:\", acc_hf)\n",
    "print(\"Custom Model Accuracy:\", acc_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2542171",
   "metadata": {},
   "source": [
    "<h4 style=\"color: green\">\n",
    "Note: The code throws an error, but it should still be correct, the issue is probably only related to the loading of the models\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HQC6grKnuSgZ",
   "metadata": {
    "id": "HQC6grKnuSgZ"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 2.4}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "cross-feedback comment section\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_sO-H1PVMSsp",
   "metadata": {
    "id": "_sO-H1PVMSsp"
   },
   "source": [
    "## **Task 3: Encoder-Decoder Architecture** (5 + 2 + 2 + 5 = 14 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W42O89DrMZNj",
   "metadata": {
    "id": "W42O89DrMZNj"
   },
   "source": [
    "We explored an encoder-based model (BERT) in the previous exercise. In this task, we look at another family of transformer architectures, the encoder-decoder. We use the [T5](https://arxiv.org/pdf/1910.10683.pdf) model, presented by Raffel et al.  T5 is an encoder-decoder architecture pre-trained on a multi-task mixture of unsupervised and supervised tasks. In this task, we set up a fine-tuning example for question answering using the [SQUAD](https://huggingface.co/datasets/squad) dataset. Since the actual fine-tuning is time-consuming and computational intensive for inference, we use an already pre-trained model. The main goal is to introduce you to the structure of the fine-tuning and its simplicity with the Hugging Face framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-oSCvS6wwef",
   "metadata": {
    "id": "c-oSCvS6wwef"
   },
   "source": [
    "To fine-tune the BERT-based models, we usually add a task-specific head. On the other hand, T5 converts all NLP problems into a text-to-text format.  \n",
    "It is trained using teacher forcing, meaning that we require an input sequence and a corresponding target sequence.\n",
    "\n",
    "\n",
    "1.   The input sequence is fed to the model using `input_ids` from the tokenizer.\n",
    "2.   The target sequence is shifted to the right, i.e., prepended by a start-sequence token and fed to the decoder using the `decoder_input_ids` (input_ids of the encoded target sequence). The target sequence is appended by EOS (end of the sentence) to denote the end of a generation and corresponds to the `labels`.\n",
    "3. The task prefix defines what task is expected of T5. For example, we prepend the input sequence with `translate English to German: ` before encoding the input to tell the model to translate. T5 already has a set of pre-defined task prefixes, and it is best to stick to those since they were used during pre-training. With enough training data, you can also introduce your own custom task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sg6jO_SeznX3",
   "metadata": {
    "id": "sg6jO_SeznX3"
   },
   "source": [
    "In contrast to the encoder model, where only a single `max_length` is required, for encoder-decoder architectures, one typically defines a `max_source_length` and `max_target_length`, which determine the maximum length of the input and output sequences, respectively. We must also ensure that the padding ID of the `labels` is not taken into account by the loss function. This can be done by replacing them with `-100`, which is the `ignore_index` of the `CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0zLQjAxlNzJ_",
   "metadata": {
    "id": "0zLQjAxlNzJ_"
   },
   "source": [
    "### Subtask 1: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7hx8LCNjBlvi",
   "metadata": {
    "id": "7hx8LCNjBlvi"
   },
   "source": [
    "We first start by loading the dataset from Hugging Face hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "FjujP1xsuQGX",
   "metadata": {
    "id": "FjujP1xsuQGX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "datasets_squad = load_dataset(\"squad\")\n",
    "datasets_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "x7VEY66uEEeY",
   "metadata": {
    "id": "x7VEY66uEEeY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context ----> Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "question ----> To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "answers ----> {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n"
     ]
    }
   ],
   "source": [
    "print(\"context ---->\" ,datasets_squad[\"train\"][0][\"context\"])\n",
    "print(\"question ---->\",datasets_squad[\"train\"][0][\"question\"])\n",
    "print(\"answers ---->\",datasets_squad[\"train\"][0][\"answers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5OrYB9xBByvj",
   "metadata": {
    "id": "5OrYB9xBByvj"
   },
   "source": [
    "Now let's load the needed pre-trained tokenizer for `t5-small`, which is the smallest T5 model. Set the maximum sequence length to `512`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "WwYjYXASMg_z",
   "metadata": {
    "id": "WwYjYXASMg_z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "### your code ###\n",
    "from transformers import AutoTokenizer\n",
    "t5_tokenizer =  AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "### your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FvN50codiJXR",
   "metadata": {
    "id": "FvN50codiJXR"
   },
   "source": [
    "The next step is to pre-process the dataset using the tokenizer to convert the sequences to IDs and add the special tokens.\n",
    "T5 is based on the SentencePiece tokenizer, and the end of sentence token is denoted by `</s>`.\n",
    "Complete the function `add_eos_to_examples` to format the input and target sequence. Your input as `input_text` should have the format `question:{question_text} context:{context_text} <EOS_Token>` and your target as `target_text` should have the format `{answer_text} <EOS_Token>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "xbisNi2-MYC2",
   "metadata": {
    "id": "xbisNi2-MYC2"
   },
   "outputs": [],
   "source": [
    "def add_eos_to_examples(example):\n",
    "    ### your code ###\n",
    "    example['input_text'] = f\"question: {example['question']} context: {example['context']} </s>\"\n",
    "    example['target_text'] = f\"{''.join(example['answers']['text'])} </s>\"\n",
    "    ### your code ###\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l1cI8qcCIcXM",
   "metadata": {
    "id": "l1cI8qcCIcXM"
   },
   "source": [
    "Use the `map` function to process the data, and do not set the `batched` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Z7Q2TH_AIJDp",
   "metadata": {
    "id": "Z7Q2TH_AIJDp"
   },
   "outputs": [],
   "source": [
    "### your code ###\n",
    "encoded_squad = datasets_squad.map(add_eos_to_examples)\n",
    "### your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "FgqckdGNDWNp",
   "metadata": {
    "id": "FgqckdGNDWNp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: What is in front of the Notre Dame Main Building? context: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary. </s>\n",
      "a copper statue of Christ </s>\n"
     ]
    }
   ],
   "source": [
    "print(encoded_squad[\"train\"][1][\"input_text\"])\n",
    "print(encoded_squad[\"train\"][1][\"target_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UqK9_TtLFZrU",
   "metadata": {
    "id": "UqK9_TtLFZrU"
   },
   "source": [
    "Complete the function `convert_to_features` that takes in the examples from the dataset and tokenizes them using the T5 tokenizer. However, our answers in this dataset are relatively short and do not require `512` tokens, in contrast to the input sequence which is a combination of question and context paragraphs and is usually long. To this end, we want to truncate the input sequence at `512` and the target sequence at `16`. If any input or target is smaller than the specified length, make sure you pad them. Finally, convert everything to PyTorch tensors to be easily used by the data collator and place them in the dictionary `encodings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4yPglRvTEg_p",
   "metadata": {
    "id": "4yPglRvTEg_p"
   },
   "outputs": [],
   "source": [
    "def convert_to_features(examples):\n",
    "    ### your code ###\n",
    "    # Trunicate input sequence at 512 tokens and target sequence at 16 tokens. If target smaller than 16 tokens, pad with -100\n",
    "    input_encodings = t5_tokenizer(examples['input_text'], truncation=True, max_length=512, padding=\"max_length\", return_tensors='pt')\n",
    "    target_encodings = t5_tokenizer(examples['target_text'], truncation=True, max_length=16, padding=\"max_length\", return_tensors='pt')\n",
    "    \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'target_ids': target_encodings['input_ids']\n",
    "    }\n",
    "    ### your code ###\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UI_tQfeNIgi7",
   "metadata": {
    "id": "UI_tQfeNIgi7"
   },
   "source": [
    "Use the `map` function to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "gYm6RZGF19xY",
   "metadata": {
    "id": "gYm6RZGF19xY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 87599/87599 [01:21<00:00, 1081.30 examples/s]\n",
      "Map: 100%|██████████| 10570/10570 [00:10<00:00, 1013.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "### your code ###\n",
    "encoded_squad = encoded_squad.map(convert_to_features)\n",
    "### your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "gaIppB0A2sxX",
   "metadata": {
    "id": "gaIppB0A2sxX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers', 'input_text', 'target_text', 'input_ids', 'attention_mask', 'target_ids'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers', 'input_text', 'target_text', 'input_ids', 'attention_mask', 'target_ids'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_squad #new columns are added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iMhQ6_vpIlUC",
   "metadata": {
    "id": "iMhQ6_vpIlUC"
   },
   "source": [
    "Interestingly, although we specified PyTorch tensors as output, the type of the `input_ids` is still a list. To remedy this problem, you need to explicitly set the type of the column that contains PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "gaU31GYeIlsH",
   "metadata": {
    "id": "gaU31GYeIlsH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoded_squad[\"train\"][0][\"input_ids\"])\n",
    "type(encoded_squad[\"train\"][0][\"target_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "depIPwgSIntY",
   "metadata": {
    "id": "depIPwgSIntY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### your code ###\n",
    "encoded_squad.set_format(type='torch', columns=['input_ids', 'attention_mask', 'target_ids'])\n",
    "### your code ###\n",
    "type(encoded_squad[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "kcZ1Jg8kI9UN",
   "metadata": {
    "id": "kcZ1Jg8kI9UN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input_ids: torch.Size([1, 512])\n",
      "Shape of the target_ids: torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the input_ids:\",encoded_squad[\"train\"][0][\"input_ids\"].shape)\n",
    "print(\"Shape of the target_ids:\",encoded_squad[\"train\"][0]['target_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XpYHaNlpOCMd",
   "metadata": {
    "id": "XpYHaNlpOCMd"
   },
   "source": [
    "The final step in the data processing is the creation of the data collator to\n",
    "prepare `labels` from `target_ids` and return examples with keys as expected by the forward method of T5.\n",
    "This is necessary because the trainer directly passes this dict as argument to the model so you need to check the input of T5 and rename the column based on that.\n",
    "`input_ids`, `target_ids`, `attention_mask`, and `target_attention_mask` need to be stacked in a batch and the pad tokens in the target need to be set to `-100` to avoid loss computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "RQzQ50R326cL",
   "metadata": {
    "id": "RQzQ50R326cL"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers import DataCollator\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "@dataclass\n",
    "class T2TDataCollator:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    def __call__(self, batch):\n",
    "\n",
    "      ### your code ###\n",
    "        feature_dict={\n",
    "        }\n",
    "        # Stack `input_ids`, `target_ids`, `attention_mask`, and `target_attention_mask` in the dictionary\n",
    "\n",
    "        for key in batch[0].keys():\n",
    "            # Replace all pad toekns with -100\n",
    "            if key == \"target_ids\":\n",
    "                feature_dict[\"labels\"] = torch.stack([example[key].masked_fill(example[key] == self.tokenizer.pad_token_id, -100) for example in batch]).squeeze(1)\n",
    "            else:\n",
    "              feature_dict[key] = torch.stack([example[key] for example in batch]).squeeze(1)\n",
    "        return feature_dict\n",
    "      ### your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "zXOwBe1bPCRJ",
   "metadata": {
    "id": "zXOwBe1bPCRJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "accepted_keys = ['input_text', 'target_text', 'input_ids', 'attention_mask', 'target_ids', 'target_attention_mask']\n",
    "features = [{k: v for k, v in encoded_squad[\"train\"][i].items() if k in accepted_keys} for i in range(2)]\n",
    "batch=T2TDataCollator(t5_tokenizer)(features)\n",
    "print(batch[\"input_ids\"].shape)\n",
    "print(batch[\"attention_mask\"].shape)\n",
    "print(batch[\"labels\"].shape)\n",
    "# Save batch example to txt file\n",
    "with open(\"batch_example.txt\", \"w\") as f:\n",
    "    for key, value in batch.items():\n",
    "        f.write(f\"{key}: {value[0].tolist()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gb9KZjhsu_5N",
   "metadata": {
    "id": "gb9KZjhsu_5N"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 3.1}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "✅ Point distribution 3/3.5 ✅\n",
    "the tokenizer is not loaded correctly. (0.25/0.5)\n",
    "-sequence length 512 is missing\n",
    "the EOS sentence and prefixes are added correctly in `add_eos_to_examples`. (0.5/0.5)\n",
    "the map function is used correctly for `add_eos_to_examples`. (0.5/0.5)\n",
    "the input and target are tokenized and padded correctly in `convert_to_features`. (1.0/1.0)\n",
    "- \"target_attention_mask\" could have been added to the dictionary\n",
    "the map function for `convert_to_features` is correct. (0.5/0.5)\n",
    "- By setting the batched argument as true would be for more efficient processing\n",
    "conversion of the columns to tensors is partially correct. (0.25/0.5)\n",
    "- \"target_attention_mask\" is missing.\n",
    "\n",
    "✅ Point distribution 1.5/1.5 ✅\n",
    "the tensors are stacked properly, look at the output shapes for hints. (0.5/0.5)\n",
    "the names are correctly defined. (0.5/0.5)\n",
    "the label pads are set to -100. (0.5/0.5)\n",
    "Group's solution matches the provided solution in terms of tensor stacking and naming. Additionally, it correctly sets padding in the \"labels\" tensor to -100.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ktvtcVh1N6l0",
   "metadata": {
    "id": "ktvtcVh1N6l0"
   },
   "source": [
    "### Subtask 2: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mnMvSwtbV2GC",
   "metadata": {
    "id": "mnMvSwtbV2GC"
   },
   "source": [
    "For training and inference, we can use `T5ForConditionalGeneration`, which includes the language modeling head on top of the decoder. Load the `t5-small` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aO4NNyEFKXap",
   "metadata": {
    "id": "aO4NNyEFKXap"
   },
   "outputs": [],
   "source": [
    "### your code ###\n",
    "from transformers import T5ForConditionalGeneration\n",
    "t5 = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "### your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rE9j5o_iBLOL",
   "metadata": {
    "id": "rE9j5o_iBLOL"
   },
   "source": [
    "Next, similar to the previous task we initiate training arguments. Note that this time we are using a `Seq2SeqTrainingArguments` for a `Seq2SeqTrainer`. Set the parameters for training as follows:\n",
    "\n",
    "\n",
    "*   T5 doesn't support GPU and TPU evaluation for now, so we only focus on training. You do not need to pass any parameters for evaluation setup.\n",
    "*   The output directory should be named `t5-squad`.\n",
    "* The T5 models need a slightly higher learning rate than the default one set in the `Trainer` when using the `AdamW` optimizer. Set the learning rate to `1e-4` and the regularization parameter to `0.01`.\n",
    "* Random seed should be `77`, and we train for a maximum of `200` steps and save a checkpoint every `100` steps. A complete training of the T5 model requires far more than `200` steps, however, that is beyond the scope of this assignment.\n",
    "* T5 models require a large batch size. The default model was trained with a batch size of `128`. However, we cannot fit that into a single GPU, therefore we use gradient accumulation. Set the batch size to `32` and choose the gradient accumulation step to reach the effective batch size of `128`.\n",
    "* Make sure that your trainer does not remove unused columns during training, as this will cause a runtime error later on.\n",
    "\n",
    "\n",
    "**Gradient accumulation:** is a technique that simulates a larger batch size by accumulating gradients from multiple small batches before performing a weight update.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "UiWbhXjk5Mr0",
   "metadata": {
    "id": "UiWbhXjk5Mr0"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "### your code ###\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"t5-squad\",\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=32,\n",
    "    # 32 * 4 = 128\n",
    "    gradient_accumulation_steps=4,\n",
    "    max_steps=200,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    remove_unused_columns=False,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=True,\n",
    "    seed=77\n",
    ")\n",
    "\n",
    "    ### your code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AEOvujcduYjG",
   "metadata": {
    "id": "AEOvujcduYjG"
   },
   "source": [
    "Once again make sure that you are using GPU before running the cell below.\n",
    "Initilize your `Seq2SeqTrainer` with inputs necessary for training. The training should take around 15 min on Google Colab T4 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "J_Vb3za_4kBo",
   "metadata": {
    "id": "J_Vb3za_4kBo"
   },
   "outputs": [],
   "source": [
    "# Initialize our Trainer\n",
    "from transformers import Seq2SeqTrainer\n",
    "    ### your code ###\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=t5,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_squad[\"train\"],\n",
    "    eval_dataset=encoded_squad[\"validation\"],\n",
    "    data_collator=T2TDataCollator(t5_tokenizer),\n",
    "    tokenizer=t5_tokenizer\n",
    ")\n",
    "\n",
    "    ### your code ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8GDPeyPiBIEX",
   "metadata": {
    "id": "8GDPeyPiBIEX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [13:43<?, ?it/s]\n",
      "  0%|          | 0/200 [11:35<?, ?it/s]\n",
      "100%|██████████| 200/200 [25:49<00:00,  7.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1549.6319, 'train_samples_per_second': 16.52, 'train_steps_per_second': 0.129, 'train_loss': 0.16797323226928712, 'epoch': 0.29}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.16797323226928712, metrics={'train_runtime': 1549.6319, 'train_samples_per_second': 16.52, 'train_steps_per_second': 0.129, 'train_loss': 0.16797323226928712, 'epoch': 0.29})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1-gKhqSpu7Uz",
   "metadata": {
    "id": "1-gKhqSpu7Uz"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 3.2}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "✅ Point distribution 2/2✅\n",
    "\n",
    "initializing the correct model (0.5/0.5)\n",
    "all the training parameters are set correctly.(1.0/1.0)\n",
    "the trainer is correctly initiated.(0.5/0.5)\n",
    "matches the tutor's solution in terms of initializing the model, setting training parameters, and initiating the trainer.\n",
    "In the provided solution, the save_strategy is included in the Seq2SeqTrainingArguments. The group's solution could also include this parameter in their training_args dictionary. \n",
    "The provided solution includes remove_unused_columns=False in the Seq2SeqTrainer initialization. The group could add this parameter in their trainer initialization.\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AQ9jj65UvER1",
   "metadata": {
    "id": "AQ9jj65UvER1"
   },
   "source": [
    "### Subtask 3: Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkDgQponWOs4",
   "metadata": {
    "id": "bkDgQponWOs4"
   },
   "source": [
    "Our trained model has seen far too few instances to make a coherent prediction. To this end, we load an already trained checkpoint from Hugging Face and perform inference. Load this [model](https://huggingface.co/mrm8488/t5-base-finetuned-squadv2) and the respective tokenizer. Note that we are loading a `base` model that is slightly larger than `t5-small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecdabdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/leonremke/Documents/GIT_REPOS/UNI/INLTP-Assignments/.venv/lib/python3.9/site-packages (0.1.99)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Downloading protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "Successfully installed protobuf-4.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lW8Wss36vV20",
   "metadata": {
    "id": "lW8Wss36vV20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "model.safetensors: 100%|██████████| 1.19G/1.19G [03:08<00:00, 6.29MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "### your code ###\n",
    "# Loading mrm8488/t5-base-finetuned-squadv2\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-squadv2\")\n",
    "t5_model = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/t5-base-finetuned-squadv2\")\n",
    "### your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "azC95xxzxj84",
   "metadata": {
    "id": "azC95xxzxj84"
   },
   "source": [
    "At inference time for T5, it is recommended to use the `generate()` function. This auto-regressively generates the decoder output. Complete the code for the `get_answer` function, which gives a model, a tokenizer, and a question and context pair, and generates the answer from the context given. The output should be the answer to the given question in natural text (without the special tokens).\n",
    "\n",
    "**Hint:** Many of the steps are similar to how you prepared your input data for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "_Run50fvWPcv",
   "metadata": {
    "id": "_Run50fvWPcv"
   },
   "outputs": [],
   "source": [
    "def get_answer(tokenizer,model, question, context):\n",
    "  ### your code ###\n",
    "  input_text = f\"question: {question} context: {context} </s>\"\n",
    "  features = tokenizer([input_text], return_tensors='pt')\n",
    "\n",
    "\n",
    "  answer= model.generate(input_ids=features['input_ids'], \n",
    "               attention_mask=features['attention_mask'])\n",
    "  # Convert into natural language\n",
    "  answer = tokenizer.decode(answer[0])\n",
    "  ### your code ###\n",
    "  return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F6Fq37I3yMeQ",
   "metadata": {
    "id": "F6Fq37I3yMeQ"
   },
   "source": [
    "Let's try it with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09znSykkdkk0",
   "metadata": {
    "id": "09znSykkdkk0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Harry</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"Sarah has joined NLP for transformers class and is working on her research project with the support of Harry.\"\n",
    "question = \"Who is supporting Sarah?\"\n",
    "\n",
    "get_answer(t5_tokenizer,t5_model,question, context)###your answer should be \"Harry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "LQNpgTyazjge",
   "metadata": {
    "id": "LQNpgTyazjge"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> power efficient</s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"TPUs are more power efficient in comparison to GPUs making them a better choice for machine learning projects.\"\n",
    "question = \"What is better for machine learning projects?\"\n",
    "\n",
    "get_answer(t5_tokenizer,t5_model,question, context)###your answer should be \"TPUs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sIz0JuwzGEFN",
   "metadata": {
    "id": "sIz0JuwzGEFN"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 3.3}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "✅ Point distribution 2/2 ✅\n",
    "\n",
    "initialized the correct model and tokenizer. (0.5/0.5)\n",
    "prepared the input correctly. (0.5/0.5)\n",
    "generation and decoding using the tokenizer is correct. (1.0/1.0)\n",
    "Despite some differences in the string formatting of input_text (using %s vs. f-string) which does not affect the functionality of the code, you achieve the same result. You correctly initialize the model and tokenizer, prepare the input text, and generate the answer using the specified tokenizer. \n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9LfBp2eKqYc",
   "metadata": {
    "id": "i9LfBp2eKqYc"
   },
   "source": [
    "### Subtask 4: T5 Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NRVp_0KaKvN4",
   "metadata": {
    "id": "NRVp_0KaKvN4"
   },
   "source": [
    "To answer questions of the final subtask you need to have a general overview of the [T5 paper](https://arxiv.org/pdf/1910.10683.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EwoEHJ1eMSVr",
   "metadata": {
    "id": "EwoEHJ1eMSVr"
   },
   "source": [
    "\n",
    "\n",
    "1.   Describe what a “text-to-text format\" is and how T5 processes input and output for text classification tasks? What are the possible complications with a predefined set of classes?\n",
    "2.   Describe the \"masked language modeling\" and \"word dropout\" unsupervised objective with sentinel tokens. Give an example of how this would look in a single sentence.\n",
    "3. Explain \"fully-visible\", \"causal\" and \"causal masking with prefix\" masking.\n",
    "4. Briefly describe \"adapter layers\" and \"gradual unfreezing\" as methods for fine-tuning on fewer parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gIi_WZuvMWUb",
   "metadata": {
    "id": "gIi_WZuvMWUb"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "`\n",
    "1. “text-to-text format\" describes the approach to use the same model architecture, loss and input/output modality (text) for all NLP tasks (sentiment, classification, summarisation, translation, usw.). In general this approach is a form of transfer learning, where the model is trained on a large corpus for general knowledge and language understanding to further finetune on a specific tasks.\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rIf7G01tkc4u",
   "metadata": {
    "id": "rIf7G01tkc4u"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "`\n",
    "2. \n",
    "   1. **\"masked language modeling\"** is a technique where certain words are masked to train the model in predicting these missing parts of the sentence.\n",
    "   2. **\"word dropout\"** is a extension to this technique, which does not mask a specific part of the text, but instead masks random words of the text to improve the generalization. These masking tokens are called sentinel tokens.\n",
    "      1. randomly samples and then drops out 15% of tokens in the input sequence, all other are replaced by a sentinel token\n",
    "   3. **Example in a single sentence:** \"The money is hidden `<mask>` the basement.\"\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iC-WBUKQkf6r",
   "metadata": {
    "id": "iC-WBUKQkf6r"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "`\n",
    "3. Attention Masking\n",
    "   1. **Fully-visible** masking allows the self-attention to focus on any area of the input.\n",
    "   2. **Casual** masks mask all tokens that are behind the <target> token. In natural language the paper describes this as looking into the future. This is helpful, since the model cann see the target section when predicting.\n",
    "   3. **Casual with prefix** is similar to casual masking with the addition of the prefix.\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L2Mo5YElkhtI",
   "metadata": {
    "id": "L2Mo5YElkhtI"
   },
   "source": [
    "**Answer**\n",
    "\n",
    "`\n",
    "4. \n",
    "   1. **Adapter layers:** are usual NN dense ReLu layers which are added behind every transformer block. This is possible, since their input dimensions match their output dimensions. It is resource efficient method, because only adapter layer and layer normalization parameters are updated when finetuning.\n",
    "   2. **Gradual unfreezing:** is a technique where not all layers of the transformer are updated at once, but on every n iterations the finetuning includes one layer more into the update until all layers where updated. This process starts with the final layer.\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WiYns91wr2P5",
   "metadata": {
    "id": "WiYns91wr2P5"
   },
   "source": [
    "#### ${\\color{red}{Comments\\ 3.4}}$\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
    "\n",
    "\n",
    "```\n",
    "✅ Point distribution (5/5)✅\n",
    "- 1.5 point for part 1. (1.5/1.5)\n",
    "- 1 point for part 2. (1/1)\n",
    "- 1.5 point for part 3. (1.5/1.5)\n",
    "- 1 point for part 4. (1/1)\n",
    "\n",
    "1.accurate description of the text-to-text format, emphasizing the use of the same model architecture for diverse NLP tasks through transfer learning.\n",
    "2.provides a clear explanation of masked language modeling and word dropout. However, it doesn't explicitly mention that the sentinel IDs are special tokens added to the vocabulary.\n",
    "3.correctly explains fully-visible, causal, and causal masking with prefix, demonstrating a solid understanding of these masking techniques.\n",
    "4.accurately describes adapter layers and gradual unfreezing, showing these methods for fine-tuning on fewer parameters correctly.\n",
    "```\n",
    "\n",
    "\n",
    "${\\color{red}{⚠️Comments\\ end⚠️}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0784d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "007900d3b4d940ed8e75ffcb1a449282": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "021b8f0ed860481da9b692a64c76eced": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f071a994d59c4786a8de930823a798bb",
       "IPY_MODEL_979a2d2165aa439eb9f53243b48f4235",
       "IPY_MODEL_2dd52546dd8d43e787b39319eb621c48"
      ],
      "layout": "IPY_MODEL_22d26990dccf44399d6b7316ebd6109e"
     }
    },
    "0361bad8a55147a28dd49b87f6a5a0c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30959f57119346cd96f30a3e4d573f45",
      "placeholder": "​",
      "style": "IPY_MODEL_849cfa8331304d6fbb0d54b6de39d1b2",
      "value": "vocab.txt: 100%"
     }
    },
    "037ac3bd40fd4a8493a54b0ad274ff34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "048757572a7a4255b90a3013e49fd169": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74b182da3443406c9dcf1c91310ac2b7",
      "placeholder": "​",
      "style": "IPY_MODEL_bb0eb5bcab934a05a0a774b8940f4b0f",
      "value": "Map: 100%"
     }
    },
    "069903334f5a473196d989203e08a270": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c87c6653e0b840f08fa6f5d32ee73cbe",
       "IPY_MODEL_1c1c02687c7b46dc932649ad6b76c09f",
       "IPY_MODEL_d21f7ffc85234dc580c3e426c1bd8885"
      ],
      "layout": "IPY_MODEL_f6c484ad77f74a00b68a8108085fcc0f"
     }
    },
    "090ee45b51354baeb27a1818a3889c34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35b61a49f19e4caa98e527159194341f",
      "placeholder": "​",
      "style": "IPY_MODEL_cbba9215e5494575be6159e003995891",
      "value": "Map: 100%"
     }
    },
    "0b2efc34361f47d8b7a491ab140221eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b5abc95fcb041ab8402a13d925292a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ce25511b0c54f9a8ad546a00c7d041a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d84c640fba846acbcd3abb92e0b24e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5049fbdc5db4ef4ab908f16901573dd",
       "IPY_MODEL_2d8ad4c70b194050b447e1525312a636",
       "IPY_MODEL_d7f3dfab8d7d480f808d0a89bc5bbbb6"
      ],
      "layout": "IPY_MODEL_1e8b6cb082d0464c89f31d0dc981d1ae"
     }
    },
    "0eebbf045d5d44938f87c8b8e34934d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f2a1a430f8140ec9c6d909fcbdebd90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ff40e429a5747f48de3f356bf415709": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "115e3b3e5b8242dd83bd6992071e7823": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "147ffcd6b3384a05ae7658cd0982f32d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ee7ecb284b8482882186a6300001f61",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d30bc69199fe44ad9ebcc190a90948da",
      "value": 231508
     }
    },
    "156559c29199483d82f93035348cf40a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "174d000d421e4299ab33e7b3e41d70f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c27e8811bbb143ca858e8aa11b36c865",
       "IPY_MODEL_feb8371c04ac40afa3c011415ed07bd2",
       "IPY_MODEL_36b46aec1888489e8e82915739d7e941"
      ],
      "layout": "IPY_MODEL_f2a5311797d84b30a515ec772031cb96"
     }
    },
    "190d3cbed2384ca89c211f290fe2c668": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19614ee0b7a140969c83b3ff0b5cad6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c1c02687c7b46dc932649ad6b76c09f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_037ac3bd40fd4a8493a54b0ad274ff34",
      "max": 4203,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_886d55f8441d40b0b1ba1b85eff3a7d1",
      "value": 4203
     }
    },
    "1c921f44296f4fbbba790ca690618120": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e8b6cb082d0464c89f31d0dc981d1ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fa8b739e3f045a0bb3d31147d4900f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ba966155c584b06b177e52ce1c7495f",
      "max": 7967,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fedd66d83af04fe08e432b6899321d7b",
      "value": 7967
     }
    },
    "1fd0ea7e9ae640e6a0333240e22f96f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "216ba850075a46208c4ce5316e23f4e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21f37e12489d4c5db71851539f163c6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22d26990dccf44399d6b7316ebd6109e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "234692e7eb264701abcaca0b3c5e96db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23ce666d4dd4452aa33796e2f785ac8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24517fb789b64889852c5c59764d8c34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26475a21ebff4973a517851e2bcb7b27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "265d180ad9e648c194472d8258f195d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "265fb4db2fc3495ea1c787f0cfc3184c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26e98c12c57f4731948ec3d0c59cd3a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbe26119eed94ab0a7e775e3070eefcc",
      "max": 267954768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_405cfa82a5b14a35aba8dde062df62fa",
      "value": 267954768
     }
    },
    "2734418a212c4044899a4509265765c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4906bb9727364d179a22d7895d537705",
      "placeholder": "​",
      "style": "IPY_MODEL_90ce257bf1164264806fa72327da4179",
      "value": " 232k/232k [00:00&lt;00:00, 1.73MB/s]"
     }
    },
    "29c5a6ef24ee43ccadd891d774b93bb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8aac1cce4ab4c079674b85c71b6a416",
      "placeholder": "​",
      "style": "IPY_MODEL_21f37e12489d4c5db71851539f163c6c",
      "value": "Downloading data: "
     }
    },
    "2b81a4e73e4149a5b1d682dade9c75c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c2a64eb71224cfda8cfb60f6869bbd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d8ad4c70b194050b447e1525312a636": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94d41362847e431ab013a75ac431125d",
      "max": 7100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88cae77cf84847efb964bc0cc21ec55e",
      "value": 7100
     }
    },
    "2dd52546dd8d43e787b39319eb621c48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fd0ea7e9ae640e6a0333240e22f96f0",
      "placeholder": "​",
      "style": "IPY_MODEL_d15544fead5f4a4d95db8be9ae6120ac",
      "value": " 7.82M/? [00:00&lt;00:00, 28.1MB/s]"
     }
    },
    "2f05a4d4092c4a43a0d4b10be5c77ea0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30959f57119346cd96f30a3e4d573f45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3097c731c8eb411db10609a4fc9eb2cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fda181650fd4908999a30892431b3be",
      "placeholder": "​",
      "style": "IPY_MODEL_6fd644afa33a4536956f50a6b1d17e48",
      "value": " 20005/20005 [00:22&lt;00:00, 773.25 examples/s]"
     }
    },
    "33dd465640c6456d8f8a5e5657dcb52c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "349611bde2e5489c9b63436ff8e2bda7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67099f9a3a734be791c4d133715da363",
       "IPY_MODEL_c74ef17522654428a6ad6e65948dc5e2",
       "IPY_MODEL_3d4d483d936e494584ab216f96b9a972"
      ],
      "layout": "IPY_MODEL_8418aa5b385043669c8d2edbb8a301b3"
     }
    },
    "359f41dc0a8a4ed0a548e596a466a93f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35b61a49f19e4caa98e527159194341f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35bbff4bdfb2446089e5378cb105cf9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36b46aec1888489e8e82915739d7e941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19614ee0b7a140969c83b3ff0b5cad6c",
      "placeholder": "​",
      "style": "IPY_MODEL_156559c29199483d82f93035348cf40a",
      "value": " 73546/73546 [01:23&lt;00:00, 934.93 examples/s]"
     }
    },
    "3815a63aab344a768b7ef1565989b952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcf9ac8f07ab427ab78cfe09dafcd152",
      "placeholder": "​",
      "style": "IPY_MODEL_6f4e3198f914455c96d85f1134ae8ad0",
      "value": " 268M/268M [00:04&lt;00:00, 45.0MB/s]"
     }
    },
    "3ba966155c584b06b177e52ce1c7495f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bfdbd6d26a9447eaa612d04cd0e46cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_048757572a7a4255b90a3013e49fd169",
       "IPY_MODEL_957e27222bec433ca19262825b276359",
       "IPY_MODEL_a0226be9cf934af999b986c51e01cd3c"
      ],
      "layout": "IPY_MODEL_190d3cbed2384ca89c211f290fe2c668"
     }
    },
    "3d1615a0e9ae438a98e8347bdadf2f37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d4d483d936e494584ab216f96b9a972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f2a1a430f8140ec9c6d909fcbdebd90",
      "placeholder": "​",
      "style": "IPY_MODEL_6ed11b69997044a2a7571f3872aebbcd",
      "value": " 20006/20006 [00:01&lt;00:00, 11796.17 examples/s]"
     }
    },
    "3dbe0771dc614016b0108aa4f21a6365": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ee154deae6d431e824dbf7b2d72070f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5a7b3bf299241a886b958d9204a5ba3",
       "IPY_MODEL_cfabc4420a7c4bdca39c01e5e62faf42",
       "IPY_MODEL_98edcdbed47946ca8ef1b2c60f02a15e"
      ],
      "layout": "IPY_MODEL_0ff40e429a5747f48de3f356bf415709"
     }
    },
    "405cfa82a5b14a35aba8dde062df62fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45eb191b9ac14eff80b12e837a87fbf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4692e3964b7440d794d4625b08692507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26475a21ebff4973a517851e2bcb7b27",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67e531e278504247aaddf6de4d17e2a0",
      "value": 28
     }
    },
    "46f1b5739fa84c4e9e3f4029c18e568a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47f5b713728545d39aeedf65558258c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4906bb9727364d179a22d7895d537705": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49a27242d0fe44ae8e0af200280aba14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f3c3f4854b44d3abeb66405d7c36228",
       "IPY_MODEL_642d57c00b6a4809b6330e65046c2f8f",
       "IPY_MODEL_c23b288d5ed1442cad80012a64b46e64"
      ],
      "layout": "IPY_MODEL_9a377a3780e24232b8c12ac29eed97c9"
     }
    },
    "49b0eaefe2a640c184dffe89cab27794": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa1829f7a57643aa9a9a42be635e5eca",
      "placeholder": "​",
      "style": "IPY_MODEL_6a4288d797d04edeb1861c23dc371cc4",
      "value": " 7.89M/? [00:00&lt;00:00, 22.6MB/s]"
     }
    },
    "4c6ae1461ac34a96a71820cb3ee35da0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f3c3f4854b44d3abeb66405d7c36228": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0eebbf045d5d44938f87c8b8e34934d6",
      "placeholder": "​",
      "style": "IPY_MODEL_b3b53e6af28f4bd4b04471b651cb86b2",
      "value": "Generating train split: 100%"
     }
    },
    "54f4073a15e8443488fa8e224c1b3ca8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "556cb992cb69488ca88c51bca7884c23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6efea153049a467d945507b922767dc9",
       "IPY_MODEL_4692e3964b7440d794d4625b08692507",
       "IPY_MODEL_f129b011542e47a7b3deb195d6bd54ca"
      ],
      "layout": "IPY_MODEL_d11034b705ee43e89a6444af654e6095"
     }
    },
    "5739a7692748402c913c6e28a8354903": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62de7ece5ec34e44aa30c57077da9e8d",
      "placeholder": "​",
      "style": "IPY_MODEL_f4612458689a4184a02334faa218165e",
      "value": "model.safetensors: 100%"
     }
    },
    "5755cd49cc8c43219e369a608401b97c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "578304a456b84469bddf7b106dcda33f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59106f669b284e96acc2e8e37cadca25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "594827e957f24aa4af9cf3f54895be96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83ab832dfbc54bbca93682b740cd50d5",
      "placeholder": "​",
      "style": "IPY_MODEL_3d1615a0e9ae438a98e8347bdadf2f37",
      "value": "tokenizer.json: 100%"
     }
    },
    "5a34873d2c384e738ea0c98f00e37cd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9e2c788e43448e296dc982d55e4a154",
      "placeholder": "​",
      "style": "IPY_MODEL_5d598908cc7a4ae98a77fdfb5c5e1413",
      "value": "Downloading data: "
     }
    },
    "5a57877bd1584d38b77fb7f1408aabbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f97256cc0f9a43b79688eb076147e980",
       "IPY_MODEL_1fa8b739e3f045a0bb3d31147d4900f7",
       "IPY_MODEL_f0f4796fd6f64f8f84027dca0b403f99"
      ],
      "layout": "IPY_MODEL_265fb4db2fc3495ea1c787f0cfc3184c"
     }
    },
    "5ab45343bbb843c59214c7ae88aed759": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bb59cc2b87e47549cfb02c49a43f300": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cacb793be0d4a0182e0c6e6db95a503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46f1b5739fa84c4e9e3f4029c18e568a",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b449490449cf4f7599dfe79f92ad16c1",
      "value": 466062
     }
    },
    "5d598908cc7a4ae98a77fdfb5c5e1413": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e902246d66f471e82a87a2da202dbfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5f9fbdf5c7954348b12fe236d8d2149c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35bbff4bdfb2446089e5378cb105cf9e",
      "placeholder": "​",
      "style": "IPY_MODEL_24517fb789b64889852c5c59764d8c34",
      "value": "Generating test split: 100%"
     }
    },
    "5fd84178dc1d4101869d693d61d300c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62de7ece5ec34e44aa30c57077da9e8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "642d57c00b6a4809b6330e65046c2f8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c2a64eb71224cfda8cfb60f6869bbd9",
      "max": 73546,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_faa89a0704e149528f4ff84946a68dbd",
      "value": 73546
     }
    },
    "648899cb119f42ff949cd0b1b432ee12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66edd391e81c4a0f8bb63b1eca20f58e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67099f9a3a734be791c4d133715da363": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_648899cb119f42ff949cd0b1b432ee12",
      "placeholder": "​",
      "style": "IPY_MODEL_d9200911023d47918495cd1307814c5c",
      "value": "Generating validation split: 100%"
     }
    },
    "67e531e278504247aaddf6de4d17e2a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67ea5dc5d0e44ca0b3e044d2c05162ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68e4b94d07b84955806f37b808d59675": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a4288d797d04edeb1861c23dc371cc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ed11b69997044a2a7571f3872aebbcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ee7ecb284b8482882186a6300001f61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6efea153049a467d945507b922767dc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ab45343bbb843c59214c7ae88aed759",
      "placeholder": "​",
      "style": "IPY_MODEL_91923ab4188c4ab0b96da0d1a6ca5df9",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "6f4e3198f914455c96d85f1134ae8ad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fd644afa33a4536956f50a6b1d17e48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "706e66897bfe40c996206711386acccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7236f0d574ef4554b7da54104457fd49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74b182da3443406c9dcf1c91310ac2b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74db6de2bc4746058c2469d702a8b8ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7918418ae85d49afb4448db6a0b285ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0361bad8a55147a28dd49b87f6a5a0c6",
       "IPY_MODEL_147ffcd6b3384a05ae7658cd0982f32d",
       "IPY_MODEL_2734418a212c4044899a4509265765c8"
      ],
      "layout": "IPY_MODEL_c14aa0003a084a4c8f33c70550d94868"
     }
    },
    "7ba1d762b16b4db789fc9a45d67b43bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e1a93a9ccc04f8a88cf09133e3858dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_594827e957f24aa4af9cf3f54895be96",
       "IPY_MODEL_5cacb793be0d4a0182e0c6e6db95a503",
       "IPY_MODEL_df015b6c7d5543a9b595b911e9cf81c3"
      ],
      "layout": "IPY_MODEL_7236f0d574ef4554b7da54104457fd49"
     }
    },
    "7ef279340fd2417da8bfb759e1ec4a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4ddc6c88c59428da1dcf2d68680ec12",
       "IPY_MODEL_de30af7c954d457c88116d2dbdfb50b6",
       "IPY_MODEL_8545cc6a77c24d16887fe821caa9188c"
      ],
      "layout": "IPY_MODEL_234692e7eb264701abcaca0b3c5e96db"
     }
    },
    "7f89ba5ea2f44f1cb850d90f5ff43ca3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8002acdb281f4cf4a8dfd2d5f5804f83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83ab832dfbc54bbca93682b740cd50d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8418aa5b385043669c8d2edbb8a301b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84903426242f4928b95fb5bc768dcc25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "849cfa8331304d6fbb0d54b6de39d1b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8545cc6a77c24d16887fe821caa9188c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f05a4d4092c4a43a0d4b10be5c77ea0",
      "placeholder": "​",
      "style": "IPY_MODEL_007900d3b4d940ed8e75ffcb1a449282",
      "value": " 483/483 [00:00&lt;00:00, 33.5kB/s]"
     }
    },
    "886d55f8441d40b0b1ba1b85eff3a7d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88be60663f574a36b05415099c7d9ebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68e4b94d07b84955806f37b808d59675",
      "placeholder": "​",
      "style": "IPY_MODEL_fb69487f907c45a38b44826503c5849c",
      "value": " 28.2M/? [00:00&lt;00:00, 37.6MB/s]"
     }
    },
    "88cae77cf84847efb964bc0cc21ec55e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8cf76e72149b492db2a131fcfe28b562": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d35a7a964c14f798b96c18cad73f169": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "909ca5bee1a34086812609f2a8524625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90ce257bf1164264806fa72327da4179": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91923ab4188c4ab0b96da0d1a6ca5df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94d41362847e431ab013a75ac431125d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "957e27222bec433ca19262825b276359": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c921f44296f4fbbba790ca690618120",
      "max": 20006,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd14944f9a054c3d95d195f68df593f0",
      "value": 20006
     }
    },
    "979a2d2165aa439eb9f53243b48f4235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8002acdb281f4cf4a8dfd2d5f5804f83",
      "max": 2214653,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c38cf7f1fa048c68a907aa408f759df",
      "value": 2214653
     }
    },
    "97f473ef07f040b498fedf3e7decbe56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98edcdbed47946ca8ef1b2c60f02a15e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afcbba2ab9e1478a897692d48e16065e",
      "placeholder": "​",
      "style": "IPY_MODEL_f8abdeef1a874b21a6a26e85630e917f",
      "value": " 8.88k/8.88k [00:00&lt;00:00, 330kB/s]"
     }
    },
    "9a377a3780e24232b8c12ac29eed97c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c38cf7f1fa048c68a907aa408f759df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9fda181650fd4908999a30892431b3be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0226be9cf934af999b986c51e01cd3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cf76e72149b492db2a131fcfe28b562",
      "placeholder": "​",
      "style": "IPY_MODEL_d951bec8d7c049c69b37412b26806912",
      "value": " 20006/20006 [00:22&lt;00:00, 877.34 examples/s]"
     }
    },
    "a3a5fe30ad17420295e5ff5996dc13f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f9fbdf5c7954348b12fe236d8d2149c",
       "IPY_MODEL_bd584a34ff534146917c6336c6136d11",
       "IPY_MODEL_ec929cb2fcad45eaad53f558f2f90d40"
      ],
      "layout": "IPY_MODEL_216ba850075a46208c4ce5316e23f4e5"
     }
    },
    "a49a2787e46a4a29b85d760b1c15d645": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4ddc6c88c59428da1dcf2d68680ec12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3fa688048aa49859105b385711c394d",
      "placeholder": "​",
      "style": "IPY_MODEL_a8c58072428c46fea597473d72d0e529",
      "value": "config.json: 100%"
     }
    },
    "a4f95680036e4b1c8e7df70b19b14bbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6bec7d0b3594f69b4ac6c809457e1d9",
      "max": 2238601,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_265d180ad9e648c194472d8258f195d4",
      "value": 2238601
     }
    },
    "a5049fbdc5db4ef4ab908f16901573dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ce25511b0c54f9a8ad546a00c7d041a",
      "placeholder": "​",
      "style": "IPY_MODEL_97f473ef07f040b498fedf3e7decbe56",
      "value": "Downloading metadata: 100%"
     }
    },
    "a5a7b3bf299241a886b958d9204a5ba3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_359f41dc0a8a4ed0a548e596a466a93f",
      "placeholder": "​",
      "style": "IPY_MODEL_67ea5dc5d0e44ca0b3e044d2c05162ab",
      "value": "Downloading readme: 100%"
     }
    },
    "a6186dc1ec544b69b98290fea5b2553a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6f4f537543b407c9c22539fac062caf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a86346c2f4354dc4876ea9da7dadfa70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8c58072428c46fea597473d72d0e529": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af8f18e7d2754934bf82e22260df1fb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afcbba2ab9e1478a897692d48e16065e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b37a253d25d745dcb2859b6781a969d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3b53e6af28f4bd4b04471b651cb86b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3fa688048aa49859105b385711c394d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b449490449cf4f7599dfe79f92ad16c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bb0eb5bcab934a05a0a774b8940f4b0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc68c23d359a4f4ba577c5aa55265d46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcf9ac8f07ab427ab78cfe09dafcd152": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd584a34ff534146917c6336c6136d11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23ce666d4dd4452aa33796e2f785ac8d",
      "max": 20005,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_54f4073a15e8443488fa8e224c1b3ca8",
      "value": 20005
     }
    },
    "c14aa0003a084a4c8f33c70550d94868": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c23b288d5ed1442cad80012a64b46e64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b2efc34361f47d8b7a491ab140221eb",
      "placeholder": "​",
      "style": "IPY_MODEL_a6186dc1ec544b69b98290fea5b2553a",
      "value": " 73546/73546 [00:07&lt;00:00, 10157.26 examples/s]"
     }
    },
    "c27e8811bbb143ca858e8aa11b36c865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b37a253d25d745dcb2859b6781a969d3",
      "placeholder": "​",
      "style": "IPY_MODEL_706e66897bfe40c996206711386acccf",
      "value": "Map: 100%"
     }
    },
    "c2dbaa670dc042528573f912ae400329": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af8f18e7d2754934bf82e22260df1fb2",
      "max": 20005,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45eb191b9ac14eff80b12e837a87fbf7",
      "value": 20005
     }
    },
    "c5c2eaa5b339436f9ae750e9d2c7fbd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c74ef17522654428a6ad6e65948dc5e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5fd84178dc1d4101869d693d61d300c6",
      "max": 20006,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8e98c4d49a5420dbe27eb6a710ba93f",
      "value": 20006
     }
    },
    "c87c6653e0b840f08fa6f5d32ee73cbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f75547ba1b484fa096b2a601c6e05cb7",
      "placeholder": "​",
      "style": "IPY_MODEL_84903426242f4928b95fb5bc768dcc25",
      "value": "Downloading builder script: 100%"
     }
    },
    "c8a40c3a9ae64ddcbfd1d11378cfc8c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_090ee45b51354baeb27a1818a3889c34",
       "IPY_MODEL_c2dbaa670dc042528573f912ae400329",
       "IPY_MODEL_3097c731c8eb411db10609a4fc9eb2cd"
      ],
      "layout": "IPY_MODEL_a49a2787e46a4a29b85d760b1c15d645"
     }
    },
    "c8aac1cce4ab4c079674b85c71b6a416": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca09f1eb68bc472ea9370c62026bf09b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66edd391e81c4a0f8bb63b1eca20f58e",
      "max": 6710578,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e902246d66f471e82a87a2da202dbfc",
      "value": 6710578
     }
    },
    "cafacfc001b84794843fd369e4b77698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_29c5a6ef24ee43ccadd891d774b93bb8",
       "IPY_MODEL_a4f95680036e4b1c8e7df70b19b14bbf",
       "IPY_MODEL_49b0eaefe2a640c184dffe89cab27794"
      ],
      "layout": "IPY_MODEL_74db6de2bc4746058c2469d702a8b8ec"
     }
    },
    "cbba9215e5494575be6159e003995891": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd14944f9a054c3d95d195f68df593f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cfabc4420a7c4bdca39c01e5e62faf42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_578304a456b84469bddf7b106dcda33f",
      "max": 8880,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dbe0771dc614016b0108aa4f21a6365",
      "value": 8880
     }
    },
    "d11034b705ee43e89a6444af654e6095": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d15544fead5f4a4d95db8be9ae6120ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d21f7ffc85234dc580c3e426c1bd8885": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fef9fd747cb84e3783dd41cc90fb7d4d",
      "placeholder": "​",
      "style": "IPY_MODEL_bc68c23d359a4f4ba577c5aa55265d46",
      "value": " 4.20k/4.20k [00:00&lt;00:00, 208kB/s]"
     }
    },
    "d30bc69199fe44ad9ebcc190a90948da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d388b6f112bc403e9397f6e80978b80c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7f3dfab8d7d480f808d0a89bc5bbbb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbbae709ee7d41d7a55553bcf3185f7c",
      "placeholder": "​",
      "style": "IPY_MODEL_4c6ae1461ac34a96a71820cb3ee35da0",
      "value": " 7.10k/7.10k [00:00&lt;00:00, 246kB/s]"
     }
    },
    "d8e98c4d49a5420dbe27eb6a710ba93f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9200911023d47918495cd1307814c5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d951bec8d7c049c69b37412b26806912": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dbbae709ee7d41d7a55553bcf3185f7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbe26119eed94ab0a7e775e3070eefcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de30af7c954d457c88116d2dbdfb50b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea253b6459cf40bb9c347adf7bc15b9b",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f069586be5bf4c80b8728120b1dc8c23",
      "value": 483
     }
    },
    "df015b6c7d5543a9b595b911e9cf81c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47f5b713728545d39aeedf65558258c0",
      "placeholder": "​",
      "style": "IPY_MODEL_115e3b3e5b8242dd83bd6992071e7823",
      "value": " 466k/466k [00:00&lt;00:00, 2.34MB/s]"
     }
    },
    "e6bec7d0b3594f69b4ac6c809457e1d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8e820701f234441bced37d987e8add4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5739a7692748402c913c6e28a8354903",
       "IPY_MODEL_26e98c12c57f4731948ec3d0c59cd3a8",
       "IPY_MODEL_3815a63aab344a768b7ef1565989b952"
      ],
      "layout": "IPY_MODEL_59106f669b284e96acc2e8e37cadca25"
     }
    },
    "e9e2c788e43448e296dc982d55e4a154": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea253b6459cf40bb9c347adf7bc15b9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec929cb2fcad45eaad53f558f2f90d40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ba1d762b16b4db789fc9a45d67b43bf",
      "placeholder": "​",
      "style": "IPY_MODEL_2b81a4e73e4149a5b1d682dade9c75c5",
      "value": " 20005/20005 [00:02&lt;00:00, 7238.43 examples/s]"
     }
    },
    "f069586be5bf4c80b8728120b1dc8c23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f071a994d59c4786a8de930823a798bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a86346c2f4354dc4876ea9da7dadfa70",
      "placeholder": "​",
      "style": "IPY_MODEL_7f89ba5ea2f44f1cb850d90f5ff43ca3",
      "value": "Downloading data: "
     }
    },
    "f0f4796fd6f64f8f84027dca0b403f99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5c2eaa5b339436f9ae750e9d2c7fbd2",
      "placeholder": "​",
      "style": "IPY_MODEL_909ca5bee1a34086812609f2a8524625",
      "value": " 7.97k/7.97k [00:00&lt;00:00, 161kB/s]"
     }
    },
    "f129b011542e47a7b3deb195d6bd54ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bb59cc2b87e47549cfb02c49a43f300",
      "placeholder": "​",
      "style": "IPY_MODEL_8d35a7a964c14f798b96c18cad73f169",
      "value": " 28.0/28.0 [00:00&lt;00:00, 2.01kB/s]"
     }
    },
    "f2a5311797d84b30a515ec772031cb96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4612458689a4184a02334faa218165e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6c484ad77f74a00b68a8108085fcc0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f75547ba1b484fa096b2a601c6e05cb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8abdeef1a874b21a6a26e85630e917f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f97256cc0f9a43b79688eb076147e980": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5755cd49cc8c43219e369a608401b97c",
      "placeholder": "​",
      "style": "IPY_MODEL_d388b6f112bc403e9397f6e80978b80c",
      "value": "Downloading builder script: 100%"
     }
    },
    "fa1829f7a57643aa9a9a42be635e5eca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faa89a0704e149528f4ff84946a68dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fb69487f907c45a38b44826503c5849c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe6e8015267f4c3db98845148095bafe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a34873d2c384e738ea0c98f00e37cd3",
       "IPY_MODEL_ca09f1eb68bc472ea9370c62026bf09b",
       "IPY_MODEL_88be60663f574a36b05415099c7d9ebe"
      ],
      "layout": "IPY_MODEL_33dd465640c6456d8f8a5e5657dcb52c"
     }
    },
    "feb8371c04ac40afa3c011415ed07bd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b5abc95fcb041ab8402a13d925292a0",
      "max": 73546,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6f4f537543b407c9c22539fac062caf",
      "value": 73546
     }
    },
    "fedd66d83af04fe08e432b6899321d7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fef9fd747cb84e3783dd41cc90fb7d4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
