{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be9f7653",
      "metadata": {
        "id": "be9f7653"
      },
      "source": [
        "**Heidelberg University**\n",
        "\n",
        "**Data Science  Group**\n",
        "    \n",
        "Prof. Dr. Michael Gertz  \n",
        "\n",
        "Ashish Chouhan, Satya Almasian, John Ziegler, Jayson Salazar, Nicolas Reuter\n",
        "    \n",
        "November 13, 2023\n",
        "    \n",
        "Natural Language Processing with Transformers\n",
        "\n",
        "Winter Semster 2023/2024     \n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "258e9648",
      "metadata": {
        "id": "258e9648"
      },
      "source": [
        "# **Assignment 2: “Sequence Models”**\n",
        "**Due**: Monday, November 27, 2pm, via [Moodle](https://moodle.uni-heidelberg.de/course/view.php?id=19251)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc27ad9e",
      "metadata": {
        "id": "fc27ad9e"
      },
      "source": [
        "### **Submission Guidelines**\n",
        "\n",
        "- Solutions need to be uploaded as a **single** Jupyter notebook. You will find several pre-filled code segments in the notebook, your task is to fill in the missing cells.\n",
        "- For the written solution, use LaTeX in markdown inside the same notebook. Do **not** hand in a separate file for it.\n",
        "- Download the .zip file containing the dataset but do **not** upload it with your solution.\n",
        "- It is sufficient if one person per group uploads the solution to Moodle, but make sure that the complete names of all team members are given in the notebook.\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e322e8b0",
      "metadata": {
        "id": "e322e8b0"
      },
      "source": [
        "## **Task 1: Part-of-Speech Tagging with a Bidirectional LSTM**  (2+4+5=11 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4ca26ac",
      "metadata": {
        "id": "b4ca26ac"
      },
      "source": [
        "In this task we will be building a sequence tagger that produces an output for every element in an input sequence, using `PyTorch` and `TorchText`, where `TorchText` consists of data processing utilities and popular datasets for natural language.\n",
        "\n",
        "\n",
        "*   **input:** a sequence of text\n",
        "*   **output:** part-of-speech (POS) tag for each token in the input text\n",
        "\n",
        "We tackle this task using a multi-layer bi-directional LSTM (BiLSTM) to predict POS tags using the [Universal Dependencies](https://universaldependencies.org/) English Web Treebank (UDPOS) dataset. This dataset is contained in the `TorchText` library and we do not require an external file for it. The dataset in  `TorchText`  has two different sets of tags, universal dependency (UD) tags and Penn Treebank (PTB) tags. We only focus on the UD tags for this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nnBfLC1P5QXw",
      "metadata": {
        "id": "nnBfLC1P5QXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcca8bfa-c391-4547-c1f6-b23c6dfb573c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n"
          ]
        }
      ],
      "source": [
        "%pip install portalocker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nT5geerO7d1P",
      "metadata": {
        "id": "nT5geerO7d1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f09e27-1f57-4127-bf7b-3a3d9a2192e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install torchdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_pIBtTh3sOQe",
      "metadata": {
        "id": "_pIBtTh3sOQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb9f193-0900-4f7c-fcf0-b9f711fe8ef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.23.5)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchtext) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787e2059",
      "metadata": {
        "id": "787e2059"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.datasets import UDPOS\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import random\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# for reproducibility\n",
        "random.seed(77)\n",
        "np.random.seed(77)\n",
        "torch.manual_seed(77)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc29cb37",
      "metadata": {
        "id": "fc29cb37"
      },
      "source": [
        "### Subtask 1: Data Analysis\n",
        "The very basic components of the torchtext library include `vocab`, `word vectors`, and `tokenizer`. Those are the basic data processing building blocks for the raw text string.\n",
        "In this case, we use the tokenizer and the vocabulary. Use the `build_vocab_from_iterator` to create the vocabulary for the text field and add the `<unk>` and `<pad>` tokens to it. Use a minimal frequency of `2`.\n",
        "Also create a vocabulary for the labels (tag field). However, since the tags are predefined elements, you will not need an `<unk>` token.\n",
        " This dataset actually has two different sets of tags, universal dependency (UD) tags and Penn Treebank (PTB) tags. We train our model on the UD tags, which is the second element on the list of outputs (example below).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IlEFywat4Gva",
      "metadata": {
        "id": "IlEFywat4Gva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "392feff4-5bd9-4031-d554-c3267ffb8305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Qaim', ',', 'near', 'the', 'Syrian', 'border', '.'], ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT'], ['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']]\n"
          ]
        }
      ],
      "source": [
        "train_iter = iter(UDPOS(split=\"train\"))\n",
        "print(next(train_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7HJWFvb3AgTI",
      "metadata": {
        "id": "7HJWFvb3AgTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d821ec-5310-4fa1-8c9d-bcc65cf2378c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 12543\n",
            "Number of validation examples: 2002\n",
            "Number of testing examples: 2077\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of training examples: {len(list(UDPOS(split='train')))}\")\n",
        "print(f\"Number of validation examples: {len(list(UDPOS(split='valid')))}\")\n",
        "print(f\"Number of testing examples: {len(list(UDPOS(split='test')))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RaAW09-n_5DC",
      "metadata": {
        "id": "RaAW09-n_5DC"
      },
      "source": [
        "Note that the data is already tokenized!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rcG-FcDu5DcA",
      "metadata": {
        "id": "rcG-FcDu5DcA"
      },
      "outputs": [],
      "source": [
        "train_iter = UDPOS(split=\"train\") # to get the training set\n",
        "\n",
        "### your code (make sure pad has id of 0) ####\n",
        "\n",
        "# A helper function to retrieve tokens from the training set\n",
        "def yield_tokens(train_iter, token_type):\n",
        "    for line in train_iter:\n",
        "        if token_type == 'text':\n",
        "            yield line[0]\n",
        "        elif token_type == 'tag':\n",
        "            yield line[1]\n",
        "\n",
        "\n",
        "# Generate the vocabularies for the text part\n",
        "vocab = build_vocab_from_iterator(iterator=yield_tokens(train_iter, token_type='text'), min_freq=2, specials=[\"<pad>\", \"<unk>\"])\n",
        "\n",
        "# Set the default index to the index of \"<unk>\"\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "# Generate the vocabularies for the tag part\n",
        "ud_vocab = build_vocab_from_iterator(iterator=yield_tokens(train_iter, token_type='tag'), min_freq=2, specials=[\"<pad>\"])\n",
        "\n",
        "### your code ####\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nzalgc92j2mG",
      "metadata": {
        "id": "nzalgc92j2mG"
      },
      "source": [
        "Prepare a text processing pipeline that takes raw input and labels and converts them to ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BDqKYQnRj2D8",
      "metadata": {
        "id": "BDqKYQnRj2D8"
      },
      "outputs": [],
      "source": [
        "text_pipeline = lambda x: vocab(x)\n",
        "label_pipeline = lambda x: ud_vocab(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wg36B2Z_Hdi0",
      "metadata": {
        "id": "wg36B2Z_Hdi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e60d33b-8232-47b1-fc6a-44fe4281242c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 9271, 35, 9097, 0, 1]\n",
            "[6, 8, 1, 2]\n"
          ]
        }
      ],
      "source": [
        "print(text_pipeline(['the', 'preacher', 'at', 'mosque', \"<pad>\",\"pppp\"])) #should output [3, 9271, 35, 9097, 0, 1]\n",
        "print(label_pipeline(['DET', 'ADJ', 'NOUN', 'PUNCT'])) # should output [6, 8, 1, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cjn1qH2dHoaa",
      "metadata": {
        "id": "cjn1qH2dHoaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c725638b-4b4a-4055-b095-3ea53fe39d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in input vocabulary: 9875\n",
            "Unique tokens in UD vocabulary: 18\n"
          ]
        }
      ],
      "source": [
        "print(f\"Unique tokens in input vocabulary: {len(vocab)}\")\n",
        "print(f\"Unique tokens in UD vocabulary: {len(ud_vocab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FUnDiAOW-N5S",
      "metadata": {
        "id": "FUnDiAOW-N5S"
      },
      "source": [
        "Write a custom function for the dataloader that applies the text and label pipeline and pads the sequences to have equal lengths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aN6s1UhoRhK",
      "metadata": {
        "id": "0aN6s1UhoRhK"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "def collate_batch(batch, pad_token_ix, pad_token_ix_ud):\n",
        "    ### your code ###\n",
        "\n",
        "    x_padded = [] #padded input\n",
        "\n",
        "    y_padded = [] #padded predictions\n",
        "\n",
        "    for text, ud_tag, ptb_tag in list(batch):\n",
        "\n",
        "        # Storing the IDs of vocabularies in a tensor\n",
        "        processed_text = torch.tensor(vocab(text), dtype=torch.int64)\n",
        "        processed_ud_tag = torch.tensor(ud_vocab(ud_tag), dtype=torch.int64)\n",
        "\n",
        "        # Append the tensors for the corresponding padding list\n",
        "        x_padded.append(processed_text)\n",
        "        y_padded.append(processed_ud_tag)\n",
        "\n",
        "\n",
        "    # Pad each list element with 0, i.e. <pad>\n",
        "    x_padded = nn.utils.rnn.pad_sequence(x_padded, batch_first=True, padding_value=0)\n",
        "    y_padded = nn.utils.rnn.pad_sequence(y_padded, batch_first=True, padding_value=0)\n",
        "\n",
        "\n",
        "    ### your code ###\n",
        "\n",
        "    return x_padded.to(device), y_padded.to(device)\n",
        "\n",
        "collate_fn = partial(collate_batch, pad_token_ix=vocab['<pad>'], pad_token_ix_ud=ud_vocab['<pad>'])\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    UDPOS(split=\"train\"), batch_size=128, shuffle=True, collate_fn=collate_fn\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    UDPOS(split=\"valid\"), batch_size=128, shuffle=True, collate_fn=collate_fn\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    UDPOS(split=\"test\"), batch_size=128, shuffle=True, collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2X8ZZ0J4oek_",
      "metadata": {
        "id": "2X8ZZ0J4oek_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8dfcebc-19f7-4e7d-83e2-2c6619a25b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 57])\n",
            "torch.Size([128, 57])\n",
            "tensor([1832,   13,   17,  488, 2837,    3, 3074,    1, 5532,  512,   13,   23,\n",
            "          56,  143,    5,  170,  154,  273,   39,  157,  971,   44, 2212,  648,\n",
            "           2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0], device='cuda:0')\n",
            "tensor([14,  4,  9, 12,  3,  6,  1,  1, 10, 17,  4,  3, 10, 13,  5, 13,  1, 10,\n",
            "        14,  9,  3,  5,  7,  7,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for idx, (label, text) in enumerate(train_dataloader):\n",
        "      print(label.shape)\n",
        "      print(text.shape)\n",
        "      print(label[0])\n",
        "      print(text[0])\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jDy_wvjR_1Sg",
      "metadata": {
        "id": "jDy_wvjR_1Sg"
      },
      "source": [
        "Let's take a closer look at the data and the distribution of tags.\n",
        "Implement `tag_percentage`:\n",
        "\n",
        "*   Use the `collection.counter` to count the unique instances of each tag.\n",
        "\n",
        "*    Compute the percentage of each tag in the entire set, by using the counted frequencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273JqNZn_rRT",
      "metadata": {
        "id": "273JqNZn_rRT"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def tag_percentage(training_iterator):\n",
        "    counter = Counter()\n",
        "    #### your code to count the number of tags\n",
        "\n",
        "    training_iterator_list = list(training_iterator)\n",
        "\n",
        "    for text, ud_tag, ptb_tag in training_iterator_list:\n",
        "        counter.update(ud_tag)\n",
        "\n",
        "    ###\n",
        "    ### compute the tag percentages based on the counter object\n",
        "\n",
        "    tag_p = [(tag, counter[tag], (counter[tag] / sum(counter.values())) * 100.0) for tag in counter] #precentages\n",
        "    ###\n",
        "    return tag_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fWzoEd7h_qRw",
      "metadata": {
        "id": "fWzoEd7h_qRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e352e1e-0ec9-4598-8be5-06f139aa1d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag\t\tCount\t\tPercentage\n",
            "\n",
            "PROPN\t\t12946\t\t632.7%\n",
            "PUNCT\t\t23679\t\t1157.3%\n",
            "ADJ\t\t12477\t\t609.8%\n",
            "NOUN\t\t34781\t\t1699.9%\n",
            "VERB\t\t23081\t\t1128.1%\n",
            "DET\t\t16285\t\t795.9%\n",
            "ADP\t\t17638\t\t862.1%\n",
            "AUX\t\t12343\t\t603.3%\n",
            "PRON\t\t18577\t\t907.9%\n",
            "PART\t\t5567\t\t272.1%\n",
            "SCONJ\t\t3843\t\t187.8%\n",
            "NUM\t\t3999\t\t195.4%\n",
            "ADV\t\t10548\t\t515.5%\n",
            "CCONJ\t\t6707\t\t327.8%\n",
            "X\t\t847\t\t41.4%\n",
            "INTJ\t\t688\t\t33.6%\n",
            "SYM\t\t599\t\t29.3%\n"
          ]
        }
      ],
      "source": [
        "print(\"Tag\\t\\tCount\\t\\tPercentage\\n\")\n",
        "\n",
        "for tag, count, percent in tag_percentage(UDPOS(split='train')):\n",
        "    print(f\"{tag}\\t\\t{count}\\t\\t{percent*100:4.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHLSnb2nel8_"
      },
      "source": [
        "####${\\color{red}{Comments\\ 1.1}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "- The percentage has been miscalculated and is not presented in descending order (-0.5 point)\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "id": "dHLSnb2nel8_"
    },
    {
      "cell_type": "markdown",
      "id": "gYHy3vSELfaN",
      "metadata": {
        "id": "gYHy3vSELfaN"
      },
      "source": [
        "### Subtask 2: The Model\n",
        "\n",
        "We start by creating a simple model and then make it more complex in later subtasks. The class `BiLSTMTagger` must subclass the `nn.Module` class of `PyTorch`. Fill the blank in the class by following the notes described below.\n",
        "1.   The input is a sequence of tokens, $X = \\{x_1, x_2,...,x_T\\}$.\n",
        "2.   Each token passes through  an embeddings layer, $e(X) = \\{e(x_1), e(x_2), ..., e(x_T)\\}$. Use `nn.Embedding` for the embedding layer and make sure to pass in the index of the pad token.\n",
        "3. Embedding is processed by forward and backward LSTMs from left to right and right to left.  The first input to the forward LSTM is $x_1$ and the first input to the backward LSTM is $x_T$. The hidden state of LSTMs is dependent on\n",
        "the hidden, $h$, and cell, $c$, states from the previous time-steps:\n",
        "$$h^{\\rightarrow}_t = \\text{LSTM}^{\\rightarrow}(e(x^{\\rightarrow}_t), h^{\\rightarrow}_{t-1}, c^{\\rightarrow}_{t-1})$$\n",
        "$$h^{\\leftarrow}_t=\\text{LSTM}^{\\leftarrow}(e(x^{\\leftarrow}_t), h^{\\leftarrow}_{t-1}, c^{\\leftarrow}_{t-1})$$\n",
        "4. The hidden, $h$, and cell, $c$ of each layer is passed to the next layer, where the $h_0$ and $c_0$, for each direction and layer, are initialized to a tensor full of zeros. Use `nn.LSTM` for LSTM cells. How can you make it bidirectional?\n",
        "5. Final hidden state is the concatenation of forward and backward hidden states from the final layer of the LSTM, $H = \\{h_1, h_2, ... h_T\\}$, where $h_1 = [h^{\\rightarrow}_1;h^{\\leftarrow}_T]$, $h_2 = [h^{\\rightarrow}_2;h^{\\leftarrow}_{T-1}]$. Use `nn.Linear` here.\n",
        "6. The last layer is linear layer $f$, which is used to make the prediction of which tag applies to this token, $\\hat{y}_t = f(h_t)$.\n",
        "7. Define a `nn.Dropout` layer to apply to the embeddings and the outputs of the final layer of the LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qE4GQE6NJ1k8",
      "metadata": {
        "id": "qE4GQE6NJ1k8"
      },
      "outputs": [],
      "source": [
        "class BiLSTMTagger(nn.Module):\n",
        "    def __init__(self, hyperparameters):\n",
        "      '''\n",
        "      hyperparameters: is a dictionary containing:\n",
        "                 input_dim: dimension of the input\n",
        "                 embedding_dim: dimension of the embedding layer\n",
        "                 lstm_hidden_dim:: dimension of the hidden state of lstms\n",
        "                 output_dim: dimension of the output hidden layer\n",
        "                 n_layers: number of layers to stack\n",
        "                 bidirectional: is the lstm bi-directional\n",
        "                 dropout: probability for the drop out layer\n",
        "                 pad_idx: id of the pad token\n",
        "      '''\n",
        "      super().__init__()\n",
        "       #### your code ####\n",
        "      #embedding layer\n",
        "      self.embedding = nn.Embedding(hyperparameters['input_dim'], hyperparameters['embedding_dim'], padding_idx=hyperparameters['pad_idx'])\n",
        "      #bi-lstm, apply dropout if the number of layers is more than 1\n",
        "      self.lstm = nn.LSTM(hyperparameters['embedding_dim'], hyperparameters['lstm_hidden_dim'], num_layers=hyperparameters['n_layers'], bidirectional=hyperparameters['bidirectional'], dropout=hyperparameters['dropout'] if hyperparameters['n_layers'] > 1 else 0)\n",
        "      self.fc = nn.Linear(hyperparameters['lstm_hidden_dim'] * 2 if hyperparameters['bidirectional'] else hyperparameters['lstm_hidden_dim'], hyperparameters['output_dim'])\n",
        "      self.dropout = nn.Dropout(hyperparameters['dropout'])\n",
        "      #### your code ####\n",
        "    def forward(self, text, debug=False): #(B,S)\n",
        "      '''\n",
        "      S: sentence len\n",
        "      B: batch size\n",
        "      E: embedding size\n",
        "      H: hidden size\n",
        "      O:output size\n",
        "      L: number of layers\n",
        "      '''\n",
        "      #### your code ####\n",
        "      #pass text through embedding layer and a drop out layer\n",
        "      embd = self.dropout(self.embedding(text))\n",
        "\n",
        "\n",
        "      #pass embeddings into bi-LSTM\n",
        "      outputs, (hidden, cell) = self.lstm(embd)\n",
        "\n",
        "      #compute prediction\n",
        "      predictions = self.fc(self.dropout(outputs))\n",
        "      #### your code ####\n",
        "\n",
        "      if debug==True:\n",
        "        print(\"Input shape:\",text.shape)\n",
        "        print(\"Embedding shape:\",embd.shape)\n",
        "        print(\"LSTM output shape:\",outputs.shape)\n",
        "        print(\"LSTM hidden shape:\",hidden.shape)\n",
        "        print(\"LSTM cell shape:\",cell.shape)\n",
        "        print(\"Output shape:\",predictions.shape)\n",
        "\n",
        "      return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4OcQbD9LUkD5",
      "metadata": {
        "id": "4OcQbD9LUkD5"
      },
      "source": [
        "Response in plain text:\n",
        "1. Based on the notation defined in the forward function. What is the dimension of `outputs`, `hidden`, and `cell`?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ml4KUd1BU3op",
      "metadata": {
        "id": "ml4KUd1BU3op"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ivB8Iv4yScVW",
      "metadata": {
        "id": "ivB8Iv4yScVW"
      },
      "outputs": [],
      "source": [
        "hyper_parameters={\n",
        "  'input_dim':  len(vocab),\n",
        "  'embedding_dim': 100,\n",
        "  'lstm_hidden_dim': 128,\n",
        "  'output_dim':len(ud_vocab),\n",
        "  'n_layers': 2 ,\n",
        "  'bidirectional':True,\n",
        "  'dropout': 0.25,\n",
        "  'pad_idx': vocab['<pad>']\n",
        "}\n",
        "model = BiLSTMTagger(hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1XvNFfJBV7ya",
      "metadata": {
        "id": "1XvNFfJBV7ya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b96bf3-013e-4919-b3bb-4947860997b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 6])\n",
            "Embedding shape: torch.Size([2, 6, 100])\n",
            "LSTM output shape: torch.Size([2, 6, 256])\n",
            "LSTM hidden shape: torch.Size([4, 6, 128])\n",
            "LSTM cell shape: torch.Size([4, 6, 128])\n",
            "Output shape: torch.Size([2, 6, 18])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "input=torch.tensor([[3, 9271, 35, 9097, 0, 1],\n",
        "                    [3, 9271, 35, 9097, 0, 1]])\n",
        "model(input,debug=True).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2XiJkG-NfrDV",
      "metadata": {
        "id": "2XiJkG-NfrDV"
      },
      "source": [
        "Weights of the network are initialized randomly, so let's make a more systematic initialization to help us with the optimization. For example,  Xavier Initialization creates weights such that the variance of the activations is the same across every layer. This constant variance helps prevent the gradient from exploding or vanishing. However, it does not apply to bias terms.\n",
        "\n",
        "Create a function that uses Xavier Initialization to initialize the weights of the network, for biases use a normal distribution with a mean of 0 and a standard deviation of 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PB78pCHpa758",
      "metadata": {
        "id": "PB78pCHpa758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35286d07-4aec-4147-a879-6199030e728d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTMTagger(\n",
              "  (embedding): Embedding(9875, 100, padding_idx=0)\n",
              "  (lstm): LSTM(100, 128, num_layers=2, dropout=0.25, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=18, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "\n",
        "  ### you code ###\n",
        "  for name, param in m.named_parameters():\n",
        "    nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "  ### your code ###\n",
        "model.apply(init_weights)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sdPx1mSOgy0V",
      "metadata": {
        "id": "sdPx1mSOgy0V"
      },
      "source": [
        "Let's count the number of trainable parameters in our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P5738nU2ew_O",
      "metadata": {
        "id": "P5738nU2ew_O",
        "outputId": "f6dd1bd2-10d9-4420-dca1-4558ebbdb165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of trainable parameters: 1622910\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "  ### your code ###\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  ### your code ###\n",
        "\n",
        "print(\"number of trainable parameters:\",count_parameters(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZhYQJ-del9D"
      },
      "source": [
        "####${\\color{red}{Comments\\ 1.2}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "- No solution for 1. question in given notations (-0.5)\n",
        "- correct solution for output, hidden cell shapes\n",
        "- Model implementation and forward function correct\n",
        "- No distinction between bias vs weights made(-0.5)\n",
        "- correct num parameters\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "id": "ZZhYQJ-del9D"
    },
    {
      "cell_type": "markdown",
      "id": "-lVg08iTd0XN",
      "metadata": {
        "id": "-lVg08iTd0XN"
      },
      "source": [
        "### Subtask 3: Training\n",
        "\n",
        "We start by defining a loss function and an optimizer.\n",
        "\n",
        "\n",
        "*   **optimizer:** We use Adam with the learning rate=0.0001.\n",
        "*   **loss:** We use cross-entropy loss.\n",
        "\n",
        "Even though we have no `<unk>` tokens within our tag vocab, we still have `<pad>` tokens to create batches of the same size. However, we do not want to calculate loss on those tokens, so make sure you define your loss function in such a way that ignores the `<pad>` tokens.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8LEyNeKhmBvK",
      "metadata": {
        "id": "8LEyNeKhmBvK"
      },
      "outputs": [],
      "source": [
        "### your code ###\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=ud_vocab['<pad>'])\n",
        "### your code ###"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95Cf7ZcVgLHK",
      "metadata": {
        "id": "95Cf7ZcVgLHK"
      },
      "source": [
        "Watching the loss go down as you train a model is a good indication of the correct training procedure, but does not tell us how well we are doing on a given task.\n",
        "To this end, we also implement a categorical accuracy measure to keep track of how well our model is doing on a given task.\n",
        "Same as before: we don't want to calculate accuracy over the `<pad>` tokens as we aren't interested in predicting them.\n",
        "Implement the function `categorical_acc` to compare the prediction of non-pad tokens with labels count the correct ones and calculate the accuracy over a single batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J5OpDKuBitk1",
      "metadata": {
        "id": "J5OpDKuBitk1"
      },
      "outputs": [],
      "source": [
        "def categorical_acc(preds, gt, pad_idx):\n",
        "    \"\"\"\n",
        "    Returns categorical accuracy per batch\n",
        "    \"\"\"\n",
        "    ### your code ####\n",
        "    # get the index of the max probability\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
        "    # categorical accuracy\n",
        "    non_pad_elements = (gt != pad_idx).nonzero()\n",
        "    correct = max_preds[non_pad_elements].squeeze(1).eq(gt[non_pad_elements])\n",
        "    temp =  correct.sum() / torch.FloatTensor([gt[non_pad_elements].shape[0]])\n",
        "\n",
        "    return temp\n",
        "     ### your code ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WANOhA56kjY_",
      "metadata": {
        "id": "WANOhA56kjY_"
      },
      "outputs": [],
      "source": [
        "dummpy_input=torch.tensor([\n",
        "    [0.9,0,0,0],\n",
        "    [0.1,0.9,0,0],\n",
        "    [0.1,0,0,0.9],\n",
        "    [0.9,0.1,0,0],\n",
        "    [0.1,0.8,0,0]\n",
        "\n",
        "])\n",
        "categorical_acc(dummpy_input, torch.tensor([0,2,3,0,1]), 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y_wngIs7jFrT",
      "metadata": {
        "id": "y_wngIs7jFrT"
      },
      "source": [
        "Define the `train` model that performs one epoch of training. You can refer to the Tutorial 2 of the course to get a sample workflow. The only difference to the tutorial is that we keep track of the batch-wise accuracy as well as the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kyMs0FJNfGCp",
      "metadata": {
        "id": "kyMs0FJNfGCp"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, loss_function, pad_idx):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    for length_dataloader,(text,tags) in enumerate(dataloader):\n",
        "        #### your code ####\n",
        "\n",
        "\n",
        "        #### your code ####\n",
        "    end_time= time.time() - epoch_start_time\n",
        "    return epoch_loss / length_dataloader, epoch_acc / length_dataloader,end_time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W0ytUn7vkdcR",
      "metadata": {
        "id": "W0ytUn7vkdcR"
      },
      "source": [
        "It is not enough to only look at the training loss and accuracy, since with more training, we can always do better on the training set, but lose the generalizability to unseen data, a phenomenon known as **overfitting**. Therefore, it is important to check the loss and accuracy on the validation set after each epoch and stop before  overfitting occurs. Moreover, we can use the validation metric as an indication of which checkpoint of our model is the best.\n",
        "\n",
        "Define an `evaluate` function that runs once through the validation set and computes loss and accuracy. **Note:** You should not be updating gradients here and your model should be in evaluation mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0CKzEqyAfktd",
      "metadata": {
        "id": "0CKzEqyAfktd"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, loss_function, pad_idx):\n",
        "\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "\n",
        "    ### your code ###\n",
        "\n",
        "     ### your code ###\n",
        "\n",
        "    return val_loss / length_dataloader, val_acc / length_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3AZJidLFnOUW",
      "metadata": {
        "id": "3AZJidLFnOUW"
      },
      "source": [
        "Let's use the functions defined so far and train our model for `30` epochs. We suggest using GPU for this task, as it is quite slow on the CPU. Run the training loop for the given number of epochs and calculate the validation metric at the end of each epoch. Based on the validation loss, save the best checkpoint of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NblN-U0inVYc",
      "metadata": {
        "id": "NblN-U0inVYc"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    ### your code ###\n",
        "    train_loss, train_acc, epoch_time =\n",
        "    valid_loss, valid_acc =\n",
        "\n",
        "\n",
        "    ### your code ###\n",
        "    elapsed_mins = int(epoch_time / 60)\n",
        "    elapsed_secs = int(epoch_time - (elapsed_mins * 60))\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {elapsed_mins}m {elapsed_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Validation Loss: {valid_loss:.3f} |  Validation Acc: {valid_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dXTYFEbHzNL",
      "metadata": {
        "id": "7dXTYFEbHzNL"
      },
      "source": [
        "Question:\n",
        "\n",
        "1. Does overfitting occur? If so, after which epochs?\n",
        "\n",
        "2. How do you detect overfitting?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9qSbr8CrH9hD",
      "metadata": {
        "id": "9qSbr8CrH9hD"
      },
      "source": [
        "**Answer:**\n",
        "```\n",
        "Write your answer here.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GmqNesqiMISb",
      "metadata": {
        "id": "GmqNesqiMISb"
      },
      "source": [
        "Let's see how well our model is doing on the test set. Load the best checkpoint and calculate the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SgCFqby0m8sf",
      "metadata": {
        "id": "SgCFqby0m8sf"
      },
      "outputs": [],
      "source": [
        "#### you code ####\n",
        "\n",
        "#### you code ####\n",
        "test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYockWm6el9H"
      },
      "source": [
        "####${\\color{red}{Comments\\ 1.3}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "- The learning rate is set to 0.001 instead of 0.0001 during initialization.\n",
        "- function train model is missing: zero_grad(), .step() .backward() (-1 point)\n",
        "- loss function is not called (-0.25 point)\n",
        "- loss and accuracy are missing (-0.25 point)\n",
        "- model.eval is not used (-0.25 point)\n",
        "- the rest of the function is not completed (-0.5 point)\n",
        "- the training and validation are not called (-0.25 point)\n",
        "- checkpoint is not saved (-0.25 point)\n",
        "- answer is missing for question 1 (-0.25 point)\n",
        "- answer is missing for question 2 (-0.25 point)\n",
        "- accuracy is not calculated (-0.25 point)\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "id": "XYockWm6el9H"
    },
    {
      "cell_type": "markdown",
      "id": "7dPfzmVGMeSO",
      "metadata": {
        "id": "7dPfzmVGMeSO"
      },
      "source": [
        "### Subtask 4: Inference\n",
        "\n",
        "Let's use the model we trained to tag some actual sentences. We have the preprocessing pipeline ready from Subtask 1, now we need to map the predictions back to label texts for each token.\n",
        "\n",
        "Implement the `tag_sequence` function that takes a model and a sentence as input and generates POS tags. Keep in mind that you need to divide the sentence into tokens first. For this purpose, we just split each sentence on whitespaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xe7_ROCyEslD",
      "metadata": {
        "id": "Xe7_ROCyEslD"
      },
      "outputs": [],
      "source": [
        "def tag_sentence(model, sentence):\n",
        "    ### your code ###\n",
        "\n",
        "\n",
        "    predictions = # make predictions on th esentence\n",
        "\n",
        "\n",
        "    predicted_tags = # get the tags\n",
        "    ### your code ###\n",
        "    return predicted_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JtiR75PFRR61",
      "metadata": {
        "id": "JtiR75PFRR61"
      },
      "outputs": [],
      "source": [
        "text=\" \".join(list(UDPOS(split='test'))[0][0])\n",
        "label= list(UDPOS(split='test'))[0][1]\n",
        "predicted_tag=tag_sentence(model,text)\n",
        "print(\"Text: \",text)\n",
        "print(\"Predicted Tags: \",predicted_tag)\n",
        "print(\"True Tags: \",label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kueNkHPKel9J"
      },
      "source": [
        "####${\\color{red}{Comments\\ 1.4}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "- prediction doesn't exist (-0.5)\n",
        "\n",
        "total 11 − 0.5 - 1.0 - 3.5 - 0.5 = 5.5 points\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ],
      "id": "kueNkHPKel9J"
    },
    {
      "cell_type": "markdown",
      "id": "X4n7Xi4TT_Ww",
      "metadata": {
        "id": "X4n7Xi4TT_Ww"
      },
      "source": [
        "## **Task 2: Theoretical Questions** (0.5+1.5+1+3=6 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QbQJ3baXUHkQ",
      "metadata": {
        "id": "QbQJ3baXUHkQ"
      },
      "source": [
        "### Subtask 1:\n",
        "In beam search, if you increase the beam width, what will happen to a) the runtime and memory and b) the quality of results?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ei5A-D_djZup",
      "metadata": {
        "id": "Ei5A-D_djZup"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "\n",
        "```\n",
        "a) Increasing beam width generally increases runtime and memory usage.\n",
        "b) Increasing beam width can improve the quality of results by exploring a larger search space but may also lead to more redundancy.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RuzX2q7TywyW",
      "metadata": {
        "id": "RuzX2q7TywyW"
      },
      "source": [
        "####${\\color{red}{Comments\\ 2.1}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "- a is correct\n",
        "- b is correct\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N7KlRPnhknbl",
      "metadata": {
        "id": "N7KlRPnhknbl"
      },
      "source": [
        "### Subtask 2:\n",
        "Except for beam search, there are other ways to create a more coherent output for generation tasks, one of which is adding a temperature to the softmax over the vocabulary. Temperature is a hyperparameter that is applied to the input of a softmax to affect the final probabilities. All values in the input are divided by the temperature before going through the softmax. What do you think will happen in these cases:\n",
        "\n",
        "1. A low temperature - below 1\n",
        "2. A high temperature - above 1\n",
        "3. Really small temperature - temperature $→$ 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uxuh5LOFnF3D",
      "metadata": {
        "id": "uxuh5LOFnF3D"
      },
      "source": [
        "**Answer:**\n",
        "```\n",
        "Low temperature (below 1): This will make the probability distribution more peaked. It will emphasize high-probability words and suppress the influence of low-probability words. The generated output is likely to be more focused and deterministic.\n",
        "\n",
        "High temperature (above 1): This will make the probability distribution flatter. It will assign more equal probabilities to a broader range of words, including both high and low-probability words. The generated output is likely to be more diverse but might lack precision.\n",
        "\n",
        "Really small temperature (approaching 0): As the temperature approaches zero, the softmax operation amplifies differences between the input values. This results in a distribution that tends to have a single dominant probability. The output becomes highly deterministic, with a strong focus on the word with the highest probability.\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GmW4NNb4yyZF",
      "metadata": {
        "id": "GmW4NNb4yyZF"
      },
      "source": [
        "####${\\color{red}{Comments\\ 2.2}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "cross-feedback comment section\n",
        "- 1 is correct\n",
        "- 2 is correct\n",
        "- 3 is correct but could've been used better terminology ,for temperature zero case, to describe highly deterministic ---> greedy\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tM2DmNOwod4r",
      "metadata": {
        "id": "tM2DmNOwod4r"
      },
      "source": [
        "### Subtask 3:\n",
        "Explain what the “bottleneck” of an encoder-decoder RNN is and how attention provides a way to get around this bottleneck."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DNJ3f_MtdzrM",
      "metadata": {
        "id": "DNJ3f_MtdzrM"
      },
      "source": [
        "**Answer:**\n",
        "```\n",
        "The \"bottleneck\" in an encoder-decoder RNN refers to the fixed-size internal representation (context vector) that the encoder produces for the entire input sequence. This fixed-size representation may struggle to capture all relevant information, especially in long sequences. Attention mechanisms address this bottleneck by allowing the decoder to dynamically focus on different parts of the input sequence when generating each element of the output sequence. This way, attention provides a flexible way to access and utilize the entire input sequence during the decoding process, improving the model's ability to handle long-range dependencies and capture relevant information.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JFUHVF40y0j-",
      "metadata": {
        "id": "JFUHVF40y0j-"
      },
      "source": [
        "####${\\color{red}{Comments\\ 2.3}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "- the solution correctly describes the bottleneck in RNN and explains advatange of attention for long sequences. It is correct thus.\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HaHhdLdJehL3",
      "metadata": {
        "id": "HaHhdLdJehL3"
      },
      "source": [
        "### Subtask 4:\n",
        "As mentioned, there are various way to remedy the repetitiveness and incoherence of generation outputs. One of the widely used methods is Nucleus sampling described the paper \"[ The Curious Case of Neural Text DeGeneration](https://arxiv.org/pdf/1904.09751.pdf)\". Read the model section and introduction of the paper and use it as reference to answer the following questions:\n",
        "\n",
        "1. Describe top-k sampling in your own words, no need for mathematical notation.\n",
        "2. Describe Nucleus sampling in your own words, there is not need for mathematical notation.\n",
        "3.  Why is beam search not a good strategy for human-like text generation and why don't these methods suffer from the problem of the beam search?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9Ojtbn1kgaYE",
      "metadata": {
        "id": "9Ojtbn1kgaYE"
      },
      "source": [
        "**Answer:**\n",
        "```\n",
        "**Top-k Sampling:**\n",
        "In top-k sampling, during the generation process, instead of sampling from the entire vocabulary, only the top-k most likely words are considered. The model's probabilities are calculated for all words, and then the sampling is confined to the k words with the highest probabilities. This helps in limiting the randomness of the generated text and provides a balance between controlled output and diversity.\n",
        "\n",
        "**Nucleus Sampling:**\n",
        "Nucleus sampling is an extension of top-k sampling. Rather than fixing the number of options (k), nucleus sampling involves sampling from the smallest set of words whose cumulative probability exceeds a certain threshold (nucleus probability). This dynamic approach adapts to the changing distribution of word probabilities, allowing for more flexibility in controlling the diversity of generated text.\n",
        "\n",
        "**Beam Search Limitations:**\n",
        "Beam search is a strategy that explores multiple possible sequences during generation and selects the one with the highest overall probability. However, beam search tends to produce outputs that are too focused and may lack diversity. It often converges to a narrow set of possibilities, leading to repetitive and less human-like text.\n",
        "\n",
        "**Advantages of Top-k and Nucleus Sampling:**\n",
        "Top-k and nucleus sampling allow for more diverse and contextually relevant outputs. By not strictly adhering to a fixed beam width, these methods can capture a wider range of possibilities and avoid the narrow focus problem of beam search. They provide a balance between exploring various options and maintaining coherence in the generated text, making them more suitable for human-like text generation.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0wU67Iqpy2rg",
      "metadata": {
        "id": "0wU67Iqpy2rg"
      },
      "source": [
        "####${\\color{red}{Comments\\ 2.4}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "- 1 is correct\n",
        "- 2 is correct\n",
        "- 3 is incorrect (-1.0), it seems correct in very simple terminology but lacks the explanation with tail distribution. It also fails to address 2nd part of question.\n",
        "\n",
        "\n",
        "total points: 0.5 + 1.5 + 1 + (3-1) = 5\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IZl0-MMY6MWs",
      "metadata": {
        "id": "IZl0-MMY6MWs"
      },
      "source": [
        "## **Task 3: Scaled Dot-Product Attention** (4+1=5 points)\n",
        "In class, you learned about attention and Transformers as described in the 2017 paper\n",
        "[Attention Is All You Need](https://arxiv.org/abs/1706.03762).\n",
        "The base of the attention module is a scaled dot product with Queries, Keys, and Values.\n",
        "In this task, you will implement a simplified version of scaled dot-product attention and inspired by the translation task, aim to replicate word alignment between English and French.\n",
        "You will not be training the embedding from scratch, we provide you with pre-trained embedding for both languages.\n",
        "However, you need to know the details of scaled dot product attention, which mainly consists of two matrix multiplications and a softmax scaling.\n",
        "Refer to Figure 2 of the [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper.\n",
        "\n",
        "The inputs of the attention module are Queries, Keys, and Values. Mathematically, attention is defined as follows:\n",
        "\n",
        "$$\n",
        "\\large \\mathrm{Attention}\\left(Q, K, V\\right) = \\mathrm{softmax}\\left(\\frac{QK^{\\top}}{\\sqrt{d_k}}\\right)V\n",
        "$$\n",
        "\n",
        "\n",
        "*   $Q$, $K$, and $V$ are the Queries, Keys, and Values matrices.\n",
        "* $d_k$ is the dimension of the Keys (in practice dimensions of all matrices are the same).\n",
        "*   $QK^{\\top}$ is a measure of the similarity between the Queries and the Keys\n",
        "* softmax transforms the similarity into weights.\n",
        "* Weights multiplied by the Values are the output of the attention, defining how much importance should be given to each token of the input.\n",
        "\n",
        "In the case of self-attention, both Queries and Keys come from the encoder, however, for cross attention between encoder and decoder, decoder states are used as the queries while encoder states are the Keys and Values.\n",
        "In our case, we need the cross attention between one language to another to find the correct alignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gOP3Fa8IfkMK",
      "metadata": {
        "id": "gOP3Fa8IfkMK",
        "outputId": "591e515a-17e9-4dcf-87b7-2dc59bb93fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.8.2-cp310-cp310-win_amd64.whl.metadata (5.9 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.2.0-cp310-cp310-win_amd64.whl.metadata (5.8 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.45.1-cp310-cp310-win_amd64.whl.metadata (158 kB)\n",
            "     ---------------------------------------- 0.0/158.4 kB ? eta -:--:--\n",
            "     -------------------------------------- 158.4/158.4 kB 3.2 MB/s eta 0:00:00\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\prdie\\dropbox\\1ws2324\\inlpt\\inlpt\\nlp_env\\lib\\site-packages (from matplotlib) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\prdie\\dropbox\\1ws2324\\inlpt\\inlpt\\nlp_env\\lib\\site-packages (from matplotlib) (23.2)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-win_amd64.whl.metadata (9.6 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\prdie\\dropbox\\1ws2324\\inlpt\\inlpt\\nlp_env\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\prdie\\dropbox\\1ws2324\\inlpt\\inlpt\\nlp_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Downloading matplotlib-3.8.2-cp310-cp310-win_amd64.whl (7.6 MB)\n",
            "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 0.7/7.6 MB 14.8 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 1.3/7.6 MB 14.0 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 1.9/7.6 MB 13.5 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 2.5/7.6 MB 14.5 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 3.1/7.6 MB 14.1 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 3.7/7.6 MB 13.9 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 4.3/7.6 MB 13.8 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 4.9/7.6 MB 13.6 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 5.5/7.6 MB 13.5 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 6.1/7.6 MB 13.0 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 6.7/7.6 MB 13.0 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 7.3/7.6 MB 13.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  7.6/7.6 MB 13.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.6/7.6 MB 12.5 MB/s eta 0:00:00\n",
            "Downloading contourpy-1.2.0-cp310-cp310-win_amd64.whl (186 kB)\n",
            "   ---------------------------------------- 0.0/186.7 kB ? eta -:--:--\n",
            "   --------------------------------------- 186.7/186.7 kB 11.8 MB/s eta 0:00:00\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.45.1-cp310-cp310-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 0.6/2.2 MB 19.5 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.2/2.2 MB 15.6 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 1.8/2.2 MB 14.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 12.5 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl (56 kB)\n",
            "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 56.1/56.1 kB ? eta 0:00:00\n",
            "Downloading Pillow-10.1.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
            "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
            "   -------- ------------------------------- 0.6/2.6 MB 18.2 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.2/2.6 MB 15.1 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.8/2.6 MB 14.1 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.4/2.6 MB 13.7 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.5/2.6 MB 11.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.6/2.6 MB 10.4 MB/s eta 0:00:00\n",
            "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "   ---------------------------------------- 0.0/103.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 103.1/103.1 kB 5.8 MB/s eta 0:00:00\n",
            "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.45.1 kiwisolver-1.4.5 matplotlib-3.8.2 pillow-10.1.0 pyparsing-3.1.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tB6RD3wssHe9",
      "metadata": {
        "id": "tB6RD3wssHe9"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#load the dictionaries (dictionary of words to ids)\n",
        "with open(\"./word2int_en.pkl\", \"rb\") as f:\n",
        "    en_dict = pickle.load(f)\n",
        "\n",
        "with open(\"./word2int_fr.pkl\", \"rb\") as f:\n",
        "    fr_dict = pickle.load(f)\n",
        "\n",
        "# load word embeddings (dictionary of token ids to embeddings)\n",
        "en_embeddings = np.load(\"./embeddings_en.npz\")[\"embeddings\"]\n",
        "fr_embeddings = np.load(\"./embeddings_fr.npz\")[\"embeddings\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7VYjN1xHsbYj",
      "metadata": {
        "id": "7VYjN1xHsbYj"
      },
      "source": [
        "### Subtask 1: Attention Weights\n",
        "Fill the blanks in `tokenize` to tokenize a sentence and convert it to ids and `embed` function to create an embedding of a sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cwS_M10nwOBH",
      "metadata": {
        "id": "cwS_M10nwOBH"
      },
      "outputs": [],
      "source": [
        "def tokenize(sentence, token_mapping):\n",
        "    # token_mapping contains 10000 words to their ids\n",
        "    # we stick to simple blank space tokenization\n",
        "    tokenized = []\n",
        "    for word in sentence.lower().split(\" \"):\n",
        "        ### your code ###\n",
        "        # if the word is in token mapping, then take its id from token_mapping\n",
        "        if word in token_mapping:\n",
        "            tokenized.append(token_mapping[word])\n",
        "        else:\n",
        "            # if not in the token mapping, use -1 as id (suggested by Almasian, Shideh)\n",
        "            # print(\"NOT FOUND\")\n",
        "            # print(f\"NOT FOUND {word}\")\n",
        "            tokenized.append(-1)\n",
        "        ### your code ###\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "def embed(tokens, embeddings):\n",
        "    \"\"\" get the embedding for the tokens in a sentence stacked in a simple matrix (sequence length, embedding size)\n",
        "        tokens: tokenized sentence\n",
        "        embeddings: dictionary of token to embeddings.\n",
        "    \"\"\"\n",
        "    embed_size = embeddings.shape[1]\n",
        "    #### your code ####\n",
        "    seq_length = len(tokens)\n",
        "    output = np.zeros((seq_length, embed_size)) # initially everything is 0\n",
        "    for i, token in enumerate(tokens):\n",
        "        if 0 <= token < embeddings.shape[0]: # check if we have an embedding for the given token\n",
        "            output[i] = embeddings[token]\n",
        "        else: # if we do not have an embedding for the token\n",
        "            output[i] = np.zeros(embed_size) # np.random.rand(embed_size) could be used to add a random embedding\n",
        "    #### your code ####\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dkAulXarueT_",
      "metadata": {
        "id": "dkAulXarueT_",
        "outputId": "a797b63e-6d5c-4e70-f197-d847af9f657e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized english: [59, 40, 9355, 6, 158, -1]\n",
            "embedding english: (6, 300)\n",
            "Tokenized french: [21, 73, 192, 16, 8652, -1, 558, -1]\n",
            "embedding french: (8, 300)\n"
          ]
        }
      ],
      "source": [
        "sentence_en = \"there were clouds in my coffeeeeee.\"\n",
        "tokenized_en = tokenize(sentence_en, en_dict)\n",
        "embedded_en = embed(tokenized_en, en_embeddings)\n",
        "print(\"Tokenized english:\",tokenized_en)\n",
        "print(\"embedding english:\",embedded_en.shape)\n",
        "\n",
        "sentence_fr = \"il y avait des nuages ​​dans mon ccafé.\"\n",
        "tokenized_fr = tokenize(sentence_fr, fr_dict)\n",
        "embedded_fr = embed(tokenized_fr, fr_embeddings)\n",
        "print(\"Tokenized french:\",tokenized_fr)\n",
        "print(\"embedding french:\",embedded_fr.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WJ58FCMpsHJP",
      "metadata": {
        "id": "WJ58FCMpsHJP"
      },
      "source": [
        "\n",
        "Implement the `softmax` function with `Numpy`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caOjXfbxon9h",
      "metadata": {
        "id": "caOjXfbxon9h"
      },
      "outputs": [],
      "source": [
        "def softmax(x, axis=0):\n",
        "    \"\"\"\n",
        "    x: input matrix\n",
        "    axis: defines which axis to compute the softmax over 0 for rows and 1 for columns\n",
        "        axis=0 calculates softmax across rows which means each column sums to 1\n",
        "        axis=1 calculates softmax across columns which means each row sums to 1\n",
        "    \"\"\"\n",
        "\n",
        "    #### your code ####\n",
        "    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True)) # use shifting to avoid overflow\n",
        "    softmax_x = exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n",
        "    #### your code ####\n",
        "\n",
        "    return softmax_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kCbjmG49p-v0",
      "metadata": {
        "id": "kCbjmG49p-v0",
        "outputId": "0383897c-8ba3-4f98-e8c8-9e348f542d12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w=softmax(np.array([[1,3,4,1], [24,3,2,3]]),axis=0)\n",
        "w.sum(axis=0)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oNqtNPB9orLr",
      "metadata": {
        "id": "oNqtNPB9orLr"
      },
      "source": [
        "Use the `softmax` function to calculate the weights.\n",
        "$$ \\mathrm{softmax}\\left(\\frac{QK^{\\top}}{\\sqrt{d_k}}\\right)$$\n",
        "Assume the queries and keys are 2D matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ysRdVCnP7Qir",
      "metadata": {
        "id": "ysRdVCnP7Qir"
      },
      "outputs": [],
      "source": [
        "def calc_weights(queries, keys):\n",
        "    \"\"\"\n",
        "    queries: queries matrix\n",
        "    keys: keys matrix\n",
        "    \"\"\"\n",
        "    #### your code ####\n",
        "    d_k = keys.shape[1]\n",
        "    weights = softmax(np.dot(queries, keys.T) / np.sqrt(d_k), axis=1)\n",
        "    #### your code ####\n",
        "\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LVYGelEsqsoo",
      "metadata": {
        "id": "LVYGelEsqsoo",
        "outputId": "468a0783-fc66-44c5-ca43-249cf040eeff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.19557032 0.80442968]\n",
            " [0.19557032 0.80442968]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights=calc_weights(np.array([[1,3],[1,3]]),np.array([[0,3],[2,3]]))\n",
        "print(weights)\n",
        "weights.sum(axis=1)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16V5yFAew1Hx",
      "metadata": {
        "id": "16V5yFAew1Hx"
      },
      "source": [
        "Use the `calcu_weights` to compute the attention matrix between two sentences from English and French and visualize the weights to check for alignments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "miW865arw9Fv",
      "metadata": {
        "id": "miW865arw9Fv",
        "outputId": "befb25f8-02af-4b5a-ad25-9d8a045745f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The top allignment is between the words 'nuages' and 'clouds' with a score of 0.09370453641488403\n",
            "The second top allignment is between the words 'café' and 'coffee' with a score of 0.0932135859530074\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sentence_en = \"there were clouds in my coffee and unicorns in the sky.\"\n",
        "tokenized_en = tokenize(sentence_en, en_dict)\n",
        "embedded_en = embed(tokenized_en, en_embeddings)\n",
        "\n",
        "sentence_fr = \"il y avait des nuages ​​dans mon café et des licornes dans le ciel.\"\n",
        "tokenized_fr = tokenize(sentence_fr, fr_dict)\n",
        "embedded_fr = embed(tokenized_fr, fr_embeddings)\n",
        "\n",
        "alignment = calc_weights(embedded_fr, embedded_en)\n",
        "# visualize weights\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "ax.imshow(alignment,cmap='gray')\n",
        "ax.xaxis.tick_top()\n",
        "ax.set_xticks(np.arange(alignment.shape[1]))\n",
        "ax.set_xticklabels(sentence_en.split(\" \"), rotation=90, size=12);\n",
        "ax.set_yticks(np.arange(alignment.shape[0]));\n",
        "ax.set_yticklabels(sentence_fr.split(\" \"), size=12);\n",
        "\n",
        "\n",
        "### your code to compute the top-2 ###\n",
        "top1_score = -1\n",
        "top2_score = -2\n",
        "top1_coordinates = [None, None]\n",
        "top2_coordinates = [None, None]\n",
        "for i in range(alignment.shape[0]):\n",
        "    for j in range(alignment.shape[1]):\n",
        "        if alignment[i][j] >= top1_score:\n",
        "            top2_score = top1_score\n",
        "            top2_coordinates = top1_coordinates\n",
        "            top1_score = alignment[i][j]\n",
        "            top1_coordinates = [i, j]\n",
        "        elif alignment[i][j] > top2_score:\n",
        "            top2_score = alignment[i][j]\n",
        "            top2_coordinates = [i, j]\n",
        "\n",
        "\n",
        "top1_words = [sentence_fr.split(\" \")[top1_coordinates[0]], sentence_en.split(\" \")[top1_coordinates[1]]]\n",
        "top2_words = [sentence_fr.split(\" \")[top2_coordinates[0]], sentence_en.split(\" \")[top2_coordinates[1]]]\n",
        "print(f\"The top allignment is between the words '{top1_words[0]}' and '{top1_words[1]}' with a score of {top1_score}\")\n",
        "print(f\"The second top allignment is between the words '{top2_words[0]}' and '{top2_words[1]}' with a score of {top2_score}\")\n",
        "### your code ###"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0BxnOJJ2xhIZ",
      "metadata": {
        "id": "0BxnOJJ2xhIZ"
      },
      "source": [
        "1. What are the top 2 alignments shown in the figure?\n",
        "2. On the rows you see flat lines for `ciel` and `dans` and `licornes`, why do you think that is?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QUwdKXhZxqUP",
      "metadata": {
        "id": "QUwdKXhZxqUP"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "```\n",
        "1. What are the top 2 alignments shown in the figure?\n",
        "    The top alignment shown in the figure is between the words 'nuages' and 'clouds' with an alignment score of 0.09370453641488403\n",
        "\n",
        "    The second top aligment shown in the figure is between the words 'café' and 'coffee' with an alignment score of 0.0932135859530074\n",
        "    \n",
        "2. On the rows you see flat lines for `ciel` and `dans` and `licornes`, why do you think that is?\n",
        "    I think that is due to the fact that `ciel` and `dans` and `licornes` do not have predefined embeddings and they get the same embedding (zeros) because of not having a predefined emebedding. This makes them unrelated to other words.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C2TnQmsxy70i",
      "metadata": {
        "id": "C2TnQmsxy70i"
      },
      "source": [
        "#### ${\\color{red}{Comments\\ 3.1}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "✅ Point distribution ✅ 4/4\n",
        "- Tokenization outputs are correct\n",
        "- embedding shapes are correct\n",
        "- Weights are correct and softmax sum is 1.0. (0.5 + 0.5 = 1.0). \n",
        "\n",
        "The provided solution uses a try-except block to handle unknown words, assigning -1 as the token ID.\n",
        "Yours explicitly checks if the word is in the token mapping before assigning its ID.\n",
        "Both solutions initialize the embedding matrix with zeros.\n",
        "Your solution includes a check to ensure that the token ID is within the valid range for embeddings. (0.5 + 0.5 = 1.0)\n",
        "\n",
        "For softmax implementation, the solution is correct and provides the correct output, by modularizing the softmax calculation by using a separate function which may be considered more readable. (0.5 + 0.5 = 1.0)\n",
        "\n",
        "Both solutions are correct in calculating the top-2 alignments. Your solution includes a visualization with numerical row and column labels. It would have been better to visualize it with words. Both Q-A answers are true. You focused on the absence of predefined embeddings, while the provided solution focuses on random embeddings not being sufficient for the attention module. (0.5 + 0.5 = 1.0)\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eqXwL4MpzW--",
      "metadata": {
        "id": "eqXwL4MpzW--"
      },
      "source": [
        "### Subtask 2: Scaled Dot-product\n",
        "Implement the scaled dot-product attention using the functions from above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8iQTr4KCzqZk",
      "metadata": {
        "id": "8iQTr4KCzqZk",
        "outputId": "b4afd058-465a-4632-f0fd-1239c59b6fc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(14, 300)\n",
            "[[-0.0077802  -0.00345834 -0.01493142  0.05936939 -0.02286767 -0.00835552\n",
            "   0.00079745 -0.03737862  0.0270674   0.05374082]\n",
            " [-0.00777829 -0.00336843 -0.01498988  0.05937157 -0.02285948 -0.00835695\n",
            "   0.00085725 -0.03740797  0.02706951  0.05377672]]\n"
          ]
        }
      ],
      "source": [
        "def attention(queries, keys, values):\n",
        "    \"\"\"  scaled dot-product attention\n",
        "    queries: query matrix\n",
        "    keys: key matrix\n",
        "    value: value matrix\n",
        "    \"\"\"\n",
        "\n",
        "    #### your code ####\n",
        "    attention = np.dot(calc_weights(queries, keys), values)\n",
        "    #### your code ####\n",
        "    return attention\n",
        "\n",
        "\n",
        "attention_result = attention(embedded_fr, embedded_en, embedded_en)\n",
        "print(attention_result.shape)\n",
        "print(attention_result[0:2,:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vlwGjAWMy_OX",
      "metadata": {
        "id": "vlwGjAWMy_OX"
      },
      "source": [
        "####${\\color{red}{Comments\\ 3.2}}$\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ begin⚠️}}$\n",
        "\n",
        "\n",
        "```\n",
        "✅ Point distribution ✅ 1/1\n",
        "Solution is correct and produce identical outputs with the provided solution. Attention operation has been applied appropriately, and attention mechanism is functioning as intended. (0.5 + 0.5 = 1.0)\n",
        "\n",
        "\n",
        "Total task 3 points: 4 + 1 = 5\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "${\\color{red}{⚠️Comments\\ end⚠️}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qDx8DrnVzAR1",
      "metadata": {
        "id": "qDx8DrnVzAR1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
