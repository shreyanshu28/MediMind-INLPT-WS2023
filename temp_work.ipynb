{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyanshu28/MediMind-INLPT-WS2023/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PMID</th>\n",
              "      <th>OWN</th>\n",
              "      <th>STAT</th>\n",
              "      <th>DCOM</th>\n",
              "      <th>LR</th>\n",
              "      <th>IS</th>\n",
              "      <th>VI</th>\n",
              "      <th>IP</th>\n",
              "      <th>DP</th>\n",
              "      <th>TI</th>\n",
              "      <th>...</th>\n",
              "      <th>CRDT</th>\n",
              "      <th>PHST</th>\n",
              "      <th>AID</th>\n",
              "      <th>PST</th>\n",
              "      <th>SO</th>\n",
              "      <th>AUID</th>\n",
              "      <th>CIN</th>\n",
              "      <th>CI</th>\n",
              "      <th>OTO</th>\n",
              "      <th>OT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23921675</td>\n",
              "      <td>NLM</td>\n",
              "      <td>MEDLINE</td>\n",
              "      <td>20140528.0</td>\n",
              "      <td>20160511.0</td>\n",
              "      <td>1532-7957 (Linking)</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2013 Nov</td>\n",
              "      <td>The relation between intelligence and religios...</td>\n",
              "      <td>...</td>\n",
              "      <td>2013/08/08 06:00</td>\n",
              "      <td>2014/05/29 06:00 [medline]</td>\n",
              "      <td>10.1177/1088868313497266 [doi]</td>\n",
              "      <td>ppublish</td>\n",
              "      <td>Pers Soc Psychol Rev. 2013 Nov;17(4):325-54. d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NOTNLM</td>\n",
              "      <td>religiosity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       PMID  OWN     STAT        DCOM          LR                   IS  VI IP  \\\n",
              "0  23921675  NLM  MEDLINE  20140528.0  20160511.0  1532-7957 (Linking)  17  4   \n",
              "\n",
              "         DP                                                 TI  ...  \\\n",
              "0  2013 Nov  The relation between intelligence and religios...  ...   \n",
              "\n",
              "               CRDT                        PHST  \\\n",
              "0  2013/08/08 06:00  2014/05/29 06:00 [medline]   \n",
              "\n",
              "                              AID       PST  \\\n",
              "0  10.1177/1088868313497266 [doi]  ppublish   \n",
              "\n",
              "                                                  SO AUID  CIN   CI     OTO  \\\n",
              "0  Pers Soc Psychol Rev. 2013 Nov;17(4):325-54. d...  NaN  NaN  NaN  NOTNLM   \n",
              "\n",
              "            OT  \n",
              "0  religiosity  \n",
              "\n",
              "[1 rows x 41 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#read csv\n",
        "df = pd.read_csv('pubmed.csv')\n",
        "\n",
        "#display first 5 rows\n",
        "df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TI</th>\n",
              "      <th>PMID</th>\n",
              "      <th>AB</th>\n",
              "      <th>AU</th>\n",
              "      <th>AD</th>\n",
              "      <th>LA</th>\n",
              "      <th>MH</th>\n",
              "      <th>PHST</th>\n",
              "      <th>DP</th>\n",
              "      <th>TI</th>\n",
              "      <th>OT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>59222</td>\n",
              "      <td>5.922200e+04</td>\n",
              "      <td>59222</td>\n",
              "      <td>59136</td>\n",
              "      <td>57515</td>\n",
              "      <td>59222</td>\n",
              "      <td>37467</td>\n",
              "      <td>59168</td>\n",
              "      <td>59222</td>\n",
              "      <td>59222</td>\n",
              "      <td>44698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>59222</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59201</td>\n",
              "      <td>37390</td>\n",
              "      <td>54289</td>\n",
              "      <td>23</td>\n",
              "      <td>9096</td>\n",
              "      <td>24687</td>\n",
              "      <td>3305</td>\n",
              "      <td>59222</td>\n",
              "      <td>23247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>The relation between intelligence and religios...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>An amendment to this paper has been published ...</td>\n",
              "      <td>Wang Y</td>\n",
              "      <td>Department of Psychology.</td>\n",
              "      <td>eng</td>\n",
              "      <td>Young Adult</td>\n",
              "      <td>2021/12/15 06:00 [medline]</td>\n",
              "      <td>2022</td>\n",
              "      <td>The relation between intelligence and religios...</td>\n",
              "      <td>machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>95</td>\n",
              "      <td>45</td>\n",
              "      <td>57742</td>\n",
              "      <td>2866</td>\n",
              "      <td>164</td>\n",
              "      <td>3123</td>\n",
              "      <td>1</td>\n",
              "      <td>681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.378635e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.750435e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.030133e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.190746e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.482948e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.672128e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.834837e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       TI          PMID  \\\n",
              "count                                               59222  5.922200e+04   \n",
              "unique                                              59222           NaN   \n",
              "top     The relation between intelligence and religios...           NaN   \n",
              "freq                                                    1           NaN   \n",
              "mean                                                  NaN  3.378635e+07   \n",
              "std                                                   NaN  3.750435e+06   \n",
              "min                                                   NaN  2.030133e+07   \n",
              "25%                                                   NaN  3.190746e+07   \n",
              "50%                                                   NaN  3.482948e+07   \n",
              "75%                                                   NaN  3.672128e+07   \n",
              "max                                                   NaN  3.834837e+07   \n",
              "\n",
              "                                                       AB      AU  \\\n",
              "count                                               59222   59136   \n",
              "unique                                              59201   37390   \n",
              "top     An amendment to this paper has been published ...  Wang Y   \n",
              "freq                                                    6      95   \n",
              "mean                                                  NaN     NaN   \n",
              "std                                                   NaN     NaN   \n",
              "min                                                   NaN     NaN   \n",
              "25%                                                   NaN     NaN   \n",
              "50%                                                   NaN     NaN   \n",
              "75%                                                   NaN     NaN   \n",
              "max                                                   NaN     NaN   \n",
              "\n",
              "                               AD     LA           MH  \\\n",
              "count                       57515  59222        37467   \n",
              "unique                      54289     23         9096   \n",
              "top     Department of Psychology.    eng  Young Adult   \n",
              "freq                           45  57742         2866   \n",
              "mean                          NaN    NaN          NaN   \n",
              "std                           NaN    NaN          NaN   \n",
              "min                           NaN    NaN          NaN   \n",
              "25%                           NaN    NaN          NaN   \n",
              "50%                           NaN    NaN          NaN   \n",
              "75%                           NaN    NaN          NaN   \n",
              "max                           NaN    NaN          NaN   \n",
              "\n",
              "                              PHST     DP  \\\n",
              "count                        59168  59222   \n",
              "unique                       24687   3305   \n",
              "top     2021/12/15 06:00 [medline]   2022   \n",
              "freq                           164   3123   \n",
              "mean                           NaN    NaN   \n",
              "std                            NaN    NaN   \n",
              "min                            NaN    NaN   \n",
              "25%                            NaN    NaN   \n",
              "50%                            NaN    NaN   \n",
              "75%                            NaN    NaN   \n",
              "max                            NaN    NaN   \n",
              "\n",
              "                                                       TI                OT  \n",
              "count                                               59222             44698  \n",
              "unique                                              59222             23247  \n",
              "top     The relation between intelligence and religios...  machine learning  \n",
              "freq                                                    1               681  \n",
              "mean                                                  NaN               NaN  \n",
              "std                                                   NaN               NaN  \n",
              "min                                                   NaN               NaN  \n",
              "25%                                                   NaN               NaN  \n",
              "50%                                                   NaN               NaN  \n",
              "75%                                                   NaN               NaN  \n",
              "max                                                   NaN               NaN  "
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop_duplicates(subset='TI', keep='first') #remove duplicate articles with same title (there are some articles with different PMIDs but same title)\n",
        "df = df.dropna(subset=['AB','TI'])  #drop na for title and abstract\n",
        "#drop based on selected values in a column\n",
        "df = df[df['TI']!='[Not Available].'] \n",
        "\n",
        "\n",
        "df[['TI','PMID','AB','AU','AD','LA','MH','PHST','DP','TI','OT']].describe(include='all')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PMID</th>\n",
              "      <th>OWN</th>\n",
              "      <th>STAT</th>\n",
              "      <th>DCOM</th>\n",
              "      <th>LR</th>\n",
              "      <th>IS</th>\n",
              "      <th>VI</th>\n",
              "      <th>IP</th>\n",
              "      <th>DP</th>\n",
              "      <th>TI</th>\n",
              "      <th>...</th>\n",
              "      <th>CRDT</th>\n",
              "      <th>PHST</th>\n",
              "      <th>AID</th>\n",
              "      <th>PST</th>\n",
              "      <th>SO</th>\n",
              "      <th>AUID</th>\n",
              "      <th>CIN</th>\n",
              "      <th>CI</th>\n",
              "      <th>OTO</th>\n",
              "      <th>OT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.929100e+04</td>\n",
              "      <td>59236</td>\n",
              "      <td>59291</td>\n",
              "      <td>3.946600e+04</td>\n",
              "      <td>5.923600e+04</td>\n",
              "      <td>59060</td>\n",
              "      <td>57586</td>\n",
              "      <td>42819</td>\n",
              "      <td>59291</td>\n",
              "      <td>59291</td>\n",
              "      <td>...</td>\n",
              "      <td>59291</td>\n",
              "      <td>59236</td>\n",
              "      <td>58771</td>\n",
              "      <td>59236</td>\n",
              "      <td>59236</td>\n",
              "      <td>24166</td>\n",
              "      <td>1584</td>\n",
              "      <td>34905</td>\n",
              "      <td>44730</td>\n",
              "      <td>44729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6108</td>\n",
              "      <td>1022</td>\n",
              "      <td>636</td>\n",
              "      <td>3306</td>\n",
              "      <td>59223</td>\n",
              "      <td>...</td>\n",
              "      <td>31398</td>\n",
              "      <td>24702</td>\n",
              "      <td>58759</td>\n",
              "      <td>3</td>\n",
              "      <td>59236</td>\n",
              "      <td>20309</td>\n",
              "      <td>1521</td>\n",
              "      <td>12371</td>\n",
              "      <td>2</td>\n",
              "      <td>23251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NLM</td>\n",
              "      <td>MEDLINE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1424-8220 (Linking)</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>2022</td>\n",
              "      <td>[Not Available].</td>\n",
              "      <td>...</td>\n",
              "      <td>2019/06/05 06:00</td>\n",
              "      <td>2021/12/15 06:00 [medline]</td>\n",
              "      <td>100001882012 [pii]</td>\n",
              "      <td>ppublish</td>\n",
              "      <td>Pers Soc Psychol Rev. 2013 Nov;17(4):325-54. d...</td>\n",
              "      <td>ORCID: 0000-0001-9954-9711</td>\n",
              "      <td>Behav Brain Sci. 2017 Jan;40:e224. PMID: 29342679</td>\n",
              "      <td>© 2023. The Author(s).</td>\n",
              "      <td>NOTNLM</td>\n",
              "      <td>machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>59223</td>\n",
              "      <td>37486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1857</td>\n",
              "      <td>2569</td>\n",
              "      <td>8062</td>\n",
              "      <td>3126</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>76</td>\n",
              "      <td>165</td>\n",
              "      <td>3</td>\n",
              "      <td>33341</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>1086</td>\n",
              "      <td>44694</td>\n",
              "      <td>682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.378722e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.020552e+07</td>\n",
              "      <td>2.021659e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.749792e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.641255e+04</td>\n",
              "      <td>1.841197e+04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.030133e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.013012e+07</td>\n",
              "      <td>2.012092e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.190932e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.019111e+07</td>\n",
              "      <td>2.021051e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.483058e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.021102e+07</td>\n",
              "      <td>2.022072e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.672178e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.022121e+07</td>\n",
              "      <td>2.023070e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.834837e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.024021e+07</td>\n",
              "      <td>2.024021e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                PMID    OWN     STAT          DCOM            LR  \\\n",
              "count   5.929100e+04  59236    59291  3.946600e+04  5.923600e+04   \n",
              "unique           NaN      3        4           NaN           NaN   \n",
              "top              NaN    NLM  MEDLINE           NaN           NaN   \n",
              "freq             NaN  59223    37486           NaN           NaN   \n",
              "mean    3.378722e+07    NaN      NaN  2.020552e+07  2.021659e+07   \n",
              "std     3.749792e+06    NaN      NaN  2.641255e+04  1.841197e+04   \n",
              "min     2.030133e+07    NaN      NaN  2.013012e+07  2.012092e+07   \n",
              "25%     3.190932e+07    NaN      NaN  2.019111e+07  2.021051e+07   \n",
              "50%     3.483058e+07    NaN      NaN  2.021102e+07  2.022072e+07   \n",
              "75%     3.672178e+07    NaN      NaN  2.022121e+07  2.023070e+07   \n",
              "max     3.834837e+07    NaN      NaN  2.024021e+07  2.024021e+07   \n",
              "\n",
              "                         IS     VI     IP     DP                TI  ...  \\\n",
              "count                 59060  57586  42819  59291             59291  ...   \n",
              "unique                 6108   1022    636   3306             59223  ...   \n",
              "top     1424-8220 (Linking)     13      1   2022  [Not Available].  ...   \n",
              "freq                   1857   2569   8062   3126                10  ...   \n",
              "mean                    NaN    NaN    NaN    NaN               NaN  ...   \n",
              "std                     NaN    NaN    NaN    NaN               NaN  ...   \n",
              "min                     NaN    NaN    NaN    NaN               NaN  ...   \n",
              "25%                     NaN    NaN    NaN    NaN               NaN  ...   \n",
              "50%                     NaN    NaN    NaN    NaN               NaN  ...   \n",
              "75%                     NaN    NaN    NaN    NaN               NaN  ...   \n",
              "max                     NaN    NaN    NaN    NaN               NaN  ...   \n",
              "\n",
              "                    CRDT                        PHST                 AID  \\\n",
              "count              59291                       59236               58771   \n",
              "unique             31398                       24702               58759   \n",
              "top     2019/06/05 06:00  2021/12/15 06:00 [medline]  100001882012 [pii]   \n",
              "freq                  76                         165                   3   \n",
              "mean                 NaN                         NaN                 NaN   \n",
              "std                  NaN                         NaN                 NaN   \n",
              "min                  NaN                         NaN                 NaN   \n",
              "25%                  NaN                         NaN                 NaN   \n",
              "50%                  NaN                         NaN                 NaN   \n",
              "75%                  NaN                         NaN                 NaN   \n",
              "max                  NaN                         NaN                 NaN   \n",
              "\n",
              "             PST                                                 SO  \\\n",
              "count      59236                                              59236   \n",
              "unique         3                                              59236   \n",
              "top     ppublish  Pers Soc Psychol Rev. 2013 Nov;17(4):325-54. d...   \n",
              "freq       33341                                                  1   \n",
              "mean         NaN                                                NaN   \n",
              "std          NaN                                                NaN   \n",
              "min          NaN                                                NaN   \n",
              "25%          NaN                                                NaN   \n",
              "50%          NaN                                                NaN   \n",
              "75%          NaN                                                NaN   \n",
              "max          NaN                                                NaN   \n",
              "\n",
              "                              AUID  \\\n",
              "count                        24166   \n",
              "unique                       20309   \n",
              "top     ORCID: 0000-0001-9954-9711   \n",
              "freq                            21   \n",
              "mean                           NaN   \n",
              "std                            NaN   \n",
              "min                            NaN   \n",
              "25%                            NaN   \n",
              "50%                            NaN   \n",
              "75%                            NaN   \n",
              "max                            NaN   \n",
              "\n",
              "                                                      CIN  \\\n",
              "count                                                1584   \n",
              "unique                                               1521   \n",
              "top     Behav Brain Sci. 2017 Jan;40:e224. PMID: 29342679   \n",
              "freq                                                   25   \n",
              "mean                                                  NaN   \n",
              "std                                                   NaN   \n",
              "min                                                   NaN   \n",
              "25%                                                   NaN   \n",
              "50%                                                   NaN   \n",
              "75%                                                   NaN   \n",
              "max                                                   NaN   \n",
              "\n",
              "                            CI     OTO                OT  \n",
              "count                    34905   44730             44729  \n",
              "unique                   12371       2             23251  \n",
              "top     © 2023. The Author(s).  NOTNLM  machine learning  \n",
              "freq                      1086   44694               682  \n",
              "mean                       NaN     NaN               NaN  \n",
              "std                        NaN     NaN               NaN  \n",
              "min                        NaN     NaN               NaN  \n",
              "25%                        NaN     NaN               NaN  \n",
              "50%                        NaN     NaN               NaN  \n",
              "75%                        NaN     NaN               NaN  \n",
              "max                        NaN     NaN               NaN  \n",
              "\n",
              "[11 rows x 41 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check nans for all columns\n",
        "\n",
        "# df[df[['AB','TI']].isnull().any(axis=1) == True][['AB','PMID','TI','OT']].describe(include='all')\n",
        "\n",
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'PubMed Data/PubMedTextFiles/abstract-intelligen-set-2013.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 64133 lines in the data.\n",
            "There are 10687 paragraphs in the data.\n"
          ]
        }
      ],
      "source": [
        "# Open the text file\n",
        "with open(file_path, 'r', encoding='utf-8') as in_file:\n",
        "    # Read the entire text file\n",
        "    data = in_file.read()\n",
        "\n",
        "    # Split the data into lines\n",
        "    lines = data.split('\\n')\n",
        "    print(f'There are {len(lines)} lines in the data.')\n",
        "\n",
        "    # Split the data into paragraphs\n",
        "    paragraphs = data.split('\\n\\n')\n",
        "    print(f'There are {len(paragraphs)} paragraphs in the data.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Define a function to parse the data\n",
        "def parse_data(data):\n",
        "    # Split the data into records\n",
        "    records = data.split('\\n\\n')\n",
        "    # Initialize a list to store the parsed data\n",
        "    parsed_data = []\n",
        "    # Iterate over each record\n",
        "    for record in records:\n",
        "        # Split the record into lines\n",
        "        lines = record.split('\\n')\n",
        "        # Initialize an empty dictionary to store the record data\n",
        "        record_data = {}\n",
        "        # Iterate over each line\n",
        "        for line in lines:\n",
        "            # Check if the line contains a colon\n",
        "            if ':' in line:\n",
        "                # Split the line into key and value\n",
        "                key, value = line.split(':', 1)\n",
        "                # Remove leading and trailing whitespace\n",
        "                key = key.strip()\n",
        "                value = value.strip()\n",
        "                # Add the key-value pair to the record data\n",
        "                record_data[key] = value\n",
        "        # Add the record data to the parsed data\n",
        "        parsed_data.append(record_data)\n",
        "    # Return the parsed data\n",
        "    return parsed_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "dict contains fields not in fieldnames: 'Amemiya A, editors. GeneReviews(®) [Internet]. Seattle (WA)', 'In'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriteheader()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Write the parsed data to the csv file\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\csv.py:157\u001b[0m, in \u001b[0;36mDictWriter.writerows\u001b[1;34m(self, rowdicts)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwriterows\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdicts):\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dict_to_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowdicts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\csv.py:149\u001b[0m, in \u001b[0;36mDictWriter._dict_to_list\u001b[1;34m(self, rowdict)\u001b[0m\n\u001b[0;32m    147\u001b[0m     wrong_fields \u001b[38;5;241m=\u001b[39m rowdict\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrong_fields:\n\u001b[1;32m--> 149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict contains fields not in fieldnames: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m                          \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mrepr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m wrong_fields]))\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (rowdict\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestval) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames)\n",
            "\u001b[1;31mValueError\u001b[0m: dict contains fields not in fieldnames: 'Amemiya A, editors. GeneReviews(®) [Internet]. Seattle (WA)', 'In'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Open the text file and csv file\n",
        "with open('input.txt', 'r', encoding='utf-8') as in_file, open('output.csv', 'w', newline='', encoding='utf-8') as out_file:\n",
        "    # Read the entire text file\n",
        "    data = in_file.read()\n",
        "    # Parse the data\n",
        "    parsed_data = parse_data(data)\n",
        "    # Create a csv writer object\n",
        "    writer = csv.DictWriter(out_file, fieldnames=['Title', 'Author Information', 'Clinical Characteristics', 'Clinical Information', 'Copyright', 'PMID'])\n",
        "    # Write the header to the csv file\n",
        "    writer.writeheader()\n",
        "    # Write the parsed data to the csv file\n",
        "    writer.writerows(parsed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Define a function to parse the data\n",
        "def parse_data(data):\n",
        "    # Split the data into records\n",
        "    records = data.split('\\n\\n')\n",
        "    # Initialize a list to store the parsed data\n",
        "    parsed_data = []\n",
        "    # Iterate over each record\n",
        "    for record in records:\n",
        "        # Split the record into lines\n",
        "        lines = record.split('\\n')\n",
        "        # Initialize an empty dictionary to store the record data\n",
        "        record_data = {}\n",
        "        # Iterate over each line\n",
        "        for line in lines:\n",
        "            # Check if the line contains a colon\n",
        "            if ':' in line:\n",
        "                # Split the line into key and value\n",
        "                key, value = line.split(':', 1)\n",
        "                # Remove leading and trailing whitespace\n",
        "                key = key.strip()\n",
        "                value = value.strip()\n",
        "                # Add the key-value pair to the record data\n",
        "                record_data[key] = value\n",
        "        # Add the record data to the parsed data\n",
        "        parsed_data.append(record_data)\n",
        "    # Return the parsed data\n",
        "    return parsed_data\n",
        "\n",
        "# Open the text file and csv file\n",
        "with open('input.txt', 'r', encoding='utf-8') as in_file, open('output.csv', 'w', newline='', encoding='utf-8') as out_file:\n",
        "    # Read the entire text file\n",
        "    data = in_file.read()\n",
        "    # Parse the data\n",
        "    parsed_data = parse_data(data)\n",
        "    # Create a csv writer object\n",
        "    writer = csv.DictWriter(out_file, fieldnames=['Title', 'Author Information', 'Clinical Characteristics', 'Clinical Information', 'Copyright', 'PMID'])\n",
        "    # Write the header to the csv file\n",
        "    writer.writeheader()\n",
        "    # Write the parsed data to the csv file\n",
        "    for row in parsed_data:\n",
        "        # Only write rows that contain the correct fields\n",
        "        if all(field in row for field in writer.fieldnames):\n",
        "            writer.writerow(row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1623\n",
            "----------------------------------------\n",
            "Toxicol Appl Pharmacol. 2013 Sep 15;271(3):309-23. doi: \n",
            "10.1016/j.taap.2010.03.019. Epub 2010 Mar 29.\n",
            "\n",
            "Approaches to advancing quantitative human health risk assessment of \n",
            "environmental chemicals in the post-genomic era.\n",
            "\n",
            "Chiu WA(1), Euling SY, Scott CS, Subramaniam RP.\n",
            "\n",
            "Author information:\n",
            "(1)National Center for Environmental Assessment, U.S. Environmental Protection \n",
            "Agency, Washington DC, 20460, USA. Electronic address: chiu.weihsueh@epa.gov.\n",
            "\n",
            "The contribution of genomics and associated technologies to human health risk \n",
            "assessment for environmental chemicals has focused largely on elucidating \n",
            "mechanisms of toxicity, as discussed in other articles in this issue. However, \n",
            "there is interest in moving beyond hazard characterization to making more direct \n",
            "impacts on quantitative risk assessment (QRA)--i.e., the determination of \n",
            "toxicity values for setting exposure standards and cleanup values. We propose \n",
            "that the evolution of QRA of environmental chemicals in the post-genomic era \n",
            "will involve three, somewhat overlapping phases in which different types of \n",
            "approaches begin to mature. The initial focus (in Phase I) has been and \n",
            "continues to be on \"augmentation\" of weight of evidence--using genomic and \n",
            "related technologies qualitatively to increase the confidence in and scientific \n",
            "basis of the results of QRA. Efforts aimed towards \"integration\" of these data \n",
            "with traditional animal-based approaches, in particular quantitative predictors, \n",
            "or surrogates, for the in vivo toxicity data to which they have been anchored \n",
            "are just beginning to be explored now (in Phase II). In parallel, there is a \n",
            "recognized need for \"expansion\" of the use of established biomarkers of \n",
            "susceptibility or risk of human diseases and disorders for QRA, particularly for \n",
            "addressing the issues of cumulative assessment and population risk. Ultimately \n",
            "(in Phase III), substantial further advances could be realized by the \n",
            "development of novel molecular and pathway-based biomarkers and statistical and \n",
            "in silico models that build on anticipated progress in understanding the \n",
            "pathways of human diseases and disorders. Such efforts would facilitate a \n",
            "gradual \"reorientation\" of QRA towards approaches that more directly link \n",
            "environmental exposures to human outcomes.\n",
            "\n",
            "Published by Elsevier Inc.\n",
            "\n",
            "DOI: 10.1016/j.taap.2010.03.019\n",
            "PMID: 20353796 [Indexed for MEDLINE]\n",
            "\n",
            "----------------------------------------\n",
            "Assessment. 2013 Apr;20(2):242-52. doi: 10.1177/1073191111411658. Epub 2011 Jun \n",
            "10.\n",
            "\n",
            "How much power and speed is measured in this test?\n",
            "\n",
            "Partchev I(1), De Boeck P, Steyer R.\n",
            "\n",
            "Author information:\n",
            "(1)K. U. Leuven, Leuven, Belgium.\n",
            "\n",
            "An old issue in psychological assessment is to what extent power and speed each \n",
            "are measured by a given intelligence test. Starting from accuracy and response \n",
            "time data, an approach based on posterior time limits (cut-offs of recorded \n",
            "response time) leads to three kinds of recoded data: time data (whether or not \n",
            "the response precedes the cut-off), time-accuracy data (whether or not a \n",
            "response is correct and precedes the cut-off), and accuracy data (as \n",
            "time-accuracy data, but coded as missing when not preceding the time cut-off). \n",
            "Each type of data can be modeled as binary responses. Speed and power are \n",
            "investigated through the effect of posterior time limits on two main aspects: \n",
            "(a) the latent variable that is measured: whether it is more power-related or \n",
            "more speed-related; (b) how well the latent variable (of whatever kind) is \n",
            "measured through the item(s). As empirical data, we use responses and response \n",
            "times for a verbal analogies test. The main findings are that, independent of \n",
            "the posterior time limit, basically the same latent speed trait was measured \n",
            "through the time data, and basically the same latent power trait was measured \n",
            "through the accuracy data, while for the time-accuracy data the nature of the \n",
            "latent trait moved from power to speed when the posterior time limit was \n",
            "reduced. It was also found that a reduction of the posterior time limit had no \n",
            "negative effect on the reliability of the latent trait measures (of whatever \n",
            "kind).\n",
            "\n",
            "DOI: 10.1177/1073191111411658\n",
            "PMID: 21665882 [Indexed for MEDLINE]\n",
            "\n",
            "----------------------------------------\n",
            "Autism. 2013 Mar;17(2):172-83. doi: 10.1177/1362361311409960. Epub 2011 Jun 29.\n",
            "\n",
            "Does central coherence relate to the cognitive performance of children with \n",
            "autism in dynamic assessments?\n",
            "\n",
            "Aljunied M(1), Frederickson N.\n",
            "\n",
            "Author information:\n",
            "(1)University College London, UK, and Ministry of Education, Singapore.\n",
            "\n",
            "Central coherence refers to an in-built propensity to form meaningful links over \n",
            "a wide range of stimuli and to generalize over as wide a range of contexts as \n",
            "possible. In children with autism this ability is diminished, and the impact of \n",
            "central coherence deficits in children with autism have previously been observed \n",
            "using static measures of learning, such as reading comprehension test \n",
            "performance. In this study, the relationship between central coherence and more \n",
            "dynamic indicators of learning are investigated. The responses of 52 children \n",
            "with autism (mean age 9:10 years) on a test of central coherence and a dynamic \n",
            "assessment task were analysed. All the children showed significant improvements \n",
            "in dynamic assessment test scores after mediation; however, among those with \n",
            "below average nonverbal intelligence scores, weak central coherence was \n",
            "significantly associated with smaller gains in performance after teaching. \n",
            "Implications for the validity of dynamic assessments for children with autism \n",
            "are discussed.\n",
            "\n",
            "DOI: 10.1177/1362361311409960\n",
            "PMID: 21715547 [Indexed for MEDLINE]\n",
            "\n",
            "----------------------------------------\n",
            "Food Chem Toxicol. 2013 Apr;54:50-8. doi: 10.1016/j.fct.2011.06.052. Epub 2011 \n",
            "Jun 23.\n",
            "\n",
            "Effects of docosahexaenoic acid and methylmercury on child's brain development \n",
            "due to consumption of fish by Finnish mother during pregnancy: a probabilistic \n",
            "modeling approach.\n",
            "\n",
            "Leino O(1), Karjalainen AK, Tuomisto JT.\n",
            "\n",
            "Author information:\n",
            "(1)National Institute for Health and Welfare, Terveyden ja hyvinvoinnin laitos, \n",
            "Kuopio, Finland. Olli.leino@thl.fi\n",
            "\n",
            "Fish contains both beneficial substances e.g. docosahexaenoic acids but also \n",
            "harmful compounds e.g. methylmercury. Importantly, the health effects caused by \n",
            "these two substances can be evaluated in one common end point, intelligence \n",
            "quotient (IQ), providing a more transparent analysis. We estimated health \n",
            "effects of maternal fish consumption on child's central nervous system by \n",
            "creating a model with three alternative maternal fish consumption scenarios \n",
            "(lean fish, fatty fish, and current fish consumption). Additionally, we analyzed \n",
            "impacts of both regular fish consumption and extreme fish consumption habits. At \n",
            "the individual level, the simulated net effects were small, encompassing a range \n",
            "of one IQ point in all scenarios. Fatty fish consumption, however, clearly \n",
            "generated a beneficial net IQ effect, and lean fish consumption evoked an \n",
            "adverse net IQ effect. In view of the current fish consumption pattern of \n",
            "Finnish mothers the benefits and risks seem to more or less compensate each \n",
            "other. This study clearly shows the significance of which fish species are \n",
            "consumed during pregnancy and lactation, and the results can be generalized to \n",
            "apply to typical western population fish consumption habits.\n",
            "\n",
            "Copyright © 2011 Elsevier Ltd. All rights reserved.\n",
            "\n",
            "DOI: 10.1016/j.fct.2011.06.052\n",
            "PMID: 21723361 [Indexed for MEDLINE]\n",
            "\n",
            "dict_keys(['Assessment. 2013 Apr;20(2)', 'Author information', 'response time) leads to three kinds of recoded data', 'investigated through the effect of posterior time limits on two main aspects', '(a) the latent variable that is measured', 'DOI', 'PMID'])\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import ray\n",
        "import re\n",
        "from ray.data import from_items\n",
        "\n",
        "# Define a function to parse the data\n",
        "def parse_data(data):\n",
        "    # Split the data into records\n",
        "    # print(data)\n",
        "    # records = data.split('\\n\\n')\n",
        "    # Initialize a list to store the parsed data\n",
        "    pattern = r'\\n\\n\\d+\\.\\s'\n",
        "    # # Split the data into records\n",
        "    records = re.split(pattern, data)\n",
        "    records.pop(0)\n",
        "    print(len(records))\n",
        "    parsed_data = []\n",
        "    # Iterate over each record\n",
        "    for i,record in enumerate(records):\n",
        "        print(\"--\"*20)\n",
        "        print(record)\n",
        "        if i >= 3:\n",
        "            break\n",
        "        \n",
        "        # Split the record into lines\n",
        "        # print(record)\n",
        "        \n",
        "        lines = record.split('\\n')\n",
        "        \n",
        "        # Initialize an empty dictionary to store the record data\n",
        "        record_data = {}\n",
        "        # Initialize a variable to store the current key\n",
        "        current_key = None\n",
        "        # Iterate over each line\n",
        "        for line in lines:\n",
        "            # Check if the line contains a colon\n",
        "            if ':' in line:\n",
        "                # Split the line into key and value\n",
        "                key, value = line.split(':', 1)\n",
        "                # Remove leading and trailing whitespace\n",
        "                key = key.strip()\n",
        "                value = value.strip()\n",
        "                # Add the key-value pair to the record data\n",
        "                record_data[key] = value\n",
        "                # Update the current key\n",
        "                current_key = key\n",
        "            elif current_key is not None:\n",
        "                # If the line does not contain a colon, add it to the current field\n",
        "                record_data[current_key] += ' ' + line.strip()\n",
        "        # Add the record data to the parsed data\n",
        "        parsed_data.append(record_data)\n",
        "    # Return the parsed data\n",
        "    return parsed_data\n",
        "\n",
        "# Open the text file and csv file\n",
        "with open(file_path, 'r', encoding='utf-8') as in_file, open('output.csv', 'w', newline='', encoding='utf-8') as out_file:\n",
        "    # Read the entire text file\n",
        "    data = in_file.read()\n",
        "    # Parse the data\n",
        "    parsed_data = parse_data(data)\n",
        "    # Create a csv writer object\n",
        "\n",
        "print(parsed_data[1].keys())\n",
        "\n",
        "# dataset = from_items(parsed_data)\n",
        "\n",
        "# # Print the first few records of the dataset\n",
        "# print(dataset.take(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ray\n",
        "import re\n",
        "from ray.data import from_items\n",
        "\n",
        "# Initialize Ray\n",
        "ray.init()\n",
        "\n",
        "# Define a function to parse the data\n",
        "def parse_data(data):\n",
        "    # Define the regular expression pattern\n",
        "    pattern = r'(?<=\\n)\\d+\\.\\s'\n",
        "    # Split the data into records\n",
        "    records = re.split(pattern, data)\n",
        "    # Initialize a list to store the parsed data\n",
        "    parsed_data = []\n",
        "    # Iterate over each record\n",
        "    for record in records:\n",
        "        # Split the record into lines\n",
        "        lines = record.split('\\n')\n",
        "        # Initialize an empty dictionary to store the record data\n",
        "        record_data = {}\n",
        "        # Initialize a variable to store the current key\n",
        "        current_key = None\n",
        "        # Iterate over each line\n",
        "        for line in lines:\n",
        "            # Check if the line contains a colon\n",
        "            if ':' in line:\n",
        "                # Split the line into key and value\n",
        "                key, value = line.split(':', 1)\n",
        "                # Remove leading and trailing whitespace\n",
        "                key = key.strip()\n",
        "                value = value.strip()\n",
        "                # Add the key-value pair to the record data\n",
        "                record_data[key] = value\n",
        "                # Update the current key\n",
        "                current_key = key\n",
        "            elif current_key is not None:\n",
        "                # If the line does not contain a colon, add it to the current field\n",
        "                record_data[current_key] += ' ' + line.strip()\n",
        "        # Add the record data to the parsed data if it is not empty\n",
        "        if record_data:\n",
        "            parsed_data.append(record_data)\n",
        "    # Return the parsed data\n",
        "    return parsed_data\n",
        "\n",
        "# Open the text file\n",
        "with open('input.txt', 'r', encoding='utf-8') as in_file:\n",
        "    # Read the entire text file\n",
        "    data = in_file.read()\n",
        "    # Parse the data\n",
        "    parsed_data = parse_data(data)\n",
        "\n",
        "# Convert the parsed data into a Ray dataset\n",
        "dataset = from_items(parsed_data)\n",
        "\n",
        "# Print the first few records of the dataset\n",
        "print(dataset.take(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOKwDXBMJ3Yq7Bq+hZC/VYI",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
