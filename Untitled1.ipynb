{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyanshu28/MediMind-INLPT-WS2023/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 350684 lines in the data.\n",
            "There are 53067 paragraphs in the data.\n"
          ]
        }
      ],
      "source": [
        "# Open the text file\n",
        "with open('input.txt', 'r', encoding='utf-8') as in_file:\n",
        "    # Read the entire text file\n",
        "    data = in_file.read()\n",
        "\n",
        "    # Split the data into lines\n",
        "    lines = data.split('\\n')\n",
        "    print(f'There are {len(lines)} lines in the data.')\n",
        "\n",
        "    # Split the data into paragraphs\n",
        "    paragraphs = data.split('\\n\\n')\n",
        "    print(f'There are {len(paragraphs)} paragraphs in the data.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Define a function to parse the data\n",
        "def parse_data(data):\n",
        "    # Split the data into records\n",
        "    records = data.split('\\n\\n')\n",
        "    # Initialize a list to store the parsed data\n",
        "    parsed_data = []\n",
        "    # Iterate over each record\n",
        "    for record in records:\n",
        "        # Split the record into lines\n",
        "        lines = record.split('\\n')\n",
        "        # Initialize an empty dictionary to store the record data\n",
        "        record_data = {}\n",
        "        # Iterate over each line\n",
        "        for line in lines:\n",
        "            # Check if the line contains a colon\n",
        "            if ':' in line:\n",
        "                # Split the line into key and value\n",
        "                key, value = line.split(':', 1)\n",
        "                # Remove leading and trailing whitespace\n",
        "                key = key.strip()\n",
        "                value = value.strip()\n",
        "                # Add the key-value pair to the record data\n",
        "                record_data[key] = value\n",
        "        # Add the record data to the parsed data\n",
        "        parsed_data.append(record_data)\n",
        "    # Return the parsed data\n",
        "    return parsed_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "dict contains fields not in fieldnames: 'Amemiya A, editors. GeneReviews(®) [Internet]. Seattle (WA)', 'In'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriteheader()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Write the parsed data to the csv file\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\csv.py:157\u001b[0m, in \u001b[0;36mDictWriter.writerows\u001b[1;34m(self, rowdicts)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwriterows\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdicts):\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dict_to_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowdicts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\csv.py:149\u001b[0m, in \u001b[0;36mDictWriter._dict_to_list\u001b[1;34m(self, rowdict)\u001b[0m\n\u001b[0;32m    147\u001b[0m     wrong_fields \u001b[38;5;241m=\u001b[39m rowdict\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrong_fields:\n\u001b[1;32m--> 149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict contains fields not in fieldnames: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m                          \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mrepr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m wrong_fields]))\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (rowdict\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestval) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames)\n",
            "\u001b[1;31mValueError\u001b[0m: dict contains fields not in fieldnames: 'Amemiya A, editors. GeneReviews(®) [Internet]. Seattle (WA)', 'In'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Open the text file and csv file\n",
        "with open('input.txt', 'r', encoding='utf-8') as in_file, open('output.csv', 'w', newline='', encoding='utf-8') as out_file:\n",
        "    # Read the entire text file\n",
        "    data = in_file.read()\n",
        "    # Parse the data\n",
        "    parsed_data = parse_data(data)\n",
        "    # Create a csv writer object\n",
        "    writer = csv.DictWriter(out_file, fieldnames=['Title', 'Author Information', 'Clinical Characteristics', 'Clinical Information', 'Copyright', 'PMID'])\n",
        "    # Write the header to the csv file\n",
        "    writer.writeheader()\n",
        "    # Write the parsed data to the csv file\n",
        "    writer.writerows(parsed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Define a function to parse the data\n",
        "def parse_data(data):\n",
        "    # Split the data into records\n",
        "    records = data.split('\\n\\n')\n",
        "    # Initialize a list to store the parsed data\n",
        "    parsed_data = []\n",
        "    # Iterate over each record\n",
        "    for record in records:\n",
        "        # Split the record into lines\n",
        "        lines = record.split('\\n')\n",
        "        # Initialize an empty dictionary to store the record data\n",
        "        record_data = {}\n",
        "        # Iterate over each line\n",
        "        for line in lines:\n",
        "            # Check if the line contains a colon\n",
        "            if ':' in line:\n",
        "                # Split the line into key and value\n",
        "                key, value = line.split(':', 1)\n",
        "                # Remove leading and trailing whitespace\n",
        "                key = key.strip()\n",
        "                value = value.strip()\n",
        "                # Add the key-value pair to the record data\n",
        "                record_data[key] = value\n",
        "        # Add the record data to the parsed data\n",
        "        parsed_data.append(record_data)\n",
        "    # Return the parsed data\n",
        "    return parsed_data\n",
        "\n",
        "# Open the text file and csv file\n",
        "with open('input.txt', 'r', encoding='utf-8') as in_file, open('output.csv', 'w', newline='', encoding='utf-8') as out_file:\n",
        "    # Read the entire text file\n",
        "    data = in_file.read()\n",
        "    # Parse the data\n",
        "    parsed_data = parse_data(data)\n",
        "    # Create a csv writer object\n",
        "    writer = csv.DictWriter(out_file, fieldnames=['Title', 'Author Information', 'Clinical Characteristics', 'Clinical Information', 'Copyright', 'PMID'])\n",
        "    # Write the header to the csv file\n",
        "    writer.writeheader()\n",
        "    # Write the parsed data to the csv file\n",
        "    for row in parsed_data:\n",
        "        # Only write rows that contain the correct fields\n",
        "        if all(field in row for field in writer.fieldnames):\n",
        "            writer.writerow(row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9031\n",
            "dict_keys(['In', 'Amemiya A, editors. GeneReviews(®) [Internet]. Seattle (WA)', 'Author information', 'CLINICAL CHARACTERISTICS', 'both females and males. Two main types of clinical presentation are seen', 'DIAGNOSIS/TESTING', 'MANAGEMENT', 'GENETIC COUNSELING', 'chance of transmitting it in each pregnancy is 50%', 'PMID'])\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import ray\n",
        "import re\n",
        "from ray.data import from_items\n",
        "\n",
        "# Define a function to parse the data\n",
        "def parse_data(data):\n",
        "    # Split the data into records\n",
        "    # print(data)\n",
        "    # records = data.split('\\n\\n')\n",
        "    # Initialize a list to store the parsed data\n",
        "    pattern = r'(?<=\\n)\\d+\\.\\s'\n",
        "    # Split the data into records\n",
        "    records = re.split(pattern, data)\n",
        "    print(len(records))\n",
        "    parsed_data = []\n",
        "    # Iterate over each record\n",
        "    for record in records:\n",
        "        # Split the record into lines\n",
        "        # print(record)\n",
        "        \n",
        "        lines = record.split('\\n')\n",
        "        \n",
        "        # Initialize an empty dictionary to store the record data\n",
        "        record_data = {}\n",
        "        # Initialize a variable to store the current key\n",
        "        current_key = None\n",
        "        # Iterate over each line\n",
        "        for line in lines:\n",
        "            # Check if the line contains a colon\n",
        "            if ':' in line:\n",
        "                # Split the line into key and value\n",
        "                key, value = line.split(':', 1)\n",
        "                # Remove leading and trailing whitespace\n",
        "                key = key.strip()\n",
        "                value = value.strip()\n",
        "                # Add the key-value pair to the record data\n",
        "                record_data[key] = value\n",
        "                # Update the current key\n",
        "                current_key = key\n",
        "            elif current_key is not None:\n",
        "                # If the line does not contain a colon, add it to the current field\n",
        "                record_data[current_key] += ' ' + line.strip()\n",
        "        # Add the record data to the parsed data\n",
        "        parsed_data.append(record_data)\n",
        "    # Return the parsed data\n",
        "    return parsed_data\n",
        "\n",
        "# Open the text file and csv file\n",
        "with open('input.txt', 'r', encoding='utf-8') as in_file, open('output.csv', 'w', newline='', encoding='utf-8') as out_file:\n",
        "    # Read the entire text file\n",
        "    data = in_file.read()\n",
        "    # Parse the data\n",
        "    parsed_data = parse_data(data)\n",
        "    # Create a csv writer object\n",
        "\n",
        "print(parsed_data[1].keys())\n",
        "\n",
        "# dataset = from_items(parsed_data)\n",
        "\n",
        "# # Print the first few records of the dataset\n",
        "# print(dataset.take(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ray\n",
        "import re\n",
        "from ray.data import from_items\n",
        "\n",
        "# Initialize Ray\n",
        "ray.init()\n",
        "\n",
        "# Define a function to parse the data\n",
        "def parse_data(data):\n",
        "    # Define the regular expression pattern\n",
        "    pattern = r'(?<=\\n)\\d+\\.\\s'\n",
        "    # Split the data into records\n",
        "    records = re.split(pattern, data)\n",
        "    # Initialize a list to store the parsed data\n",
        "    parsed_data = []\n",
        "    # Iterate over each record\n",
        "    for record in records:\n",
        "        # Split the record into lines\n",
        "        lines = record.split('\\n')\n",
        "        # Initialize an empty dictionary to store the record data\n",
        "        record_data = {}\n",
        "        # Initialize a variable to store the current key\n",
        "        current_key = None\n",
        "        # Iterate over each line\n",
        "        for line in lines:\n",
        "            # Check if the line contains a colon\n",
        "            if ':' in line:\n",
        "                # Split the line into key and value\n",
        "                key, value = line.split(':', 1)\n",
        "                # Remove leading and trailing whitespace\n",
        "                key = key.strip()\n",
        "                value = value.strip()\n",
        "                # Add the key-value pair to the record data\n",
        "                record_data[key] = value\n",
        "                # Update the current key\n",
        "                current_key = key\n",
        "            elif current_key is not None:\n",
        "                # If the line does not contain a colon, add it to the current field\n",
        "                record_data[current_key] += ' ' + line.strip()\n",
        "        # Add the record data to the parsed data if it is not empty\n",
        "        if record_data:\n",
        "            parsed_data.append(record_data)\n",
        "    # Return the parsed data\n",
        "    return parsed_data\n",
        "\n",
        "# Open the text file\n",
        "with open('input.txt', 'r', encoding='utf-8') as in_file:\n",
        "    # Read the entire text file\n",
        "    data = in_file.read()\n",
        "    # Parse the data\n",
        "    parsed_data = parse_data(data)\n",
        "\n",
        "# Convert the parsed data into a Ray dataset\n",
        "dataset = from_items(parsed_data)\n",
        "\n",
        "# Print the first few records of the dataset\n",
        "print(dataset.take(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOKwDXBMJ3Yq7Bq+hZC/VYI",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
